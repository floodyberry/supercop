# block pos: 0 33 uops: 6

# qhasm: int64 input_0

# qhasm: int64 input_1

# qhasm: int64 input_2

# qhasm: int64 input_3

# qhasm: int64 input_4

# qhasm: int64 input_5

# qhasm: stack64 input_6

# qhasm: stack64 input_7

# qhasm: int64 caller_r11

# qhasm: int64 caller_r12

# qhasm: int64 caller_r13

# qhasm: int64 caller_r14

# qhasm: int64 caller_r15

# qhasm: int64 caller_rbx

# qhasm: int64 caller_rbp

# qhasm: stack64 stack_r11

# qhasm: stack64 stack_r12

# qhasm: stack64 stack_r13

# qhasm: stack64 stack_r14

# qhasm: stack64 stack_r15

# qhasm: stack64 stack_rbx

# qhasm: stack64 stack_rbp

# qhasm: int64 pos

# qhasm: int64 i

# qhasm: int64 j

# qhasm: int64 bit

# qhasm: int64 prevbit

# qhasm: reg256 x0

# qhasm: reg256 x1

# qhasm: reg256 x2

# qhasm: reg256 x3

# qhasm: reg256 x4

# qhasm: reg256 x5

# qhasm: reg256 y0

# qhasm: reg256 y1

# qhasm: reg256 y2

# qhasm: reg256 y3

# qhasm: reg256 y4

# qhasm: reg256 y5

# qhasm: reg256 t0

# qhasm: reg256 t1

# qhasm: reg256 t2

# qhasm: reg256 t3

# qhasm: reg256 t4

# qhasm: reg256 t5

# qhasm: reg256 b

# qhasm: stack64 b_stack

# qhasm: reg256 one

# qhasm: reg256 two

# qhasm: reg256 2p22

# qhasm: reg256 2p43

# qhasm: reg256 2p64

# qhasm: reg256 2p85

# qhasm: reg256 2p106

# qhasm: reg256 2p127

# qhasm: reg256 2pm22

# qhasm: reg256 2pm43

# qhasm: reg256 2pm64

# qhasm: reg256 2pm85

# qhasm: reg256 2pm106

# qhasm: reg256 2pm127

# qhasm: reg256 a22

# qhasm: reg256 a43

# qhasm: reg256 a64

# qhasm: reg256 a85

# qhasm: reg256 a106

# qhasm: reg256 a127

# qhasm: reg256 abcd

# qhasm: reg256 ABCD

# qhasm: int64 const0

# qhasm: stack2048 const0_storage

# qhasm: int64 const1

# qhasm: stack2048 const1_storage

# qhasm: int64 const2

# qhasm: stack2048 const2_storage

# qhasm: int64 work0

# qhasm: int64 work1

# qhasm: int64 work2

# qhasm: int64 work3

# qhasm: reg256 P0

# qhasm: reg256 P1

# qhasm: reg256 P2

# qhasm: reg256 P3

# qhasm: reg256 P4

# qhasm: reg256 P5

# qhasm: reg256 Q0

# qhasm: reg256 Q1

# qhasm: reg256 Q2

# qhasm: reg256 Q3

# qhasm: reg256 Q4

# qhasm: reg256 Q5

# qhasm: reg256 H0

# qhasm: reg256 H1

# qhasm: reg256 H2

# qhasm: reg256 H3

# qhasm: reg256 H4

# qhasm: reg256 H5

# qhasm: reg256 I0

# qhasm: reg256 I1

# qhasm: reg256 I2

# qhasm: reg256 I3

# qhasm: reg256 I4

# qhasm: reg256 I5

# qhasm: reg256 R0

# qhasm: reg256 R1

# qhasm: reg256 R2

# qhasm: reg256 R3

# qhasm: reg256 R4

# qhasm: reg256 R5

# qhasm: reg256 S0

# qhasm: reg256 S1

# qhasm: reg256 S2

# qhasm: reg256 S3

# qhasm: reg256 S4

# qhasm: reg256 S5

# qhasm: reg256 A0

# qhasm: reg256 A1

# qhasm: reg256 A2

# qhasm: reg256 A3

# qhasm: reg256 A4

# qhasm: reg256 A5

# qhasm: reg256 B0

# qhasm: reg256 B1

# qhasm: reg256 B2

# qhasm: reg256 B3

# qhasm: reg256 B4

# qhasm: reg256 B5

# qhasm: reg256 C0

# qhasm: reg256 C1

# qhasm: reg256 C2

# qhasm: reg256 C3

# qhasm: reg256 C4

# qhasm: reg256 C5

# qhasm: reg256 D0

# qhasm: reg256 D1

# qhasm: reg256 D2

# qhasm: reg256 D3

# qhasm: reg256 D4

# qhasm: reg256 D5

# qhasm: reg256 E0

# qhasm: reg256 E1

# qhasm: reg256 E2

# qhasm: reg256 E3

# qhasm: reg256 E4

# qhasm: reg256 E5

# qhasm: reg256 F0

# qhasm: reg256 F1

# qhasm: reg256 F2

# qhasm: reg256 F3

# qhasm: reg256 F4

# qhasm: reg256 F5

# qhasm: reg256 xyzt0

# qhasm: reg256 yxtz0

# qhasm: reg256 abcd0

# qhasm: reg256 cdab0

# qhasm: reg256 badc0

# qhasm: reg256 xtzy0

# qhasm: reg256 xyzt1

# qhasm: reg256 yxtz1

# qhasm: reg256 abcd1

# qhasm: reg256 cdab1

# qhasm: reg256 badc1

# qhasm: reg256 xtzy1

# qhasm: reg256 xyzt2

# qhasm: reg256 yxtz2

# qhasm: reg256 abcd2

# qhasm: reg256 cdab2

# qhasm: reg256 badc2

# qhasm: reg256 xtzy2

# qhasm: reg256 xyzt3

# qhasm: reg256 yxtz3

# qhasm: reg256 abcd3

# qhasm: reg256 cdab3

# qhasm: reg256 badc3

# qhasm: reg256 xtzy3

# qhasm: reg256 xyzt4

# qhasm: reg256 yxtz4

# qhasm: reg256 abcd4

# qhasm: reg256 cdab4

# qhasm: reg256 badc4

# qhasm: reg256 xtzy4

# qhasm: reg256 xyzt5

# qhasm: reg256 yxtz5

# qhasm: reg256 abcd5

# qhasm: reg256 cdab5

# qhasm: reg256 badc5

# qhasm: reg256 xtzy5

# qhasm: reg256 a0

# qhasm: reg256 a1

# qhasm: reg256 a2

# qhasm: reg256 a3

# qhasm: reg256 a4

# qhasm: reg256 a5

# qhasm: reg256 const

# qhasm: reg256 c0

# qhasm: reg256 c1

# qhasm: reg256 c2

# qhasm: reg256 c3

# qhasm: reg256 c4

# qhasm: reg256 c5

# qhasm: reg256 r0

# qhasm: reg256 r1

# qhasm: reg256 r2

# qhasm: reg256 r3

# qhasm: reg256 r4

# qhasm: reg256 r5

# qhasm: reg256 2Q0

# qhasm: reg256 2Q1

# qhasm: reg256 2Q2

# qhasm: reg256 2Q3

# qhasm: reg256 2Q4

# qhasm: reg256 2Q5

# qhasm: reg256 2a0

# qhasm: reg256 2a1

# qhasm: reg256 2a2

# qhasm: reg256 2a3

# qhasm: reg256 2a4

# qhasm: reg256 2a5

# qhasm: reg256 2A0

# qhasm: reg256 2A1

# qhasm: reg256 2A2

# qhasm: reg256 2A3

# qhasm: reg256 2A4

# qhasm: reg256 2A5

# qhasm: reg256 2B0

# qhasm: reg256 2B1

# qhasm: reg256 2B2

# qhasm: reg256 2B3

# qhasm: reg256 2B4

# qhasm: reg256 2B5

# qhasm: reg256 a0a0

# qhasm: reg256 a1a1

# qhasm: reg256 a2a2

# qhasm: reg256 2a0a1

# qhasm: reg256 2a0a2

# qhasm: reg256 2a0a3

# qhasm: reg256 2a0a4

# qhasm: reg256 2a1a2

# qhasm: reg256 2a1a3

# qhasm: reg256 2a1a4

# qhasm: reg256 2a1a5

# qhasm: reg256 2a2a3

# qhasm: reg256 2a2a4

# qhasm: reg256 2a2a5

# qhasm: reg256 2a3a5

# qhasm: reg256 Q0Q0

# qhasm: reg256 Q1Q1

# qhasm: reg256 Q2Q2

# qhasm: reg256 Q3Q3

# qhasm: reg256 Q4Q4

# qhasm: reg256 Q5Q5

# qhasm: reg256 2Q0Q1

# qhasm: reg256 2Q0Q2

# qhasm: reg256 2Q0Q3

# qhasm: reg256 2Q0Q4

# qhasm: reg256 2Q0Q5

# qhasm: reg256 2Q1Q2

# qhasm: reg256 2Q1Q3

# qhasm: reg256 2Q1Q4

# qhasm: reg256 2Q1Q5

# qhasm: reg256 2Q2Q3

# qhasm: reg256 2Q2Q4

# qhasm: reg256 2Q2Q5

# qhasm: reg256 2Q3Q4

# qhasm: reg256 2Q3Q5

# qhasm: reg256 2Q4Q5

# qhasm: reg256 B0B0

# qhasm: reg256 B1B1

# qhasm: reg256 B2B2

# qhasm: reg256 B3B3

# qhasm: reg256 B4B4

# qhasm: reg256 B5B5

# qhasm: reg256 2B0B1

# qhasm: reg256 2B0B2

# qhasm: reg256 2B0B3

# qhasm: reg256 2B0B4

# qhasm: reg256 2B0B5

# qhasm: reg256 2B1B2

# qhasm: reg256 2B1B3

# qhasm: reg256 2B1B4

# qhasm: reg256 2B1B5

# qhasm: reg256 2B2B3

# qhasm: reg256 2B2B4

# qhasm: reg256 2B2B5

# qhasm: reg256 2B3B4

# qhasm: reg256 2B3B5

# qhasm: reg256 2B4B5

# qhasm: reg256 127Q1

# qhasm: reg256 127Q2

# qhasm: reg256 127Q3

# qhasm: reg256 127Q4

# qhasm: reg256 127Q5

# qhasm: reg256 127B1

# qhasm: reg256 127B2

# qhasm: reg256 127B3

# qhasm: reg256 127B4

# qhasm: reg256 127B5

# qhasm: reg256 127I1

# qhasm: reg256 127I2

# qhasm: reg256 127I3

# qhasm: reg256 127I4

# qhasm: reg256 127I5

# qhasm: reg256 127a1

# qhasm: reg256 127a2

# qhasm: reg256 127a3

# qhasm: reg256 127a4

# qhasm: reg256 127a5

# qhasm: reg256 b0

# qhasm: reg256 b1

# qhasm: reg256 b2

# qhasm: reg256 b3

# qhasm: reg256 b4

# qhasm: reg256 b5

# qhasm: reg256 a0b0

# qhasm: reg256 a0b1

# qhasm: reg256 a0b2

# qhasm: reg256 a0b3

# qhasm: reg256 a0b4

# qhasm: reg256 a0b5

# qhasm: reg256 a1b0

# qhasm: reg256 a1b1

# qhasm: reg256 a1b2

# qhasm: reg256 a1b3

# qhasm: reg256 a1b4

# qhasm: reg256 a1b5

# qhasm: reg256 a2b0

# qhasm: reg256 a2b1

# qhasm: reg256 a2b2

# qhasm: reg256 a2b3

# qhasm: reg256 a2b4

# qhasm: reg256 a2b5

# qhasm: reg256 a3b0

# qhasm: reg256 a3b1

# qhasm: reg256 a3b2

# qhasm: reg256 a3b3

# qhasm: reg256 a3b4

# qhasm: reg256 a3b5

# qhasm: reg256 a4b0

# qhasm: reg256 a4b1

# qhasm: reg256 a4b2

# qhasm: reg256 a4b3

# qhasm: reg256 a4b4

# qhasm: reg256 a4b5

# qhasm: reg256 a5b0

# qhasm: reg256 a5b1

# qhasm: reg256 a5b2

# qhasm: reg256 a5b3

# qhasm: reg256 a5b4

# qhasm: reg256 a5b5

# qhasm: enter ladder
.p2align 5
.global _ladder
.global ladder
_ladder:
ladder:
# bytes: 3 uops: 1
mov %rsp,%r11
# bytes: 4 uops: 1
and $31,%r11
# bytes: 7 uops: 1
add $832,%r11
# bytes: 3 uops: 1
sub %r11,%rsp

# qhasm:   stack_r11 = caller_r11
# asm 1: movq <caller_r11=int64#9,>stack_r11=stack64#1
# asm 2: movq <caller_r11=%r11,>stack_r11=768(%rsp)
# bytes: 8 uops: 1
movq %r11,768(%rsp)

# qhasm:   stack_r12 = caller_r12
# asm 1: movq <caller_r12=int64#10,>stack_r12=stack64#2
# asm 2: movq <caller_r12=%r12,>stack_r12=776(%rsp)
# bytes: 8 uops: 1
movq %r12,776(%rsp)
# block pos: 33 65 uops: 4

# qhasm:   stack_r13 = caller_r13
# asm 1: movq <caller_r13=int64#11,>stack_r13=stack64#3
# asm 2: movq <caller_r13=%r13,>stack_r13=784(%rsp)
# bytes: 8 uops: 1
movq %r13,784(%rsp)

# qhasm:   stack_r14 = caller_r14
# asm 1: movq <caller_r14=int64#12,>stack_r14=stack64#4
# asm 2: movq <caller_r14=%r14,>stack_r14=792(%rsp)
# bytes: 8 uops: 1
movq %r14,792(%rsp)

# qhasm:   stack_r15 = caller_r15
# asm 1: movq <caller_r15=int64#13,>stack_r15=stack64#5
# asm 2: movq <caller_r15=%r15,>stack_r15=800(%rsp)
# bytes: 8 uops: 1
movq %r15,800(%rsp)

# qhasm:   stack_rbx = caller_rbx
# asm 1: movq <caller_rbx=int64#14,>stack_rbx=stack64#6
# asm 2: movq <caller_rbx=%rbx,>stack_rbx=808(%rsp)
# bytes: 8 uops: 1
movq %rbx,808(%rsp)
# block pos: 65 101 uops: 5

# qhasm:   stack_rbp = caller_rbp
# asm 1: movq <caller_rbp=int64#15,>stack_rbp=stack64#7
# asm 2: movq <caller_rbp=%rbp,>stack_rbp=816(%rsp)
# bytes: 8 uops: 1
movq %rbp,816(%rsp)

# qhasm:   work0 = input_0 + 128
# asm 1: lea  128(<input_0=int64#1),>work0=int64#3
# asm 2: lea  128(<input_0=%rdi),>work0=%rdx
# bytes: 7 uops: 1
lea  128(%rdi),%rdx

# qhasm:   work1 = input_0 + 320
# asm 1: lea  320(<input_0=int64#1),>work1=int64#5
# asm 2: lea  320(<input_0=%rdi),>work1=%r8
# bytes: 7 uops: 1
lea  320(%rdi),%r8

# qhasm:   work2 = input_0 + 512
# asm 1: lea  512(<input_0=int64#1),>work2=int64#6
# asm 2: lea  512(<input_0=%rdi),>work2=%r9
# bytes: 7 uops: 1
lea  512(%rdi),%r9

# qhasm:   work3 = input_0 + 704
# asm 1: lea  704(<input_0=int64#1),>work3=int64#1
# asm 2: lea  704(<input_0=%rdi),>work3=%rdi
# bytes: 7 uops: 1
lea  704(%rdi),%rdi
# block pos: 101 134 uops: 5

# qhasm:   new const0_storage

# qhasm:   new const1_storage

# qhasm:   new const2_storage

# qhasm:   const0 = &const0_storage
# asm 1: leaq <const0_storage=stack2048#1,>const0=int64#4
# asm 2: leaq <const0_storage=0(%rsp),>const0=%rcx
# bytes: 4 uops: 1
leaq 0(%rsp),%rcx

# qhasm:   const0 += 128
# asm 1: add  $128,<const0=int64#4
# asm 2: add  $128,<const0=%rcx
# bytes: 7 uops: 1
add  $128,%rcx

# qhasm:   const1 = &const1_storage
# asm 1: leaq <const1_storage=stack2048#2,>const1=int64#7
# asm 2: leaq <const1_storage=256(%rsp),>const1=%rax
# bytes: 8 uops: 1
leaq 256(%rsp),%rax

# qhasm:   const1 += 128
# asm 1: add  $128,<const1=int64#7
# asm 2: add  $128,<const1=%rax
# bytes: 6 uops: 1
add  $128,%rax

# qhasm:   const2 = &const2_storage
# asm 1: leaq <const2_storage=stack2048#3,>const2=int64#8
# asm 2: leaq <const2_storage=512(%rsp),>const2=%r10
# bytes: 8 uops: 1
leaq 512(%rsp),%r10
# block pos: 134 163 uops: 4

# qhasm:   const2 += 128
# asm 1: add  $128,<const2=int64#8
# asm 2: add  $128,<const2=%r10
# bytes: 7 uops: 1
add  $128,%r10

# qhasm:   two aligned= mem256[_two]
# asm 1: vmovapd _two,>two=reg256#1
# asm 2: vmovapd _two,>two=%ymm0
# bytes: 9 uops: 1
vmovapd _two,%ymm0

# qhasm:   one aligned= mem256[_1111]
# asm 1: vmovapd _1111,>one=reg256#2
# asm 2: vmovapd _1111,>one=%ymm1
# bytes: 9 uops: 1
vmovapd _1111,%ymm1

# qhasm:   mem256[const1 + 0] aligned= two
# asm 1: vmovapd   <two=reg256#1,0(<const1=int64#7)
# asm 2: vmovapd   <two=%ymm0,0(<const1=%rax)
# bytes: 4 uops: 1
vmovapd   %ymm0,0(%rax)
# block pos: 163 196 uops: 6

# qhasm:   mem256[const1 + 32] aligned= one
# asm 1: vmovapd   <one=reg256#2,32(<const1=int64#7)
# asm 2: vmovapd   <one=%ymm1,32(<const1=%rax)
# bytes: 5 uops: 1
vmovapd   %ymm1,32(%rax)

# qhasm:   2pm127 aligned= mem256[_2pm127]
# asm 1: vmovapd _2pm127,>2pm127=reg256#1
# asm 2: vmovapd _2pm127,>2pm127=%ymm0
# bytes: 9 uops: 1
vmovapd _2pm127,%ymm0

# qhasm:   4x 127a5 = approx 2pm127 * mem256[work0 + 32]
# asm 1: vmulpd 32(<work0=int64#3),<2pm127=reg256#1,>127a5=reg256#2
# asm 2: vmulpd 32(<work0=%rdx),<2pm127=%ymm0,>127a5=%ymm1
# bytes: 5 uops: 1
vmulpd 32(%rdx),%ymm0,%ymm1

# qhasm:   4x 127a4 = approx 2pm127 * mem256[work0 + 0]
# asm 1: vmulpd 0(<work0=int64#3),<2pm127=reg256#1,>127a4=reg256#3
# asm 2: vmulpd 0(<work0=%rdx),<2pm127=%ymm0,>127a4=%ymm2
# bytes: 4 uops: 1
vmulpd 0(%rdx),%ymm0,%ymm2

# qhasm:   4x 127a3 = approx 2pm127 * mem256[work0 - 32]
# asm 1: vmulpd -32(<work0=int64#3),<2pm127=reg256#1,>127a3=reg256#4
# asm 2: vmulpd -32(<work0=%rdx),<2pm127=%ymm0,>127a3=%ymm3
# bytes: 5 uops: 1
vmulpd -32(%rdx),%ymm0,%ymm3

# qhasm:   4x 127a2 = approx 2pm127 * mem256[work0 - 64]
# asm 1: vmulpd -64(<work0=int64#3),<2pm127=reg256#1,>127a2=reg256#5
# asm 2: vmulpd -64(<work0=%rdx),<2pm127=%ymm0,>127a2=%ymm4
# bytes: 5 uops: 1
vmulpd -64(%rdx),%ymm0,%ymm4
# block pos: 196 224 uops: 4

# qhasm:   4x 127a1 = approx 2pm127 * mem256[work0 - 96]
# asm 1: vmulpd -96(<work0=int64#3),<2pm127=reg256#1,>127a1=reg256#6
# asm 2: vmulpd -96(<work0=%rdx),<2pm127=%ymm0,>127a1=%ymm5
# bytes: 5 uops: 1
vmulpd -96(%rdx),%ymm0,%ymm5

# qhasm:   mem256[const1 - 128] aligned= 2pm127
# asm 1: vmovapd   <2pm127=reg256#1,-128(<const1=int64#7)
# asm 2: vmovapd   <2pm127=%ymm0,-128(<const1=%rax)
# bytes: 5 uops: 1
vmovapd   %ymm0,-128(%rax)

# qhasm:   a22 aligned= mem256[alpha22]
# asm 1: vmovapd alpha22,>a22=reg256#1
# asm 2: vmovapd alpha22,>a22=%ymm0
# bytes: 9 uops: 1
vmovapd alpha22,%ymm0

# qhasm:   a64 aligned= mem256[alpha64]
# asm 1: vmovapd alpha64,>a64=reg256#7
# asm 2: vmovapd alpha64,>a64=%ymm6
# bytes: 9 uops: 1
vmovapd alpha64,%ymm6
# block pos: 224 256 uops: 4

# qhasm:   a106 aligned= mem256[alpha106]
# asm 1: vmovapd alpha106,>a106=reg256#8
# asm 2: vmovapd alpha106,>a106=%ymm7
# bytes: 9 uops: 1
vmovapd alpha106,%ymm7

# qhasm:   abcd aligned= mem256[newabcd]
# asm 1: vmovapd newabcd,>abcd=reg256#9
# asm 2: vmovapd newabcd,>abcd=%ymm8
# bytes: 9 uops: 1
vmovapd newabcd,%ymm8

# qhasm:   ABCD aligned= mem256[newABCD]
# asm 1: vmovapd newABCD,>ABCD=reg256#10
# asm 2: vmovapd newABCD,>ABCD=%ymm9
# bytes: 9 uops: 1
vmovapd newABCD,%ymm9

# qhasm:   mem256[work3 - 128] aligned= 127a5
# asm 1: vmovapd   <127a5=reg256#2,-128(<work3=int64#1)
# asm 2: vmovapd   <127a5=%ymm1,-128(<work3=%rdi)
# bytes: 5 uops: 1
vmovapd   %ymm1,-128(%rdi)
# block pos: 256 292 uops: 7

# qhasm:   mem256[work3 - 96] aligned= 127a4
# asm 1: vmovapd   <127a4=reg256#3,-96(<work3=int64#1)
# asm 2: vmovapd   <127a4=%ymm2,-96(<work3=%rdi)
# bytes: 5 uops: 1
vmovapd   %ymm2,-96(%rdi)

# qhasm:   mem256[work3 - 64] aligned= 127a3
# asm 1: vmovapd   <127a3=reg256#4,-64(<work3=int64#1)
# asm 2: vmovapd   <127a3=%ymm3,-64(<work3=%rdi)
# bytes: 5 uops: 1
vmovapd   %ymm3,-64(%rdi)

# qhasm:   mem256[work3 - 32] aligned= 127a2
# asm 1: vmovapd   <127a2=reg256#5,-32(<work3=int64#1)
# asm 2: vmovapd   <127a2=%ymm4,-32(<work3=%rdi)
# bytes: 5 uops: 1
vmovapd   %ymm4,-32(%rdi)

# qhasm:   mem256[work3 + 0] aligned= 127a1
# asm 1: vmovapd   <127a1=reg256#6,0(<work3=int64#1)
# asm 2: vmovapd   <127a1=%ymm5,0(<work3=%rdi)
# bytes: 4 uops: 1
vmovapd   %ymm5,0(%rdi)

# qhasm:   mem256[const2 - 128] aligned= a22
# asm 1: vmovapd   <a22=reg256#1,-128(<const2=int64#8)
# asm 2: vmovapd   <a22=%ymm0,-128(<const2=%r10)
# bytes: 6 uops: 1
vmovapd   %ymm0,-128(%r10)

# qhasm:   mem256[const2 - 64] aligned= a64
# asm 1: vmovapd   <a64=reg256#7,-64(<const2=int64#8)
# asm 2: vmovapd   <a64=%ymm6,-64(<const2=%r10)
# bytes: 6 uops: 1
vmovapd   %ymm6,-64(%r10)

# qhasm:   mem256[const2 + 0] aligned= a106
# asm 1: vmovapd   <a106=reg256#8,0(<const2=int64#8)
# asm 2: vmovapd   <a106=%ymm7,0(<const2=%r10)
# bytes: 5 uops: 1
vmovapd   %ymm7,0(%r10)
# block pos: 292 320 uops: 5

# qhasm:   mem256[const2 + 64] aligned= abcd
# asm 1: vmovapd   <abcd=reg256#9,64(<const2=int64#8)
# asm 2: vmovapd   <abcd=%ymm8,64(<const2=%r10)
# bytes: 6 uops: 1
vmovapd   %ymm8,64(%r10)

# qhasm:   mem256[const2 + 96] aligned= ABCD
# asm 1: vmovapd   <ABCD=reg256#10,96(<const2=int64#8)
# asm 2: vmovapd   <ABCD=%ymm9,96(<const2=%r10)
# bytes: 6 uops: 1
vmovapd   %ymm9,96(%r10)

# qhasm:   pos = 250
# asm 1: mov  $250,>pos=int64#9
# asm 2: mov  $250,>pos=%r11
# bytes: 7 uops: 1
mov  $250,%r11

# qhasm:   bit = *(uint8 *) (input_1 + 31)
# asm 1: movzbq 31(<input_1=int64#2),>bit=int64#4
# asm 2: movzbq 31(<input_1=%rsi),>bit=%rcx
# bytes: 5 uops: 1
movzbq 31(%rsi),%rcx

# qhasm:   (uint64) bit >>= 2
# asm 1: shr  $2,<bit=int64#4
# asm 2: shr  $2,<bit=%rcx
# bytes: 4 uops: 1
shr  $2,%rcx
# block pos: 320 352 uops: 6

# qhasm:   (uint32) bit &= 1
# asm 1: and  $1,<bit=int64#4d
# asm 2: and  $1,<bit=%ecx
# bytes: 5 uops: 1
.byte 0x3e
.byte 0x3e
and  $1,%ecx

# qhasm:   prevbit = bit
# asm 1: mov  <bit=int64#4,>prevbit=int64#10
# asm 2: mov  <bit=%rcx,>prevbit=%r12
# bytes: 4 uops: 1
.byte 0x3e
mov  %rcx,%r12

# qhasm:   bit -= 1
# asm 1: sub  $1,<bit=int64#4
# asm 2: sub  $1,<bit=%rcx
# bytes: 4 uops: 1
sub  $1,%rcx

# qhasm:   b_stack = bit
# asm 1: movq <bit=int64#4,>b_stack=stack64#8
# asm 2: movq <bit=%rcx,>b_stack=824(%rsp)
# bytes: 8 uops: 1
movq %rcx,824(%rsp)

# qhasm:   E4 aligned= mem256[work2 +   0]
# asm 1: vmovapd   0(<work2=int64#6),>E4=reg256#1
# asm 2: vmovapd   0(<work2=%r9),>E4=%ymm0
# bytes: 5 uops: 1
vmovapd   0(%r9),%ymm0

# qhasm:   E2 aligned= mem256[work2 -  64]
# asm 1: vmovapd   -64(<work2=int64#6),>E2=reg256#2
# asm 2: vmovapd   -64(<work2=%r9),>E2=%ymm1
# bytes: 6 uops: 1
vmovapd   -64(%r9),%ymm1
# block pos: 352 385 uops: 6

# qhasm:   E0 aligned= mem256[work2 - 128]
# asm 1: vmovapd   -128(<work2=int64#6),>E0=reg256#3
# asm 2: vmovapd   -128(<work2=%r9),>E0=%ymm2
# bytes: 6 uops: 1
vmovapd   -128(%r9),%ymm2

# qhasm:   a127 aligned= mem256[alpha127]
# asm 1: vmovapd alpha127,>a127=reg256#4
# asm 2: vmovapd alpha127,>a127=%ymm3
# bytes: 9 uops: 1
vmovapd alpha127,%ymm3

# qhasm:           4x c4 = approx E4 + a127
# asm 1: vaddpd <E4=reg256#1,<a127=reg256#4,>c4=reg256#5
# asm 2: vaddpd <E4=%ymm0,<a127=%ymm3,>c4=%ymm4
# bytes: 4 uops: 1
vaddpd %ymm0,%ymm3,%ymm4

# qhasm:           4x c4 approx-= a127
# asm 1: vsubpd <a127=reg256#4,<c4=reg256#5,>c4=reg256#5
# asm 2: vsubpd <a127=%ymm3,<c4=%ymm4,>c4=%ymm4
# bytes: 4 uops: 1
vsubpd %ymm3,%ymm4,%ymm4

# qhasm:   mem256[const2 + 32] aligned= a127
# asm 1: vmovapd   <a127=reg256#4,32(<const2=int64#8)
# asm 2: vmovapd   <a127=%ymm3,32(<const2=%r10)
# bytes: 6 uops: 1
vmovapd   %ymm3,32(%r10)

# qhasm:           4x E4 approx-= c4
# asm 1: vsubpd <c4=reg256#5,<E4=reg256#1,>E4=reg256#1
# asm 2: vsubpd <c4=%ymm4,<E4=%ymm0,>E4=%ymm0
# bytes: 4 uops: 1
vsubpd %ymm4,%ymm0,%ymm0
# block pos: 385 418 uops: 6

# qhasm:           4x E0 approx+= c4 * mem256[const1 - 128]
# asm 1: vfmadd231pd -128(<const1=int64#7),<c4=reg256#5,<E0=reg256#3
# asm 2: vfmadd231pd -128(<const1=%rax),<c4=%ymm4,<E0=%ymm2
# bytes: 6 uops: 1
vfmadd231pd -128(%rax),%ymm4,%ymm2

# qhasm:   a85 aligned= mem256[alpha85]
# asm 1: vmovapd alpha85,>a85=reg256#4
# asm 2: vmovapd alpha85,>a85=%ymm3
# bytes: 9 uops: 1
vmovapd alpha85,%ymm3

# qhasm:           4x c2 = approx E2 + a85
# asm 1: vaddpd <E2=reg256#2,<a85=reg256#4,>c2=reg256#5
# asm 2: vaddpd <E2=%ymm1,<a85=%ymm3,>c2=%ymm4
# bytes: 4 uops: 1
vaddpd %ymm1,%ymm3,%ymm4

# qhasm:           4x c2 approx-= a85
# asm 1: vsubpd <a85=reg256#4,<c2=reg256#5,>c2=reg256#5
# asm 2: vsubpd <a85=%ymm3,<c2=%ymm4,>c2=%ymm4
# bytes: 4 uops: 1
vsubpd %ymm3,%ymm4,%ymm4

# qhasm:   mem256[const2 - 32] aligned= a85
# asm 1: vmovapd   <a85=reg256#4,-32(<const2=int64#8)
# asm 2: vmovapd   <a85=%ymm3,-32(<const2=%r10)
# bytes: 6 uops: 1
vmovapd   %ymm3,-32(%r10)

# qhasm:           4x E4 approx+= c2
# asm 1: vaddpd <c2=reg256#5,<E4=reg256#1,>E4=reg256#1
# asm 2: vaddpd <c2=%ymm4,<E4=%ymm0,>E4=%ymm0
# bytes: 4 uops: 1
vaddpd %ymm4,%ymm0,%ymm0
# block pos: 418 449 uops: 6

# qhasm:           4x E2 approx-= c2
# asm 1: vsubpd <c2=reg256#5,<E2=reg256#2,>E2=reg256#2
# asm 2: vsubpd <c2=%ymm4,<E2=%ymm1,>E2=%ymm1
# bytes: 4 uops: 1
vsubpd %ymm4,%ymm1,%ymm1

# qhasm:   a43 aligned= mem256[alpha43]
# asm 1: vmovapd alpha43,>a43=reg256#4
# asm 2: vmovapd alpha43,>a43=%ymm3
# bytes: 9 uops: 1
vmovapd alpha43,%ymm3

# qhasm:           4x c0 = approx E0 + a43
# asm 1: vaddpd <E0=reg256#3,<a43=reg256#4,>c0=reg256#5
# asm 2: vaddpd <E0=%ymm2,<a43=%ymm3,>c0=%ymm4
# bytes: 4 uops: 1
vaddpd %ymm2,%ymm3,%ymm4

# qhasm:           4x c0 approx-= a43
# asm 1: vsubpd <a43=reg256#4,<c0=reg256#5,>c0=reg256#5
# asm 2: vsubpd <a43=%ymm3,<c0=%ymm4,>c0=%ymm4
# bytes: 4 uops: 1
vsubpd %ymm3,%ymm4,%ymm4

# qhasm:   mem256[const2 - 96] aligned= a43
# asm 1: vmovapd   <a43=reg256#4,-96(<const2=int64#8)
# asm 2: vmovapd   <a43=%ymm3,-96(<const2=%r10)
# bytes: 6 uops: 1
vmovapd   %ymm3,-96(%r10)

# qhasm:           4x E2 approx+= c0
# asm 1: vaddpd <c0=reg256#5,<E2=reg256#2,>E2=reg256#2
# asm 2: vaddpd <c0=%ymm4,<E2=%ymm1,>E2=%ymm1
# bytes: 4 uops: 1
vaddpd %ymm4,%ymm1,%ymm1
# block pos: 449 480 uops: 6

# qhasm:           4x E0 approx-= c0
# asm 1: vsubpd <c0=reg256#5,<E0=reg256#3,>E0=reg256#3
# asm 2: vsubpd <c0=%ymm4,<E0=%ymm2,>E0=%ymm2
# bytes: 4 uops: 1
vsubpd %ymm4,%ymm2,%ymm2

# qhasm:   F4 aligned= mem256[work1 +   0]
# asm 1: vmovapd   0(<work1=int64#5),>F4=reg256#4
# asm 2: vmovapd   0(<work1=%r8),>F4=%ymm3
# bytes: 5 uops: 1
vmovapd   0(%r8),%ymm3

# qhasm:   F2 aligned= mem256[work1 -  64]
# asm 1: vmovapd   -64(<work1=int64#5),>F2=reg256#5
# asm 2: vmovapd   -64(<work1=%r8),>F2=%ymm4
# bytes: 6 uops: 1
vmovapd   -64(%r8),%ymm4

# qhasm:   F0 aligned= mem256[work1 - 128]
# asm 1: vmovapd   -128(<work1=int64#5),>F0=reg256#6
# asm 2: vmovapd   -128(<work1=%r8),>F0=%ymm5
# bytes: 6 uops: 1
vmovapd   -128(%r8),%ymm5

# qhasm: mainloop:
._mainloop:

# qhasm:                           yxtz0[0,1,2,3] = E0[1,0,3,2]
# asm 1: vpermilpd $0x5,<E0=reg256#3,>yxtz0=reg256#7
# asm 2: vpermilpd $0x5,<E0=%ymm2,>yxtz0=%ymm6
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm2,%ymm6

# qhasm:                           abcd0[0,1,2,3] approx= E0[0]-yxtz0[0],E0[1]+yxtz0[1],E0[2]-yxtz0[2],E0[3]+yxtz0[3]
# asm 1: vaddsubpd <yxtz0=reg256#7,<E0=reg256#3,>abcd0=reg256#3
# asm 2: vaddsubpd <yxtz0=%ymm6,<E0=%ymm2,>abcd0=%ymm2
# bytes: 4 uops: 1
vaddsubpd %ymm6,%ymm2,%ymm2
# block pos: 480 512 uops: 6

# qhasm:                           yxtz2[0,1,2,3] = E2[1,0,3,2]
# asm 1: vpermilpd $0x5,<E2=reg256#2,>yxtz2=reg256#7
# asm 2: vpermilpd $0x5,<E2=%ymm1,>yxtz2=%ymm6
# bytes: 7 uops: 1
.byte 0x3e
vpermilpd $0x5,%ymm1,%ymm6

# qhasm:                           abcd2[0,1,2,3] approx= E2[0]-yxtz2[0],E2[1]+yxtz2[1],E2[2]-yxtz2[2],E2[3]+yxtz2[3]
# asm 1: vaddsubpd <yxtz2=reg256#7,<E2=reg256#2,>abcd2=reg256#2
# asm 2: vaddsubpd <yxtz2=%ymm6,<E2=%ymm1,>abcd2=%ymm1
# bytes: 7 uops: 1
.byte 0x3e
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm6,%ymm1,%ymm1

# qhasm:                           yxtz4[0,1,2,3] = E4[1,0,3,2]
# asm 1: vpermilpd $0x5,<E4=reg256#1,>yxtz4=reg256#7
# asm 2: vpermilpd $0x5,<E4=%ymm0,>yxtz4=%ymm6
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm0,%ymm6

# qhasm:                           abcd4[0,1,2,3] approx= E4[0]-yxtz4[0],E4[1]+yxtz4[1],E4[2]-yxtz4[2],E4[3]+yxtz4[3]
# asm 1: vaddsubpd <yxtz4=reg256#7,<E4=reg256#1,>abcd4=reg256#1
# asm 2: vaddsubpd <yxtz4=%ymm6,<E4=%ymm0,>abcd4=%ymm0
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm6,%ymm0,%ymm0

# qhasm:                           cdab0[0,1,2,3] = abcd0[2,3],abcd0[0,1]
# asm 1: vperm2f128 $0x21,<abcd0=reg256#3,<abcd0=reg256#3,>cdab0=reg256#7
# asm 2: vperm2f128 $0x21,<abcd0=%ymm2,<abcd0=%ymm2,>cdab0=%ymm6
# bytes: 6 uops: 2
vperm2f128 $0x21,%ymm2,%ymm2,%ymm6
# block pos: 512 544 uops: 6

# qhasm:                           badc0[0,1,2,3] = abcd0[1,0,3,2]
# asm 1: vpermilpd $0x5,<abcd0=reg256#3,>badc0=reg256#3
# asm 2: vpermilpd $0x5,<abcd0=%ymm2,>badc0=%ymm2
# bytes: 7 uops: 1
.byte 0x3e
vpermilpd $0x5,%ymm2,%ymm2

# qhasm:                           H0[0,1,2,3] approx= badc0[0]-cdab0[0],badc0[1]+cdab0[1],badc0[2]-cdab0[2],badc0[3]+cdab0[3]
# asm 1: vaddsubpd <cdab0=reg256#7,<badc0=reg256#3,>H0=reg256#3
# asm 2: vaddsubpd <cdab0=%ymm6,<badc0=%ymm2,>H0=%ymm2
# bytes: 7 uops: 1
.byte 0x3e
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm6,%ymm2,%ymm2

# qhasm:                           cdab2[0,1,2,3] = abcd2[2,3],abcd2[0,1]
# asm 1: vperm2f128 $0x21,<abcd2=reg256#2,<abcd2=reg256#2,>cdab2=reg256#7
# asm 2: vperm2f128 $0x21,<abcd2=%ymm1,<abcd2=%ymm1,>cdab2=%ymm6
# bytes: 6 uops: 2
vperm2f128 $0x21,%ymm1,%ymm1,%ymm6

# qhasm:                           badc2[0,1,2,3] = abcd2[1,0,3,2]
# asm 1: vpermilpd $0x5,<abcd2=reg256#2,>badc2=reg256#2
# asm 2: vpermilpd $0x5,<abcd2=%ymm1,>badc2=%ymm1
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm1,%ymm1

# qhasm:                           H2[0,1,2,3] approx= badc2[0]-cdab2[0],badc2[1]+cdab2[1],badc2[2]-cdab2[2],badc2[3]+cdab2[3]
# asm 1: vaddsubpd <cdab2=reg256#7,<badc2=reg256#2,>H2=reg256#2
# asm 2: vaddsubpd <cdab2=%ymm6,<badc2=%ymm1,>H2=%ymm1
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm6,%ymm1,%ymm1
# block pos: 544 576 uops: 6

# qhasm:                           cdab4[0,1,2,3] = abcd4[2,3],abcd4[0,1]
# asm 1: vperm2f128 $0x21,<abcd4=reg256#1,<abcd4=reg256#1,>cdab4=reg256#7
# asm 2: vperm2f128 $0x21,<abcd4=%ymm0,<abcd4=%ymm0,>cdab4=%ymm6
# bytes: 7 uops: 2
.byte 0x3e
vperm2f128 $0x21,%ymm0,%ymm0,%ymm6

# qhasm:                           badc4[0,1,2,3] = abcd4[1,0,3,2]
# asm 1: vpermilpd $0x5,<abcd4=reg256#1,>badc4=reg256#1
# asm 2: vpermilpd $0x5,<abcd4=%ymm0,>badc4=%ymm0
# bytes: 7 uops: 1
.byte 0x3e
vpermilpd $0x5,%ymm0,%ymm0

# qhasm:                           H4[0,1,2,3] approx= badc4[0]-cdab4[0],badc4[1]+cdab4[1],badc4[2]-cdab4[2],badc4[3]+cdab4[3]
# asm 1: vaddsubpd <cdab4=reg256#7,<badc4=reg256#1,>H4=reg256#1
# asm 2: vaddsubpd <cdab4=%ymm6,<badc4=%ymm0,>H4=%ymm0
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm6,%ymm0,%ymm0

# qhasm:   yxtz0[0,1,2,3] = F0[1,0,3,2]
# asm 1: vpermilpd $0x5,<F0=reg256#6,>yxtz0=reg256#7
# asm 2: vpermilpd $0x5,<F0=%ymm5,>yxtz0=%ymm6
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm5,%ymm6

# qhasm:   abcd0[0,1,2,3] approx= F0[0]-yxtz0[0],F0[1]+yxtz0[1],F0[2]-yxtz0[2],F0[3]+yxtz0[3]
# asm 1: vaddsubpd <yxtz0=reg256#7,<F0=reg256#6,>abcd0=reg256#6
# asm 2: vaddsubpd <yxtz0=%ymm6,<F0=%ymm5,>abcd0=%ymm5
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm6,%ymm5,%ymm5
# block pos: 576 608 uops: 6

# qhasm:   cdab0[0,1,2,3] = abcd0[2,3],abcd0[0,1]
# asm 1: vperm2f128 $0x21,<abcd0=reg256#6,<abcd0=reg256#6,>cdab0=reg256#7
# asm 2: vperm2f128 $0x21,<abcd0=%ymm5,<abcd0=%ymm5,>cdab0=%ymm6
# bytes: 7 uops: 2
.byte 0x3e
vperm2f128 $0x21,%ymm5,%ymm5,%ymm6

# qhasm:   badc0[0,1,2,3] = abcd0[1,0,3,2]
# asm 1: vpermilpd $0x5,<abcd0=reg256#6,>badc0=reg256#6
# asm 2: vpermilpd $0x5,<abcd0=%ymm5,>badc0=%ymm5
# bytes: 7 uops: 1
.byte 0x3e
vpermilpd $0x5,%ymm5,%ymm5

# qhasm:   I0[0,1,2,3] approx= badc0[0]-cdab0[0],badc0[1]+cdab0[1],badc0[2]-cdab0[2],badc0[3]+cdab0[3]
# asm 1: vaddsubpd <cdab0=reg256#7,<badc0=reg256#6,>I0=reg256#6
# asm 2: vaddsubpd <cdab0=%ymm6,<badc0=%ymm5,>I0=%ymm5
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm6,%ymm5,%ymm5

# qhasm:                           a22 aligned= mem256[const2 - 128]
# asm 1: vmovapd   -128(<const2=int64#8),>a22=reg256#7
# asm 2: vmovapd   -128(<const2=%r10),>a22=%ymm6
# bytes: 6 uops: 1
vmovapd   -128(%r10),%ymm6

# qhasm:                           4x H1 = approx H0 + a22
# asm 1: vaddpd <H0=reg256#3,<a22=reg256#7,>H1=reg256#8
# asm 2: vaddpd <H0=%ymm2,<a22=%ymm6,>H1=%ymm7
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddpd %ymm2,%ymm6,%ymm7
# block pos: 608 640 uops: 6

# qhasm:                           4x H1 approx-= a22
# asm 1: vsubpd <a22=reg256#7,<H1=reg256#8,>H1=reg256#7
# asm 2: vsubpd <a22=%ymm6,<H1=%ymm7,>H1=%ymm6
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vsubpd %ymm6,%ymm7,%ymm6

# qhasm:                           4x H0 approx-= H1
# asm 1: vsubpd <H1=reg256#7,<H0=reg256#3,>H0=reg256#3
# asm 2: vsubpd <H1=%ymm6,<H0=%ymm2,>H0=%ymm2
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm6,%ymm2,%ymm2

# qhasm:   mem256[work1 + 0] aligned= F4
# asm 1: vmovapd   <F4=reg256#4,0(<work1=int64#5)
# asm 2: vmovapd   <F4=%ymm3,0(<work1=%r8)
# bytes: 5 uops: 1
vmovapd   %ymm3,0(%r8)

# qhasm:                           a64 aligned= mem256[const2 - 64]
# asm 1: vmovapd   -64(<const2=int64#8),>a64=reg256#4
# asm 2: vmovapd   -64(<const2=%r10),>a64=%ymm3
# bytes: 6 uops: 1
vmovapd   -64(%r10),%ymm3

# qhasm:                           4x H3 = approx H2 + a64
# asm 1: vaddpd <H2=reg256#2,<a64=reg256#4,>H3=reg256#8
# asm 2: vaddpd <H2=%ymm1,<a64=%ymm3,>H3=%ymm7
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm1,%ymm3,%ymm7

# qhasm:                           4x H3 approx-= a64
# asm 1: vsubpd <a64=reg256#4,<H3=reg256#8,>H3=reg256#4
# asm 2: vsubpd <a64=%ymm3,<H3=%ymm7,>H3=%ymm3
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm3,%ymm7,%ymm3
# block pos: 640 672 uops: 6

# qhasm:                           4x H2 approx-= H3
# asm 1: vsubpd <H3=reg256#4,<H2=reg256#2,>H2=reg256#2
# asm 2: vsubpd <H3=%ymm3,<H2=%ymm1,>H2=%ymm1
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm3,%ymm1,%ymm1

# qhasm:                           a106 aligned= mem256[const2 + 0]
# asm 1: vmovapd   0(<const2=int64#8),>a106=reg256#8
# asm 2: vmovapd   0(<const2=%r10),>a106=%ymm7
# bytes: 5 uops: 1
vmovapd   0(%r10),%ymm7

# qhasm:                           4x H5 = approx H4 + a106
# asm 1: vaddpd <H4=reg256#1,<a106=reg256#8,>H5=reg256#9
# asm 2: vaddpd <H4=%ymm0,<a106=%ymm7,>H5=%ymm8
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm0,%ymm7,%ymm8

# qhasm:                           4x H5 approx-= a106 *mem256[const1+32]
# asm 1: vfnmadd231pd 32(<const1=int64#7),<a106=reg256#8,<H5=reg256#9
# asm 2: vfnmadd231pd 32(<const1=%rax),<a106=%ymm7,<H5=%ymm8
# bytes: 6 uops: 1
vfnmadd231pd 32(%rax),%ymm7,%ymm8

# qhasm:                           4x H4 approx-= H5
# asm 1: vsubpd <H5=reg256#9,<H4=reg256#1,>H4=reg256#1
# asm 2: vsubpd <H5=%ymm8,<H4=%ymm0,>H4=%ymm0
# bytes: 5 uops: 1
vsubpd %ymm8,%ymm0,%ymm0

# qhasm:   a22 aligned= mem256[const2 - 128]
# asm 1: vmovapd   -128(<const2=int64#8),>a22=reg256#8
# asm 2: vmovapd   -128(<const2=%r10),>a22=%ymm7
# bytes: 6 uops: 1
vmovapd   -128(%r10),%ymm7
# block pos: 672 704 uops: 6

# qhasm:   4x I1 = approx I0 + a22
# asm 1: vaddpd <I0=reg256#6,<a22=reg256#8,>I1=reg256#10
# asm 2: vaddpd <I0=%ymm5,<a22=%ymm7,>I1=%ymm9
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddpd %ymm5,%ymm7,%ymm9

# qhasm:   4x I1 approx-= a22
# asm 1: vsubpd <a22=reg256#8,<I1=reg256#10,>I1=reg256#8
# asm 2: vsubpd <a22=%ymm7,<I1=%ymm9,>I1=%ymm7
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vsubpd %ymm7,%ymm9,%ymm7

# qhasm:   4x I0 approx-= I1
# asm 1: vsubpd <I1=reg256#8,<I0=reg256#6,>I0=reg256#6
# asm 2: vsubpd <I1=%ymm7,<I0=%ymm5,>I0=%ymm5
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm7,%ymm5,%ymm5

# qhasm:                                     4x 127I1 = approx I1 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#7),<I1=reg256#8,>127I1=reg256#10
# asm 2: vmulpd -128(<const1=%rax),<I1=%ymm7,>127I1=%ymm9
# bytes: 5 uops: 1
vmulpd -128(%rax),%ymm7,%ymm9

# qhasm:                                   4x R1 = approx I1 * H0
# asm 1: vmulpd <I1=reg256#8,<H0=reg256#3,>R1=reg256#11
# asm 2: vmulpd <I1=%ymm7,<H0=%ymm2,>R1=%ymm10
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm7,%ymm2,%ymm10

# qhasm:                                 4x R2 = approx I1 * H1
# asm 1: vmulpd <I1=reg256#8,<H1=reg256#7,>R2=reg256#12
# asm 2: vmulpd <I1=%ymm7,<H1=%ymm6,>R2=%ymm11
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm7,%ymm6,%ymm11
# block pos: 704 736 uops: 6

# qhasm:                               4x R3 = approx I1 * H2
# asm 1: vmulpd <I1=reg256#8,<H2=reg256#2,>R3=reg256#13
# asm 2: vmulpd <I1=%ymm7,<H2=%ymm1,>R3=%ymm12
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm7,%ymm1,%ymm12

# qhasm:                             4x R4 = approx I1 * H3
# asm 1: vmulpd <I1=reg256#8,<H3=reg256#4,>R4=reg256#14
# asm 2: vmulpd <I1=%ymm7,<H3=%ymm3,>R4=%ymm13
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm7,%ymm3,%ymm13

# qhasm:                           4x R5 = approx I1 * H4
# asm 1: vmulpd <I1=reg256#8,<H4=reg256#1,>R5=reg256#15
# asm 2: vmulpd <I1=%ymm7,<H4=%ymm0,>R5=%ymm14
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm7,%ymm0,%ymm14

# qhasm:                                     4x R0 = approx 127I1 * H5
# asm 1: vmulpd <127I1=reg256#10,<H5=reg256#9,>R0=reg256#10
# asm 2: vmulpd <127I1=%ymm9,<H5=%ymm8,>R0=%ymm9
# bytes: 5 uops: 1
vmulpd %ymm9,%ymm8,%ymm9

# qhasm:                                 4x R2 approx+= I0 * H2
# asm 1: vfmadd231pd <I0=reg256#6,<H2=reg256#2,<R2=reg256#12
# asm 2: vfmadd231pd <I0=%ymm5,<H2=%ymm1,<R2=%ymm11
# bytes: 5 uops: 1
vfmadd231pd %ymm5,%ymm1,%ymm11

# qhasm:   yxtz2[0,1,2,3] = F2[1,0,3,2]
# asm 1: vpermilpd $0x5,<F2=reg256#5,>yxtz2=reg256#16
# asm 2: vpermilpd $0x5,<F2=%ymm4,>yxtz2=%ymm15
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm4,%ymm15
# block pos: 736 768 uops: 6

# qhasm:   abcd2[0,1,2,3] approx= F2[0]-yxtz2[0],F2[1]+yxtz2[1],F2[2]-yxtz2[2],F2[3]+yxtz2[3]
# asm 1: vaddsubpd <yxtz2=reg256#16,<F2=reg256#5,>abcd2=reg256#5
# asm 2: vaddsubpd <yxtz2=%ymm15,<F2=%ymm4,>abcd2=%ymm4
# bytes: 7 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm15,%ymm4,%ymm4

# qhasm:   cdab2[0,1,2,3] = abcd2[2,3],abcd2[0,1]
# asm 1: vperm2f128 $0x21,<abcd2=reg256#5,<abcd2=reg256#5,>cdab2=reg256#16
# asm 2: vperm2f128 $0x21,<abcd2=%ymm4,<abcd2=%ymm4,>cdab2=%ymm15
# bytes: 7 uops: 2
.byte 0x3e
vperm2f128 $0x21,%ymm4,%ymm4,%ymm15

# qhasm:   badc2[0,1,2,3] = abcd2[1,0,3,2]
# asm 1: vpermilpd $0x5,<abcd2=reg256#5,>badc2=reg256#5
# asm 2: vpermilpd $0x5,<abcd2=%ymm4,>badc2=%ymm4
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm4,%ymm4

# qhasm:   I2[0,1,2,3] approx= badc2[0]-cdab2[0],badc2[1]+cdab2[1],badc2[2]-cdab2[2],badc2[3]+cdab2[3]
# asm 1: vaddsubpd <cdab2=reg256#16,<badc2=reg256#5,>I2=reg256#5
# asm 2: vaddsubpd <cdab2=%ymm15,<badc2=%ymm4,>I2=%ymm4
# bytes: 6 uops: 1
.byte 0x3e
vaddsubpd %ymm15,%ymm4,%ymm4

# qhasm:                               4x R3 approx+= I0 * H3
# asm 1: vfmadd231pd <I0=reg256#6,<H3=reg256#4,<R3=reg256#13
# asm 2: vfmadd231pd <I0=%ymm5,<H3=%ymm3,<R3=%ymm12
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm5,%ymm3,%ymm12
# block pos: 768 800 uops: 5

# qhasm:                             4x R4 approx+= I0 * H4
# asm 1: vfmadd231pd <I0=reg256#6,<H4=reg256#1,<R4=reg256#14
# asm 2: vfmadd231pd <I0=%ymm5,<H4=%ymm0,<R4=%ymm13
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm5,%ymm0,%ymm13

# qhasm:                           4x R5 approx+= I0 * H5
# asm 1: vfmadd231pd <I0=reg256#6,<H5=reg256#9,<R5=reg256#15
# asm 2: vfmadd231pd <I0=%ymm5,<H5=%ymm8,<R5=%ymm14
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm5,%ymm8,%ymm14

# qhasm:                                   4x R1 approx+= I0 * H1
# asm 1: vfmadd231pd <I0=reg256#6,<H1=reg256#7,<R1=reg256#11
# asm 2: vfmadd231pd <I0=%ymm5,<H1=%ymm6,<R1=%ymm10
# bytes: 5 uops: 1
vfmadd231pd %ymm5,%ymm6,%ymm10

# qhasm:                                     4x R0 approx+= I0 * H0
# asm 1: vfmadd231pd <I0=reg256#6,<H0=reg256#3,<R0=reg256#10
# asm 2: vfmadd231pd <I0=%ymm5,<H0=%ymm2,<R0=%ymm9
# bytes: 5 uops: 1
vfmadd231pd %ymm5,%ymm2,%ymm9

# qhasm:   b = b_stack,b_stack,b_stack,b_stack
# asm 1: vbroadcastsd <b_stack=stack64#8,>b=reg256#16
# asm 2: vbroadcastsd <b_stack=824(%rsp),>b=%ymm15
# bytes: 10 uops: 1
vbroadcastsd 824(%rsp),%ymm15
# block pos: 800 832 uops: 6

# qhasm: 	      4x Q1 = I1 if b<0 else H1
# asm 1: vblendvpd <b=reg256#16,<I1=reg256#8,<H1=reg256#7,>Q1=reg256#8
# asm 2: vblendvpd <b=%ymm15,<I1=%ymm7,<H1=%ymm6,>Q1=%ymm7
# bytes: 10 uops: 2
.byte 0x3e
.byte 0x3e
.byte 0x3e
.byte 0x3e
vblendvpd %ymm15,%ymm7,%ymm6,%ymm7

# qhasm:               mem256[work1 - 96] aligned= Q1
# asm 1: vmovapd   <Q1=reg256#8,-96(<work1=int64#5)
# asm 2: vmovapd   <Q1=%ymm7,-96(<work1=%r8)
# bytes: 6 uops: 1
vmovapd   %ymm7,-96(%r8)

# qhasm: 	      4x Q0 = I0 if b<0 else H0
# asm 1: vblendvpd <b=reg256#16,<I0=reg256#6,<H0=reg256#3,>Q0=reg256#6
# asm 2: vblendvpd <b=%ymm15,<I0=%ymm5,<H0=%ymm2,>Q0=%ymm5
# bytes: 10 uops: 2
.byte 0x3e
.byte 0x3e
.byte 0x3e
.byte 0x3e
vblendvpd %ymm15,%ymm5,%ymm2,%ymm5

# qhasm:               mem256[work1 - 128] aligned= Q0
# asm 1: vmovapd   <Q0=reg256#6,-128(<work1=int64#5)
# asm 2: vmovapd   <Q0=%ymm5,-128(<work1=%r8)
# bytes: 6 uops: 1
vmovapd   %ymm5,-128(%r8)
# block pos: 832 864 uops: 6

# qhasm:   a64 aligned= mem256[const2 - 64]
# asm 1: vmovapd   -64(<const2=int64#8),>a64=reg256#6
# asm 2: vmovapd   -64(<const2=%r10),>a64=%ymm5
# bytes: 6 uops: 1
vmovapd   -64(%r10),%ymm5

# qhasm:   4x I3 = approx I2 + a64
# asm 1: vaddpd <I2=reg256#5,<a64=reg256#6,>I3=reg256#8
# asm 2: vaddpd <I2=%ymm4,<a64=%ymm5,>I3=%ymm7
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddpd %ymm4,%ymm5,%ymm7

# qhasm:   4x I3 approx-= a64
# asm 1: vsubpd <a64=reg256#6,<I3=reg256#8,>I3=reg256#6
# asm 2: vsubpd <a64=%ymm5,<I3=%ymm7,>I3=%ymm5
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm5,%ymm7,%ymm5

# qhasm:   4x I2 approx-= I3
# asm 1: vsubpd <I3=reg256#6,<I2=reg256#5,>I2=reg256#5
# asm 2: vsubpd <I3=%ymm5,<I2=%ymm4,>I2=%ymm4
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm5,%ymm4,%ymm4

# qhasm:                                 4x 127I3 = approx I3 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#7),<I3=reg256#6,>127I3=reg256#8
# asm 2: vmulpd -128(<const1=%rax),<I3=%ymm5,>127I3=%ymm7
# bytes: 5 uops: 1
vmulpd -128(%rax),%ymm5,%ymm7

# qhasm:                                   4x 127I2 = approx I2 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#7),<I2=reg256#5,>127I2=reg256#16
# asm 2: vmulpd -128(<const1=%rax),<I2=%ymm4,>127I2=%ymm15
# bytes: 5 uops: 1
vmulpd -128(%rax),%ymm4,%ymm15
# block pos: 864 896 uops: 6

# qhasm:                               4x R3 approx+= I3 * H0
# asm 1: vfmadd231pd <I3=reg256#6,<H0=reg256#3,<R3=reg256#13
# asm 2: vfmadd231pd <I3=%ymm5,<H0=%ymm2,<R3=%ymm12
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm5,%ymm2,%ymm12

# qhasm:                             4x R4 approx+= I3 * H1
# asm 1: vfmadd231pd <I3=reg256#6,<H1=reg256#7,<R4=reg256#14
# asm 2: vfmadd231pd <I3=%ymm5,<H1=%ymm6,<R4=%ymm13
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm5,%ymm6,%ymm13

# qhasm:                           4x R5 approx+= I3 * H2
# asm 1: vfmadd231pd <I3=reg256#6,<H2=reg256#2,<R5=reg256#15
# asm 2: vfmadd231pd <I3=%ymm5,<H2=%ymm1,<R5=%ymm14
# bytes: 5 uops: 1
vfmadd231pd %ymm5,%ymm1,%ymm14

# qhasm:                                 4x R2 approx+= 127I3 * H5
# asm 1: vfmadd231pd <127I3=reg256#8,<H5=reg256#9,<R2=reg256#12
# asm 2: vfmadd231pd <127I3=%ymm7,<H5=%ymm8,<R2=%ymm11
# bytes: 5 uops: 1
vfmadd231pd %ymm7,%ymm8,%ymm11

# qhasm:                                   4x R1 approx+= 127I3 * H4
# asm 1: vfmadd231pd <127I3=reg256#8,<H4=reg256#1,<R1=reg256#11
# asm 2: vfmadd231pd <127I3=%ymm7,<H4=%ymm0,<R1=%ymm10
# bytes: 5 uops: 1
vfmadd231pd %ymm7,%ymm0,%ymm10

# qhasm:                                     4x R0 approx+= 127I3 * H3
# asm 1: vfmadd231pd <127I3=reg256#8,<H3=reg256#4,<R0=reg256#10
# asm 2: vfmadd231pd <127I3=%ymm7,<H3=%ymm3,<R0=%ymm9
# bytes: 5 uops: 1
vfmadd231pd %ymm7,%ymm3,%ymm9
# block pos: 896 928 uops: 6

# qhasm:                           4x R5 approx+= I2 * H3
# asm 1: vfmadd231pd <I2=reg256#5,<H3=reg256#4,<R5=reg256#15
# asm 2: vfmadd231pd <I2=%ymm4,<H3=%ymm3,<R5=%ymm14
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm4,%ymm3,%ymm14

# qhasm:                             4x R4 approx+= I2 * H2
# asm 1: vfmadd231pd <I2=reg256#5,<H2=reg256#2,<R4=reg256#14
# asm 2: vfmadd231pd <I2=%ymm4,<H2=%ymm1,<R4=%ymm13
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm4,%ymm1,%ymm13

# qhasm:                               4x R3 approx+= I2 * H1
# asm 1: vfmadd231pd <I2=reg256#5,<H1=reg256#7,<R3=reg256#13
# asm 2: vfmadd231pd <I2=%ymm4,<H1=%ymm6,<R3=%ymm12
# bytes: 5 uops: 1
vfmadd231pd %ymm4,%ymm6,%ymm12

# qhasm:                                 4x R2 approx+= I2 * H0
# asm 1: vfmadd231pd <I2=reg256#5,<H0=reg256#3,<R2=reg256#12
# asm 2: vfmadd231pd <I2=%ymm4,<H0=%ymm2,<R2=%ymm11
# bytes: 5 uops: 1
vfmadd231pd %ymm4,%ymm2,%ymm11

# qhasm:                                   4x R1 approx+= 127I2 * H5
# asm 1: vfmadd231pd <127I2=reg256#16,<H5=reg256#9,<R1=reg256#11
# asm 2: vfmadd231pd <127I2=%ymm15,<H5=%ymm8,<R1=%ymm10
# bytes: 5 uops: 1
vfmadd231pd %ymm15,%ymm8,%ymm10

# qhasm:                                     4x R0 approx+= 127I2 * H4
# asm 1: vfmadd231pd <127I2=reg256#16,<H4=reg256#1,<R0=reg256#10
# asm 2: vfmadd231pd <127I2=%ymm15,<H4=%ymm0,<R0=%ymm9
# bytes: 5 uops: 1
vfmadd231pd %ymm15,%ymm0,%ymm9
# block pos: 928 960 uops: 6

# qhasm:   b = b_stack,b_stack,b_stack,b_stack
# asm 1: vbroadcastsd <b_stack=stack64#8,>b=reg256#8
# asm 2: vbroadcastsd <b_stack=824(%rsp),>b=%ymm7
# bytes: 10 uops: 1
vbroadcastsd 824(%rsp),%ymm7

# qhasm: 	      4x Q3 = I3 if b<0 else H3
# asm 1: vblendvpd <b=reg256#8,<I3=reg256#6,<H3=reg256#4,>Q3=reg256#6
# asm 2: vblendvpd <b=%ymm7,<I3=%ymm5,<H3=%ymm3,>Q3=%ymm5
# bytes: 8 uops: 2
.byte 0x3e
.byte 0x3e
vblendvpd %ymm7,%ymm5,%ymm3,%ymm5

# qhasm:               mem256[work1 - 32] aligned= Q3
# asm 1: vmovapd   <Q3=reg256#6,-32(<work1=int64#5)
# asm 2: vmovapd   <Q3=%ymm5,-32(<work1=%r8)
# bytes: 6 uops: 1
vmovapd   %ymm5,-32(%r8)

# qhasm: 	      4x Q2 = I2 if b<0 else H2
# asm 1: vblendvpd <b=reg256#8,<I2=reg256#5,<H2=reg256#2,>Q2=reg256#5
# asm 2: vblendvpd <b=%ymm7,<I2=%ymm4,<H2=%ymm1,>Q2=%ymm4
# bytes: 8 uops: 2
.byte 0x3e
.byte 0x3e
vblendvpd %ymm7,%ymm4,%ymm1,%ymm4
# block pos: 960 992 uops: 6

# qhasm:               mem256[work1 - 64] aligned= Q2
# asm 1: vmovapd   <Q2=reg256#5,-64(<work1=int64#5)
# asm 2: vmovapd   <Q2=%ymm4,-64(<work1=%r8)
# bytes: 6 uops: 1
vmovapd   %ymm4,-64(%r8)

# qhasm:   F4 aligned= mem256[work1 + 0]
# asm 1: vmovapd   0(<work1=int64#5),>F4=reg256#5
# asm 2: vmovapd   0(<work1=%r8),>F4=%ymm4
# bytes: 5 uops: 1
vmovapd   0(%r8),%ymm4

# qhasm:   yxtz4[0,1,2,3] = F4[1,0,3,2]
# asm 1: vpermilpd $0x5,<F4=reg256#5,>yxtz4=reg256#6
# asm 2: vpermilpd $0x5,<F4=%ymm4,>yxtz4=%ymm5
# bytes: 7 uops: 1
.byte 0x3e
vpermilpd $0x5,%ymm4,%ymm5

# qhasm:   abcd4[0,1,2,3] approx= F4[0]-yxtz4[0],F4[1]+yxtz4[1],F4[2]-yxtz4[2],F4[3]+yxtz4[3]
# asm 1: vaddsubpd <yxtz4=reg256#6,<F4=reg256#5,>abcd4=reg256#5
# asm 2: vaddsubpd <yxtz4=%ymm5,<F4=%ymm4,>abcd4=%ymm4
# bytes: 7 uops: 1
.byte 0x3e
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm5,%ymm4,%ymm4

# qhasm:   cdab4[0,1,2,3] = abcd4[2,3],abcd4[0,1]
# asm 1: vperm2f128 $0x21,<abcd4=reg256#5,<abcd4=reg256#5,>cdab4=reg256#6
# asm 2: vperm2f128 $0x21,<abcd4=%ymm4,<abcd4=%ymm4,>cdab4=%ymm5
# bytes: 7 uops: 2
.byte 0x3e
vperm2f128 $0x21,%ymm4,%ymm4,%ymm5
# block pos: 992 1024 uops: 6

# qhasm:   badc4[0,1,2,3] = abcd4[1,0,3,2]
# asm 1: vpermilpd $0x5,<abcd4=reg256#5,>badc4=reg256#5
# asm 2: vpermilpd $0x5,<abcd4=%ymm4,>badc4=%ymm4
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm4,%ymm4

# qhasm:   I4[0,1,2,3] approx= badc4[0]-cdab4[0],badc4[1]+cdab4[1],badc4[2]-cdab4[2],badc4[3]+cdab4[3]
# asm 1: vaddsubpd <cdab4=reg256#6,<badc4=reg256#5,>I4=reg256#5
# asm 2: vaddsubpd <cdab4=%ymm5,<badc4=%ymm4,>I4=%ymm4
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm5,%ymm4,%ymm4

# qhasm:   a106 aligned= mem256[const2 + 0]
# asm 1: vmovapd   0(<const2=int64#8),>a106=reg256#6
# asm 2: vmovapd   0(<const2=%r10),>a106=%ymm5
# bytes: 5 uops: 1
vmovapd   0(%r10),%ymm5

# qhasm:   4x I5 = approx I4 + a106
# asm 1: vaddpd <I4=reg256#5,<a106=reg256#6,>I5=reg256#8
# asm 2: vaddpd <I4=%ymm4,<a106=%ymm5,>I5=%ymm7
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm4,%ymm5,%ymm7

# qhasm:   4x I5 approx-= a106
# asm 1: vsubpd <a106=reg256#6,<I5=reg256#8,>I5=reg256#6
# asm 2: vsubpd <a106=%ymm5,<I5=%ymm7,>I5=%ymm5
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm5,%ymm7,%ymm5

# qhasm:   4x I4 approx-= I5
# asm 1: vsubpd <I5=reg256#6,<I4=reg256#5,>I4=reg256#5
# asm 2: vsubpd <I5=%ymm5,<I4=%ymm4,>I4=%ymm4
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm5,%ymm4,%ymm4
# block pos: 1024 1056 uops: 6

# qhasm:                             4x 127I5 = approx I5 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#7),<I5=reg256#6,>127I5=reg256#8
# asm 2: vmulpd -128(<const1=%rax),<I5=%ymm5,>127I5=%ymm7
# bytes: 5 uops: 1
vmulpd -128(%rax),%ymm5,%ymm7

# qhasm:                               4x 127I4 = approx I4 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#7),<I4=reg256#5,>127I4=reg256#16
# asm 2: vmulpd -128(<const1=%rax),<I4=%ymm4,>127I4=%ymm15
# bytes: 5 uops: 1
vmulpd -128(%rax),%ymm4,%ymm15

# qhasm:                           4x R5 approx+= I5 * H0
# asm 1: vfmadd231pd <I5=reg256#6,<H0=reg256#3,<R5=reg256#15
# asm 2: vfmadd231pd <I5=%ymm5,<H0=%ymm2,<R5=%ymm14
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm5,%ymm2,%ymm14

# qhasm:                             4x R4 approx+= 127I5 * H5
# asm 1: vfmadd231pd <127I5=reg256#8,<H5=reg256#9,<R4=reg256#14
# asm 2: vfmadd231pd <127I5=%ymm7,<H5=%ymm8,<R4=%ymm13
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm7,%ymm8,%ymm13

# qhasm:                               4x R3 approx+= 127I5 * H4
# asm 1: vfmadd231pd <127I5=reg256#8,<H4=reg256#1,<R3=reg256#13
# asm 2: vfmadd231pd <127I5=%ymm7,<H4=%ymm0,<R3=%ymm12
# bytes: 5 uops: 1
vfmadd231pd %ymm7,%ymm0,%ymm12

# qhasm:                                 4x R2 approx+= 127I5 * H3
# asm 1: vfmadd231pd <127I5=reg256#8,<H3=reg256#4,<R2=reg256#12
# asm 2: vfmadd231pd <127I5=%ymm7,<H3=%ymm3,<R2=%ymm11
# bytes: 5 uops: 1
vfmadd231pd %ymm7,%ymm3,%ymm11
# block pos: 1056 1088 uops: 6

# qhasm:                                   4x R1 approx+= 127I5 * H2
# asm 1: vfmadd231pd <127I5=reg256#8,<H2=reg256#2,<R1=reg256#11
# asm 2: vfmadd231pd <127I5=%ymm7,<H2=%ymm1,<R1=%ymm10
# bytes: 5 uops: 1
vfmadd231pd %ymm7,%ymm1,%ymm10

# qhasm:                                     4x R0 approx+= 127I5 * H1
# asm 1: vfmadd231pd <127I5=reg256#8,<H1=reg256#7,<R0=reg256#10
# asm 2: vfmadd231pd <127I5=%ymm7,<H1=%ymm6,<R0=%ymm9
# bytes: 5 uops: 1
vfmadd231pd %ymm7,%ymm6,%ymm9

# qhasm:   b = b_stack,b_stack,b_stack,b_stack
# asm 1: vbroadcastsd <b_stack=stack64#8,>b=reg256#8
# asm 2: vbroadcastsd <b_stack=824(%rsp),>b=%ymm7
# bytes: 10 uops: 1
vbroadcastsd 824(%rsp),%ymm7

# qhasm: 	      4x Q5 = I5 if b<0 else H5
# asm 1: vblendvpd <b=reg256#8,<I5=reg256#6,<H5=reg256#9,>Q5=reg256#6
# asm 2: vblendvpd <b=%ymm7,<I5=%ymm5,<H5=%ymm8,>Q5=%ymm5
# bytes: 6 uops: 2
vblendvpd %ymm7,%ymm5,%ymm8,%ymm5

# qhasm:               mem256[work1 + 32] aligned= Q5
# asm 1: vmovapd   <Q5=reg256#6,32(<work1=int64#5)
# asm 2: vmovapd   <Q5=%ymm5,32(<work1=%r8)
# bytes: 6 uops: 1
vmovapd   %ymm5,32(%r8)
# block pos: 1088 1120 uops: 6

# qhasm: 	      4x Q4 = I4 if b<0 else H4
# asm 1: vblendvpd <b=reg256#8,<I4=reg256#5,<H4=reg256#1,>Q4=reg256#6
# asm 2: vblendvpd <b=%ymm7,<I4=%ymm4,<H4=%ymm0,>Q4=%ymm5
# bytes: 8 uops: 2
.byte 0x3e
.byte 0x3e
vblendvpd %ymm7,%ymm4,%ymm0,%ymm5

# qhasm:               mem256[work1 + 0] aligned= Q4
# asm 1: vmovapd   <Q4=reg256#6,0(<work1=int64#5)
# asm 2: vmovapd   <Q4=%ymm5,0(<work1=%r8)
# bytes: 5 uops: 1
vmovapd   %ymm5,0(%r8)

# qhasm:                           4x R5 approx+= I4 * H1
# asm 1: vfmadd231pd <I4=reg256#5,<H1=reg256#7,<R5=reg256#15
# asm 2: vfmadd231pd <I4=%ymm4,<H1=%ymm6,<R5=%ymm14
# bytes: 7 uops: 1
.byte 0x3e
.byte 0x3e
vfmadd231pd %ymm4,%ymm6,%ymm14

# qhasm:                                       4x c5 = approx R5 + mem256[const2 + 32]
# asm 1: vaddpd 32(<const2=int64#8),<R5=reg256#15,>c5=reg256#6
# asm 2: vaddpd 32(<const2=%r10),<R5=%ymm14,>c5=%ymm5
# bytes: 6 uops: 1
vaddpd 32(%r10),%ymm14,%ymm5

# qhasm:                                       4x c5 approx-= mem256[const2 + 32]
# asm 1: vsubpd 32(<const2=int64#8),<c5=reg256#6,>c5=reg256#6
# asm 2: vsubpd 32(<const2=%r10),<c5=%ymm5,>c5=%ymm5
# bytes: 6 uops: 1
vsubpd 32(%r10),%ymm5,%ymm5
# block pos: 1120 1152 uops: 6

# qhasm: 			    4x R4 approx+= I4 * H0
# asm 1: vfmadd231pd <I4=reg256#5,<H0=reg256#3,<R4=reg256#14
# asm 2: vfmadd231pd <I4=%ymm4,<H0=%ymm2,<R4=%ymm13
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm4,%ymm2,%ymm13

# qhasm:                                       4x c4 = approx R4 + mem256[const2 + 0]
# asm 1: vaddpd 0(<const2=int64#8),<R4=reg256#14,>c4=reg256#3
# asm 2: vaddpd 0(<const2=%r10),<R4=%ymm13,>c4=%ymm2
# bytes: 5 uops: 1
vaddpd 0(%r10),%ymm13,%ymm2

# qhasm:                                       4x c4 approx-= mem256[const2 + 0]
# asm 1: vsubpd 0(<const2=int64#8),<c4=reg256#3,>c4=reg256#3
# asm 2: vsubpd 0(<const2=%r10),<c4=%ymm2,>c4=%ymm2
# bytes: 5 uops: 1
vsubpd 0(%r10),%ymm2,%ymm2

# qhasm:                               4x R3 approx+= 127I4 * H5
# asm 1: vfmadd231pd <127I4=reg256#16,<H5=reg256#9,<R3=reg256#13
# asm 2: vfmadd231pd <127I4=%ymm15,<H5=%ymm8,<R3=%ymm12
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm15,%ymm8,%ymm12

# qhasm:                                 4x R2 approx+= 127I4 * H4
# asm 1: vfmadd231pd <127I4=reg256#16,<H4=reg256#1,<R2=reg256#12
# asm 2: vfmadd231pd <127I4=%ymm15,<H4=%ymm0,<R2=%ymm11
# bytes: 5 uops: 1
vfmadd231pd %ymm15,%ymm0,%ymm11

# qhasm:                                   4x R1 approx+= 127I4 * H3
# asm 1: vfmadd231pd <127I4=reg256#16,<H3=reg256#4,<R1=reg256#11
# asm 2: vfmadd231pd <127I4=%ymm15,<H3=%ymm3,<R1=%ymm10
# bytes: 5 uops: 1
vfmadd231pd %ymm15,%ymm3,%ymm10
# block pos: 1152 1184 uops: 6

# qhasm:                                     4x R0 approx+= 127I4 * H2
# asm 1: vfmadd231pd <127I4=reg256#16,<H2=reg256#2,<R0=reg256#10
# asm 2: vfmadd231pd <127I4=%ymm15,<H2=%ymm1,<R0=%ymm9
# bytes: 5 uops: 1
vfmadd231pd %ymm15,%ymm1,%ymm9

# qhasm:                                       4x R5 approx-= c5
# asm 1: vsubpd <c5=reg256#6,<R5=reg256#15,>R5=reg256#1
# asm 2: vsubpd <c5=%ymm5,<R5=%ymm14,>R5=%ymm0
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm5,%ymm14,%ymm0

# qhasm:                                       4x R0 approx+= c5 * mem256[const1 - 128]
# asm 1: vfmadd231pd -128(<const1=int64#7),<c5=reg256#6,<R0=reg256#10
# asm 2: vfmadd231pd -128(<const1=%rax),<c5=%ymm5,<R0=%ymm9
# bytes: 6 uops: 1
vfmadd231pd -128(%rax),%ymm5,%ymm9

# qhasm:                                       4x R5 approx+= c4
# asm 1: vaddpd <c4=reg256#3,<R5=reg256#1,>R5=reg256#1
# asm 2: vaddpd <c4=%ymm2,<R5=%ymm0,>R5=%ymm0
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm2,%ymm0,%ymm0

# qhasm:                                       4x R4 approx-= c4
# asm 1: vsubpd <c4=reg256#3,<R4=reg256#14,>R4=reg256#2
# asm 2: vsubpd <c4=%ymm2,<R4=%ymm13,>R4=%ymm1
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm2,%ymm13,%ymm1

# qhasm:                                       4x c3 = approx R3 + mem256[const2 - 32]
# asm 1: vaddpd -32(<const2=int64#8),<R3=reg256#13,>c3=reg256#3
# asm 2: vaddpd -32(<const2=%r10),<R3=%ymm12,>c3=%ymm2
# bytes: 6 uops: 1
vaddpd -32(%r10),%ymm12,%ymm2
# block pos: 1184 1216 uops: 6

# qhasm:                                       4x c3 approx-= mem256[const2 - 32]
# asm 1: vsubpd -32(<const2=int64#8),<c3=reg256#3,>c3=reg256#3
# asm 2: vsubpd -32(<const2=%r10),<c3=%ymm2,>c3=%ymm2
# bytes: 6 uops: 1
vsubpd -32(%r10),%ymm2,%ymm2

# qhasm:                                       4x R4 approx+= c3
# asm 1: vaddpd <c3=reg256#3,<R4=reg256#2,>R4=reg256#2
# asm 2: vaddpd <c3=%ymm2,<R4=%ymm1,>R4=%ymm1
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddpd %ymm2,%ymm1,%ymm1

# qhasm:                                       4x R3 approx-= c3
# asm 1: vsubpd <c3=reg256#3,<R3=reg256#13,>R3=reg256#3
# asm 2: vsubpd <c3=%ymm2,<R3=%ymm12,>R3=%ymm2
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm2,%ymm12,%ymm2

# qhasm:   Q0 aligned= mem256[work1 - 128]
# asm 1: vmovapd   -128(<work1=int64#5),>Q0=reg256#4
# asm 2: vmovapd   -128(<work1=%r8),>Q0=%ymm3
# bytes: 6 uops: 1
vmovapd   -128(%r8),%ymm3

# qhasm:     4x 2Q0 = approx Q0 * mem256[const1 + 0]
# asm 1: vmulpd 0(<const1=int64#7),<Q0=reg256#4,>2Q0=reg256#5
# asm 2: vmulpd 0(<const1=%rax),<Q0=%ymm3,>2Q0=%ymm4
# bytes: 4 uops: 1
vmulpd 0(%rax),%ymm3,%ymm4

# qhasm:       4x S0 =approx Q0 * Q0
# asm 1: vmulpd <Q0=reg256#4,<Q0=reg256#4,>S0=reg256#4
# asm 2: vmulpd <Q0=%ymm3,<Q0=%ymm3,>S0=%ymm3
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm3,%ymm3,%ymm3
# block pos: 1216 1248 uops: 6

# qhasm:                                       4x c2 = approx R2 + mem256[const2 - 64]
# asm 1: vaddpd -64(<const2=int64#8),<R2=reg256#12,>c2=reg256#6
# asm 2: vaddpd -64(<const2=%r10),<R2=%ymm11,>c2=%ymm5
# bytes: 6 uops: 1
vaddpd -64(%r10),%ymm11,%ymm5

# qhasm:                                       4x c2 approx-= mem256[const2 - 64]
# asm 1: vsubpd -64(<const2=int64#8),<c2=reg256#6,>c2=reg256#6
# asm 2: vsubpd -64(<const2=%r10),<c2=%ymm5,>c2=%ymm5
# bytes: 6 uops: 1
vsubpd -64(%r10),%ymm5,%ymm5

# qhasm:                                       4x R3 approx+= c2
# asm 1: vaddpd <c2=reg256#6,<R3=reg256#3,>R3=reg256#3
# asm 2: vaddpd <c2=%ymm5,<R3=%ymm2,>R3=%ymm2
# bytes: 4 uops: 1
vaddpd %ymm5,%ymm2,%ymm2

# qhasm:                                       4x R2 approx-= c2
# asm 1: vsubpd <c2=reg256#6,<R2=reg256#12,>R2=reg256#6
# asm 2: vsubpd <c2=%ymm5,<R2=%ymm11,>R2=%ymm5
# bytes: 4 uops: 1
vsubpd %ymm5,%ymm11,%ymm5

# qhasm:                                       4x c1 = approx R1 + mem256[const2 - 96]
# asm 1: vaddpd -96(<const2=int64#8),<R1=reg256#11,>c1=reg256#7
# asm 2: vaddpd -96(<const2=%r10),<R1=%ymm10,>c1=%ymm6
# bytes: 6 uops: 1
vaddpd -96(%r10),%ymm10,%ymm6

# qhasm:                                       4x c1 approx-= mem256[const2 - 96]
# asm 1: vsubpd -96(<const2=int64#8),<c1=reg256#7,>c1=reg256#7
# asm 2: vsubpd -96(<const2=%r10),<c1=%ymm6,>c1=%ymm6
# bytes: 6 uops: 1
vsubpd -96(%r10),%ymm6,%ymm6
# block pos: 1248 1280 uops: 6

# qhasm:                                       4x R2 approx+= c1
# asm 1: vaddpd <c1=reg256#7,<R2=reg256#6,>R2=reg256#6
# asm 2: vaddpd <c1=%ymm6,<R2=%ymm5,>R2=%ymm5
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddpd %ymm6,%ymm5,%ymm5

# qhasm:                                       4x R1 approx-= c1
# asm 1: vsubpd <c1=reg256#7,<R1=reg256#11,>R1=reg256#7
# asm 2: vsubpd <c1=%ymm6,<R1=%ymm10,>R1=%ymm6
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vsubpd %ymm6,%ymm10,%ymm6

# qhasm:   Q1 aligned= mem256[work1 - 96]
# asm 1: vmovapd   -96(<work1=int64#5),>Q1=reg256#8
# asm 2: vmovapd   -96(<work1=%r8),>Q1=%ymm7
# bytes: 6 uops: 1
vmovapd   -96(%r8),%ymm7

# qhasm:     4x 2Q1 = approx Q1 * mem256[const1 + 0]
# asm 1: vmulpd 0(<const1=int64#7),<Q1=reg256#8,>2Q1=reg256#9
# asm 2: vmulpd 0(<const1=%rax),<Q1=%ymm7,>2Q1=%ymm8
# bytes: 4 uops: 1
vmulpd 0(%rax),%ymm7,%ymm8

# qhasm:       4x S2 =approx Q1 * Q1
# asm 1: vmulpd <Q1=reg256#8,<Q1=reg256#8,>S2=reg256#11
# asm 2: vmulpd <Q1=%ymm7,<Q1=%ymm7,>S2=%ymm10
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm7,%ymm7,%ymm10

# qhasm:       4x S1 =approx 2Q0 * Q1
# asm 1: vmulpd <2Q0=reg256#5,<Q1=reg256#8,>S1=reg256#8
# asm 2: vmulpd <2Q0=%ymm4,<Q1=%ymm7,>S1=%ymm7
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm4,%ymm7,%ymm7
# block pos: 1280 1312 uops: 6

# qhasm:                                       a22 aligned= mem256[const2 - 128]
# asm 1: vmovapd   -128(<const2=int64#8),>a22=reg256#12
# asm 2: vmovapd   -128(<const2=%r10),>a22=%ymm11
# bytes: 6 uops: 1
vmovapd   -128(%r10),%ymm11

# qhasm:                                       4x c0 = approx R0 + a22
# asm 1: vaddpd <R0=reg256#10,<a22=reg256#12,>c0=reg256#13
# asm 2: vaddpd <R0=%ymm9,<a22=%ymm11,>c0=%ymm12
# bytes: 5 uops: 1
vaddpd %ymm9,%ymm11,%ymm12

# qhasm:                                       4x c0 approx-= a22
# asm 1: vsubpd <a22=reg256#12,<c0=reg256#13,>c0=reg256#12
# asm 2: vsubpd <a22=%ymm11,<c0=%ymm12,>c0=%ymm11
# bytes: 5 uops: 1
vsubpd %ymm11,%ymm12,%ymm11

# qhasm:                                       4x R1 approx+= c0
# asm 1: vaddpd <c0=reg256#12,<R1=reg256#7,>R1=reg256#7
# asm 2: vaddpd <c0=%ymm11,<R1=%ymm6,>R1=%ymm6
# bytes: 5 uops: 1
vaddpd %ymm11,%ymm6,%ymm6

# qhasm:                                       4x R0 approx-= c0
# asm 1: vsubpd <c0=reg256#12,<R0=reg256#10,>R0=reg256#10
# asm 2: vsubpd <c0=%ymm11,<R0=%ymm9,>R0=%ymm9
# bytes: 5 uops: 1
vsubpd %ymm11,%ymm9,%ymm9

# qhasm:   Q2 aligned= mem256[work1 - 64]
# asm 1: vmovapd   -64(<work1=int64#5),>Q2=reg256#12
# asm 2: vmovapd   -64(<work1=%r8),>Q2=%ymm11
# bytes: 6 uops: 1
vmovapd   -64(%r8),%ymm11
# block pos: 1312 1344 uops: 6

# qhasm:       4x S4 =approx Q2 * Q2
# asm 1: vmulpd <Q2=reg256#12,<Q2=reg256#12,>S4=reg256#13
# asm 2: vmulpd <Q2=%ymm11,<Q2=%ymm11,>S4=%ymm12
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm11,%ymm11,%ymm12

# qhasm:       4x S3 =approx 2Q1 * Q2
# asm 1: vmulpd <2Q1=reg256#9,<Q2=reg256#12,>S3=reg256#14
# asm 2: vmulpd <2Q1=%ymm8,<Q2=%ymm11,>S3=%ymm13
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm8,%ymm11,%ymm13

# qhasm:       4x S2 approx+= 2Q0 * Q2
# asm 1: vfmadd231pd <2Q0=reg256#5,<Q2=reg256#12,<S2=reg256#11
# asm 2: vfmadd231pd <2Q0=%ymm4,<Q2=%ymm11,<S2=%ymm10
# bytes: 5 uops: 1
vfmadd231pd %ymm4,%ymm11,%ymm10

# qhasm:     4x 2Q2 = approx Q2 * mem256[const1 + 0]
# asm 1: vmulpd 0(<const1=int64#7),<Q2=reg256#12,>2Q2=reg256#12
# asm 2: vmulpd 0(<const1=%rax),<Q2=%ymm11,>2Q2=%ymm11
# bytes: 4 uops: 1
vmulpd 0(%rax),%ymm11,%ymm11

# qhasm:                           abcd aligned= mem256[const2 + 96]
# asm 1: vmovapd   96(<const2=int64#8),>abcd=reg256#15
# asm 2: vmovapd   96(<const2=%r10),>abcd=%ymm14
# bytes: 6 uops: 1
vmovapd   96(%r10),%ymm14

# qhasm:                           4x R5 = approx R5 * abcd
# asm 1: vmulpd <R5=reg256#1,<abcd=reg256#15,>R5=reg256#1
# asm 2: vmulpd <R5=%ymm0,<abcd=%ymm14,>R5=%ymm0
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm0,%ymm14,%ymm0
# block pos: 1344 1376 uops: 6

# qhasm:                           4x R4 = approx R4 * abcd
# asm 1: vmulpd <R4=reg256#2,<abcd=reg256#15,>R4=reg256#2
# asm 2: vmulpd <R4=%ymm1,<abcd=%ymm14,>R4=%ymm1
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm1,%ymm14,%ymm1

# qhasm:                           4x R3 = approx R3 * abcd
# asm 1: vmulpd <R3=reg256#3,<abcd=reg256#15,>R3=reg256#3
# asm 2: vmulpd <R3=%ymm2,<abcd=%ymm14,>R3=%ymm2
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm2,%ymm14,%ymm2

# qhasm:                           4x R2 = approx R2 * abcd
# asm 1: vmulpd <R2=reg256#6,<abcd=reg256#15,>R2=reg256#6
# asm 2: vmulpd <R2=%ymm5,<abcd=%ymm14,>R2=%ymm5
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm5,%ymm14,%ymm5

# qhasm:                           4x R1 = approx R1 * abcd
# asm 1: vmulpd <R1=reg256#7,<abcd=reg256#15,>R1=reg256#7
# asm 2: vmulpd <R1=%ymm6,<abcd=%ymm14,>R1=%ymm6
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm6,%ymm14,%ymm6

# qhasm:                           4x R0 = approx R0 * abcd
# asm 1: vmulpd <R0=reg256#10,<abcd=reg256#15,>R0=reg256#10
# asm 2: vmulpd <R0=%ymm9,<abcd=%ymm14,>R0=%ymm9
# bytes: 5 uops: 1
vmulpd %ymm9,%ymm14,%ymm9

# qhasm:                           a127 aligned= mem256[const2 + 32]
# asm 1: vmovapd   32(<const2=int64#8),>a127=reg256#15
# asm 2: vmovapd   32(<const2=%r10),>a127=%ymm14
# bytes: 6 uops: 1
vmovapd   32(%r10),%ymm14
# block pos: 1376 1408 uops: 6

# qhasm:                           4x c5 = approx R5 + a127
# asm 1: vaddpd <R5=reg256#1,<a127=reg256#15,>c5=reg256#16
# asm 2: vaddpd <R5=%ymm0,<a127=%ymm14,>c5=%ymm15
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm0,%ymm14,%ymm15

# qhasm:                           4x c5 approx-= a127
# asm 1: vsubpd <a127=reg256#15,<c5=reg256#16,>c5=reg256#15
# asm 2: vsubpd <a127=%ymm14,<c5=%ymm15,>c5=%ymm14
# bytes: 5 uops: 1
vsubpd %ymm14,%ymm15,%ymm14

# qhasm:                           4x R5 approx-= c5
# asm 1: vsubpd <c5=reg256#15,<R5=reg256#1,>R5=reg256#1
# asm 2: vsubpd <c5=%ymm14,<R5=%ymm0,>R5=%ymm0
# bytes: 5 uops: 1
vsubpd %ymm14,%ymm0,%ymm0

# qhasm:                           4x R0 approx+= c5 * mem256[const1 - 128]
# asm 1: vfmadd231pd -128(<const1=int64#7),<c5=reg256#15,<R0=reg256#10
# asm 2: vfmadd231pd -128(<const1=%rax),<c5=%ymm14,<R0=%ymm9
# bytes: 6 uops: 1
vfmadd231pd -128(%rax),%ymm14,%ymm9

# qhasm:                           4x R4 approx+= R5
# asm 1: vaddpd <R5=reg256#1,<R4=reg256#2,>R4=reg256#1
# asm 2: vaddpd <R5=%ymm0,<R4=%ymm1,>R4=%ymm0
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm0,%ymm1,%ymm0

# qhasm:                           a85 aligned= mem256[const2 - 32]
# asm 1: vmovapd   -32(<const2=int64#8),>a85=reg256#2
# asm 2: vmovapd   -32(<const2=%r10),>a85=%ymm1
# bytes: 6 uops: 1
vmovapd   -32(%r10),%ymm1
# block pos: 1408 1440 uops: 6

# qhasm:                           4x c3 = approx R3 + a85
# asm 1: vaddpd <R3=reg256#3,<a85=reg256#2,>c3=reg256#15
# asm 2: vaddpd <R3=%ymm2,<a85=%ymm1,>c3=%ymm14
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddpd %ymm2,%ymm1,%ymm14

# qhasm:                           4x c3 approx-= a85
# asm 1: vsubpd <a85=reg256#2,<c3=reg256#15,>c3=reg256#2
# asm 2: vsubpd <a85=%ymm1,<c3=%ymm14,>c3=%ymm1
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm1,%ymm14,%ymm1

# qhasm:                           4x R4 approx+= c3
# asm 1: vaddpd <c3=reg256#2,<R4=reg256#1,>R4=reg256#1
# asm 2: vaddpd <c3=%ymm1,<R4=%ymm0,>R4=%ymm0
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm1,%ymm0,%ymm0

# qhasm: 			  4x R3 approx-= c3
# asm 1: vsubpd <c3=reg256#2,<R3=reg256#3,>R3=reg256#2
# asm 2: vsubpd <c3=%ymm1,<R3=%ymm2,>R3=%ymm1
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm1,%ymm2,%ymm1

# qhasm:                           4x R2 approx+= R3
# asm 1: vaddpd <R3=reg256#2,<R2=reg256#6,>R2=reg256#2
# asm 2: vaddpd <R3=%ymm1,<R2=%ymm5,>R2=%ymm1
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm1,%ymm5,%ymm1

# qhasm:                           a43 aligned= mem256[const2 - 96]
# asm 1: vmovapd   -96(<const2=int64#8),>a43=reg256#3
# asm 2: vmovapd   -96(<const2=%r10),>a43=%ymm2
# bytes: 6 uops: 1
vmovapd   -96(%r10),%ymm2
# block pos: 1440 1472 uops: 6

# qhasm:                           4x c1 = approx R1 + a43
# asm 1: vaddpd <R1=reg256#7,<a43=reg256#3,>c1=reg256#6
# asm 2: vaddpd <R1=%ymm6,<a43=%ymm2,>c1=%ymm5
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddpd %ymm6,%ymm2,%ymm5

# qhasm:                           4x c1 approx-= a43
# asm 1: vsubpd <a43=reg256#3,<c1=reg256#6,>c1=reg256#3
# asm 2: vsubpd <a43=%ymm2,<c1=%ymm5,>c1=%ymm2
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm2,%ymm5,%ymm2

# qhasm:                           4x R2 approx+= c1
# asm 1: vaddpd <c1=reg256#3,<R2=reg256#2,>R2=reg256#2
# asm 2: vaddpd <c1=%ymm2,<R2=%ymm1,>R2=%ymm1
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm2,%ymm1,%ymm1

# qhasm: 			  4x R1 approx-= c1
# asm 1: vsubpd <c1=reg256#3,<R1=reg256#7,>R1=reg256#3
# asm 2: vsubpd <c1=%ymm2,<R1=%ymm6,>R1=%ymm2
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm2,%ymm6,%ymm2

# qhasm:                           4x R0 approx+= R1
# asm 1: vaddpd <R1=reg256#3,<R0=reg256#10,>R0=reg256#3
# asm 2: vaddpd <R1=%ymm2,<R0=%ymm9,>R0=%ymm2
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm2,%ymm9,%ymm2

# qhasm:   Q3 aligned= mem256[work1 - 32]
# asm 1: vmovapd   -32(<work1=int64#5),>Q3=reg256#6
# asm 2: vmovapd   -32(<work1=%r8),>Q3=%ymm5
# bytes: 6 uops: 1
vmovapd   -32(%r8),%ymm5
# block pos: 1472 1504 uops: 6

# qhasm:       4x S5 = approx 2Q2 * Q3
# asm 1: vmulpd <2Q2=reg256#12,<Q3=reg256#6,>S5=reg256#7
# asm 2: vmulpd <2Q2=%ymm11,<Q3=%ymm5,>S5=%ymm6
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm11,%ymm5,%ymm6

# qhasm:       4x S4 approx+= 2Q1 * Q3
# asm 1: vfmadd231pd <2Q1=reg256#9,<Q3=reg256#6,<S4=reg256#13
# asm 2: vfmadd231pd <2Q1=%ymm8,<Q3=%ymm5,<S4=%ymm12
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm8,%ymm5,%ymm12

# qhasm:       4x S3 approx+= 2Q0 * Q3
# asm 1: vfmadd231pd <2Q0=reg256#5,<Q3=reg256#6,<S3=reg256#14
# asm 2: vfmadd231pd <2Q0=%ymm4,<Q3=%ymm5,<S3=%ymm13
# bytes: 5 uops: 1
vfmadd231pd %ymm4,%ymm5,%ymm13

# qhasm:       4x Q3Q3 = approx Q3 * Q3
# asm 1: vmulpd <Q3=reg256#6,<Q3=reg256#6,>Q3Q3=reg256#10
# asm 2: vmulpd <Q3=%ymm5,<Q3=%ymm5,>Q3Q3=%ymm9
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm5,%ymm5,%ymm9

# qhasm:       4x S0 approx+= Q3Q3 * mem256[const1 - 128]
# asm 1: vfmadd231pd -128(<const1=int64#7),<Q3Q3=reg256#10,<S0=reg256#4
# asm 2: vfmadd231pd -128(<const1=%rax),<Q3Q3=%ymm9,<S0=%ymm3
# bytes: 6 uops: 1
vfmadd231pd -128(%rax),%ymm9,%ymm3

# qhasm:     4x 2Q3 = approx Q3 * mem256[const1 + 0]
# asm 1: vmulpd 0(<const1=int64#7),<Q3=reg256#6,>2Q3=reg256#6
# asm 2: vmulpd 0(<const1=%rax),<Q3=%ymm5,>2Q3=%ymm5
# bytes: 4 uops: 1
vmulpd 0(%rax),%ymm5,%ymm5
# block pos: 1504 1536 uops: 6

# qhasm:   Q4 aligned= mem256[work1 + 0]
# asm 1: vmovapd   0(<work1=int64#5),>Q4=reg256#10
# asm 2: vmovapd   0(<work1=%r8),>Q4=%ymm9
# bytes: 5 uops: 1
vmovapd   0(%r8),%ymm9

# qhasm:       4x S5 approx+= 2Q1 * Q4
# asm 1: vfmadd231pd <2Q1=reg256#9,<Q4=reg256#10,<S5=reg256#7
# asm 2: vfmadd231pd <2Q1=%ymm8,<Q4=%ymm9,<S5=%ymm6
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm8,%ymm9,%ymm6

# qhasm:       4x S4 approx+= 2Q0 * Q4
# asm 1: vfmadd231pd <2Q0=reg256#5,<Q4=reg256#10,<S4=reg256#13
# asm 2: vfmadd231pd <2Q0=%ymm4,<Q4=%ymm9,<S4=%ymm12
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm4,%ymm9,%ymm12

# qhasm:     4x 127Q4 = approx Q4 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#7),<Q4=reg256#10,>127Q4=reg256#15
# asm 2: vmulpd -128(<const1=%rax),<Q4=%ymm9,>127Q4=%ymm14
# bytes: 5 uops: 1
vmulpd -128(%rax),%ymm9,%ymm14

# qhasm:       4x S2 approx+= Q4 * 127Q4
# asm 1: vfmadd231pd <Q4=reg256#10,<127Q4=reg256#15,<S2=reg256#11
# asm 2: vfmadd231pd <Q4=%ymm9,<127Q4=%ymm14,<S2=%ymm10
# bytes: 5 uops: 1
vfmadd231pd %ymm9,%ymm14,%ymm10

# qhasm:       4x S1 approx+= 2Q3 * 127Q4
# asm 1: vfmadd231pd <2Q3=reg256#6,<127Q4=reg256#15,<S1=reg256#8
# asm 2: vfmadd231pd <2Q3=%ymm5,<127Q4=%ymm14,<S1=%ymm7
# bytes: 5 uops: 1
vfmadd231pd %ymm5,%ymm14,%ymm7
# block pos: 1536 1568 uops: 6

# qhasm:       4x S0 approx+= 2Q2 * 127Q4
# asm 1: vfmadd231pd <2Q2=reg256#12,<127Q4=reg256#15,<S0=reg256#4
# asm 2: vfmadd231pd <2Q2=%ymm11,<127Q4=%ymm14,<S0=%ymm3
# bytes: 7 uops: 1
.byte 0x3e
.byte 0x3e
vfmadd231pd %ymm11,%ymm14,%ymm3

# qhasm:     4x 2Q4 = approx Q4 * mem256[const1 + 0]
# asm 1: vmulpd 0(<const1=int64#7),<Q4=reg256#10,>2Q4=reg256#10
# asm 2: vmulpd 0(<const1=%rax),<Q4=%ymm9,>2Q4=%ymm9
# bytes: 4 uops: 1
vmulpd 0(%rax),%ymm9,%ymm9

# qhasm:                           yxtz4[0,1,2,3] = R4[1,0,3,2]
# asm 1: vpermilpd $0x5,<R4=reg256#1,>yxtz4=reg256#15
# asm 2: vpermilpd $0x5,<R4=%ymm0,>yxtz4=%ymm14
# bytes: 7 uops: 1
.byte 0x3e
vpermilpd $0x5,%ymm0,%ymm14

# qhasm:                           abcd4[0,1,2,3] approx= R4[0]-yxtz4[0],R4[1]+yxtz4[1],R4[2]-yxtz4[2],R4[3]+yxtz4[3]
# asm 1: vaddsubpd <yxtz4=reg256#15,<R4=reg256#1,>abcd4=reg256#1
# asm 2: vaddsubpd <yxtz4=%ymm14,<R4=%ymm0,>abcd4=%ymm0
# bytes: 7 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm14,%ymm0,%ymm0

# qhasm:                           cdab4[0,1,2,3] = abcd4[2,3],abcd4[0,1]
# asm 1: vperm2f128 $0x21,<abcd4=reg256#1,<abcd4=reg256#1,>cdab4=reg256#15
# asm 2: vperm2f128 $0x21,<abcd4=%ymm0,<abcd4=%ymm0,>cdab4=%ymm14
# bytes: 7 uops: 2
.byte 0x3e
vperm2f128 $0x21,%ymm0,%ymm0,%ymm14
# block pos: 1568 1600 uops: 6

# qhasm:                           badc4[0,1,2,3] = abcd4[1,0,3,2]
# asm 1: vpermilpd $0x5,<abcd4=reg256#1,>badc4=reg256#1
# asm 2: vpermilpd $0x5,<abcd4=%ymm0,>badc4=%ymm0
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm0,%ymm0

# qhasm:                           A4[0,1,2,3] approx= badc4[0]-cdab4[0],badc4[1]+cdab4[1],badc4[2]-cdab4[2],badc4[3]+cdab4[3]
# asm 1: vaddsubpd <cdab4=reg256#15,<badc4=reg256#1,>A4=reg256#1
# asm 2: vaddsubpd <cdab4=%ymm14,<badc4=%ymm0,>A4=%ymm0
# bytes: 5 uops: 1
vaddsubpd %ymm14,%ymm0,%ymm0

# qhasm:   Q5 aligned= mem256[work1 + 32]
# asm 1: vmovapd   32(<work1=int64#5),>Q5=reg256#15
# asm 2: vmovapd   32(<work1=%r8),>Q5=%ymm14
# bytes: 6 uops: 1
vmovapd   32(%r8),%ymm14

# qhasm:       4x S5 approx+= 2Q0 * Q5
# asm 1: vfmadd231pd <2Q0=reg256#5,<Q5=reg256#15,<S5=reg256#7
# asm 2: vfmadd231pd <2Q0=%ymm4,<Q5=%ymm14,<S5=%ymm6
# bytes: 5 uops: 1
vfmadd231pd %ymm4,%ymm14,%ymm6

# qhasm:     4x 127Q5 = approx Q5 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#7),<Q5=reg256#15,>127Q5=reg256#5
# asm 2: vmulpd -128(<const1=%rax),<Q5=%ymm14,>127Q5=%ymm4
# bytes: 5 uops: 1
vmulpd -128(%rax),%ymm14,%ymm4

# qhasm:       4x S4 approx+= Q5 * 127Q5
# asm 1: vfmadd231pd <Q5=reg256#15,<127Q5=reg256#5,<S4=reg256#13
# asm 2: vfmadd231pd <Q5=%ymm14,<127Q5=%ymm4,<S4=%ymm12
# bytes: 5 uops: 1
vfmadd231pd %ymm14,%ymm4,%ymm12
# block pos: 1600 1632 uops: 6

# qhasm:       4x S3 approx+= 2Q4 * 127Q5
# asm 1: vfmadd231pd <2Q4=reg256#10,<127Q5=reg256#5,<S3=reg256#14
# asm 2: vfmadd231pd <2Q4=%ymm9,<127Q5=%ymm4,<S3=%ymm13
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm9,%ymm4,%ymm13

# qhasm:       4x S2 approx+= 2Q3 * 127Q5
# asm 1: vfmadd231pd <2Q3=reg256#6,<127Q5=reg256#5,<S2=reg256#11
# asm 2: vfmadd231pd <2Q3=%ymm5,<127Q5=%ymm4,<S2=%ymm10
# bytes: 5 uops: 1
vfmadd231pd %ymm5,%ymm4,%ymm10

# qhasm:       4x S1 approx+= 2Q2 * 127Q5
# asm 1: vfmadd231pd <2Q2=reg256#12,<127Q5=reg256#5,<S1=reg256#8
# asm 2: vfmadd231pd <2Q2=%ymm11,<127Q5=%ymm4,<S1=%ymm7
# bytes: 5 uops: 1
vfmadd231pd %ymm11,%ymm4,%ymm7

# qhasm:       4x S0 approx+= 2Q1 * 127Q5
# asm 1: vfmadd231pd <2Q1=reg256#9,<127Q5=reg256#5,<S0=reg256#4
# asm 2: vfmadd231pd <2Q1=%ymm8,<127Q5=%ymm4,<S0=%ymm3
# bytes: 5 uops: 1
vfmadd231pd %ymm8,%ymm4,%ymm3

# qhasm:                           yxtz2[0,1,2,3] = R2[1,0,3,2]
# asm 1: vpermilpd $0x5,<R2=reg256#2,>yxtz2=reg256#5
# asm 2: vpermilpd $0x5,<R2=%ymm1,>yxtz2=%ymm4
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm1,%ymm4

# qhasm:                           abcd2[0,1,2,3] approx= R2[0]-yxtz2[0],R2[1]+yxtz2[1],R2[2]-yxtz2[2],R2[3]+yxtz2[3]
# asm 1: vaddsubpd <yxtz2=reg256#5,<R2=reg256#2,>abcd2=reg256#2
# asm 2: vaddsubpd <yxtz2=%ymm4,<R2=%ymm1,>abcd2=%ymm1
# bytes: 5 uops: 1
.byte 0x3e
vaddsubpd %ymm4,%ymm1,%ymm1
# block pos: 1632 1664 uops: 6

# qhasm:                           cdab2[0,1,2,3] = abcd2[2,3],abcd2[0,1]
# asm 1: vperm2f128 $0x21,<abcd2=reg256#2,<abcd2=reg256#2,>cdab2=reg256#5
# asm 2: vperm2f128 $0x21,<abcd2=%ymm1,<abcd2=%ymm1,>cdab2=%ymm4
# bytes: 7 uops: 2
.byte 0x3e
vperm2f128 $0x21,%ymm1,%ymm1,%ymm4

# qhasm:                           badc2[0,1,2,3] = abcd2[1,0,3,2]
# asm 1: vpermilpd $0x5,<abcd2=reg256#2,>badc2=reg256#2
# asm 2: vpermilpd $0x5,<abcd2=%ymm1,>badc2=%ymm1
# bytes: 7 uops: 1
.byte 0x3e
vpermilpd $0x5,%ymm1,%ymm1

# qhasm:                           A2[0,1,2,3] approx= badc2[0]-cdab2[0],badc2[1]+cdab2[1],badc2[2]-cdab2[2],badc2[3]+cdab2[3]
# asm 1: vaddsubpd <cdab2=reg256#5,<badc2=reg256#2,>A2=reg256#2
# asm 2: vaddsubpd <cdab2=%ymm4,<badc2=%ymm1,>A2=%ymm1
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm4,%ymm1,%ymm1

# qhasm:   a127 aligned= mem256[const2 + 32]
# asm 1: vmovapd   32(<const2=int64#8),>a127=reg256#5
# asm 2: vmovapd   32(<const2=%r10),>a127=%ymm4
# bytes: 6 uops: 1
vmovapd   32(%r10),%ymm4

# qhasm:   4x c5 = approx S5 + a127
# asm 1: vaddpd <S5=reg256#7,<a127=reg256#5,>c5=reg256#6
# asm 2: vaddpd <S5=%ymm6,<a127=%ymm4,>c5=%ymm5
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddpd %ymm6,%ymm4,%ymm5
# block pos: 1664 1696 uops: 5

# qhasm:   4x c5 approx-= a127 *mem256[const1+32]
# asm 1: vfnmadd231pd 32(<const1=int64#7),<a127=reg256#5,<c5=reg256#6
# asm 2: vfnmadd231pd 32(<const1=%rax),<a127=%ymm4,<c5=%ymm5
# bytes: 6 uops: 1
vfnmadd231pd 32(%rax),%ymm4,%ymm5

# qhasm:   4x S5 approx-= c5 * mem256[const1+32]
# asm 1: vfnmadd231pd 32(<const1=int64#7),<c5=reg256#6,<S5=reg256#7
# asm 2: vfnmadd231pd 32(<const1=%rax),<c5=%ymm5,<S5=%ymm6
# bytes: 6 uops: 1
vfnmadd231pd 32(%rax),%ymm5,%ymm6

# qhasm:   4x S0 approx+= c5 * mem256[const1 - 128]
# asm 1: vfmadd231pd -128(<const1=int64#7),<c5=reg256#6,<S0=reg256#4
# asm 2: vfmadd231pd -128(<const1=%rax),<c5=%ymm5,<S0=%ymm3
# bytes: 6 uops: 1
vfmadd231pd -128(%rax),%ymm5,%ymm3

# qhasm:                           yxtz0[0,1,2,3] = R0[1,0,3,2]
# asm 1: vpermilpd $0x5,<R0=reg256#3,>yxtz0=reg256#5
# asm 2: vpermilpd $0x5,<R0=%ymm2,>yxtz0=%ymm4
# bytes: 7 uops: 1
.byte 0x3e
vpermilpd $0x5,%ymm2,%ymm4

# qhasm:                           abcd0[0,1,2,3] approx= R0[0]-yxtz0[0],R0[1]+yxtz0[1],R0[2]-yxtz0[2],R0[3]+yxtz0[3]
# asm 1: vaddsubpd <yxtz0=reg256#5,<R0=reg256#3,>abcd0=reg256#3
# asm 2: vaddsubpd <yxtz0=%ymm4,<R0=%ymm2,>abcd0=%ymm2
# bytes: 7 uops: 1
.byte 0x3e
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm4,%ymm2,%ymm2
# block pos: 1696 1728 uops: 6

# qhasm:                           cdab0[0,1,2,3] = abcd0[2,3],abcd0[0,1]
# asm 1: vperm2f128 $0x21,<abcd0=reg256#3,<abcd0=reg256#3,>cdab0=reg256#5
# asm 2: vperm2f128 $0x21,<abcd0=%ymm2,<abcd0=%ymm2,>cdab0=%ymm4
# bytes: 7 uops: 2
.byte 0x3e
vperm2f128 $0x21,%ymm2,%ymm2,%ymm4

# qhasm:                           badc0[0,1,2,3] = abcd0[1,0,3,2]
# asm 1: vpermilpd $0x5,<abcd0=reg256#3,>badc0=reg256#3
# asm 2: vpermilpd $0x5,<abcd0=%ymm2,>badc0=%ymm2
# bytes: 7 uops: 1
.byte 0x3e
vpermilpd $0x5,%ymm2,%ymm2

# qhasm:                           A0[0,1,2,3] approx= badc0[0]-cdab0[0],badc0[1]+cdab0[1],badc0[2]-cdab0[2],badc0[3]+cdab0[3]
# asm 1: vaddsubpd <cdab0=reg256#5,<badc0=reg256#3,>A0=reg256#3
# asm 2: vaddsubpd <cdab0=%ymm4,<badc0=%ymm2,>A0=%ymm2
# bytes: 7 uops: 1
.byte 0x3e
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm4,%ymm2,%ymm2

# qhasm:   a106 aligned= mem256[const2 + 0]
# asm 1: vmovapd   0(<const2=int64#8),>a106=reg256#5
# asm 2: vmovapd   0(<const2=%r10),>a106=%ymm4
# bytes: 5 uops: 1
vmovapd   0(%r10),%ymm4

# qhasm:   4x c4 = approx S4 + a106
# asm 1: vaddpd <S4=reg256#13,<a106=reg256#5,>c4=reg256#6
# asm 2: vaddpd <S4=%ymm12,<a106=%ymm4,>c4=%ymm5
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm12,%ymm4,%ymm5
# block pos: 1728 1763 uops: 6

# qhasm:   4x c4 approx-= a106 *mem256[const1+32]
# asm 1: vfnmadd231pd 32(<const1=int64#7),<a106=reg256#5,<c4=reg256#6
# asm 2: vfnmadd231pd 32(<const1=%rax),<a106=%ymm4,<c4=%ymm5
# bytes: 6 uops: 1
vfnmadd231pd 32(%rax),%ymm4,%ymm5

# qhasm:   4x S5 approx+= c4 * mem256[const1 + 32]
# asm 1: vfmadd231pd 32(<const1=int64#7),<c4=reg256#6,<S5=reg256#7
# asm 2: vfmadd231pd 32(<const1=%rax),<c4=%ymm5,<S5=%ymm6
# bytes: 6 uops: 1
vfmadd231pd 32(%rax),%ymm5,%ymm6

# qhasm:   4x S4 approx-= c4 * mem256[const1 + 32]
# asm 1: vfnmadd231pd 32(<const1=int64#7),<c4=reg256#6,<S4=reg256#13
# asm 2: vfnmadd231pd 32(<const1=%rax),<c4=%ymm5,<S4=%ymm12
# bytes: 6 uops: 1
vfnmadd231pd 32(%rax),%ymm5,%ymm12

# qhasm:   a85 aligned= mem256[const2 - 32]
# asm 1: vmovapd   -32(<const2=int64#8),>a85=reg256#5
# asm 2: vmovapd   -32(<const2=%r10),>a85=%ymm4
# bytes: 6 uops: 1
vmovapd   -32(%r10),%ymm4

# qhasm:   4x c3 = approx S3 + a85
# asm 1: vaddpd <S3=reg256#14,<a85=reg256#5,>c3=reg256#6
# asm 2: vaddpd <S3=%ymm13,<a85=%ymm4,>c3=%ymm5
# bytes: 5 uops: 1
vaddpd %ymm13,%ymm4,%ymm5

# qhasm:   4x c3 approx-= a85 *mem256[const1+32]
# asm 1: vfnmadd231pd 32(<const1=int64#7),<a85=reg256#5,<c3=reg256#6
# asm 2: vfnmadd231pd 32(<const1=%rax),<a85=%ymm4,<c3=%ymm5
# bytes: 6 uops: 1
vfnmadd231pd 32(%rax),%ymm4,%ymm5
# block pos: 1763 1796 uops: 6

# qhasm:   4x S4 approx+= c3
# asm 1: vaddpd <c3=reg256#6,<S4=reg256#13,>S4=reg256#5
# asm 2: vaddpd <c3=%ymm5,<S4=%ymm12,>S4=%ymm4
# bytes: 4 uops: 1
vaddpd %ymm5,%ymm12,%ymm4

# qhasm:   4x S3 approx-= c3 * mem256[const1 + 32]
# asm 1: vfnmadd231pd 32(<const1=int64#7),<c3=reg256#6,<S3=reg256#14
# asm 2: vfnmadd231pd 32(<const1=%rax),<c3=%ymm5,<S3=%ymm13
# bytes: 6 uops: 1
vfnmadd231pd 32(%rax),%ymm5,%ymm13

# qhasm:   a64 aligned= mem256[const2 - 64]
# asm 1: vmovapd   -64(<const2=int64#8),>a64=reg256#6
# asm 2: vmovapd   -64(<const2=%r10),>a64=%ymm5
# bytes: 6 uops: 1
vmovapd   -64(%r10),%ymm5

# qhasm:   4x c2 = approx S2 + a64
# asm 1: vaddpd <S2=reg256#11,<a64=reg256#6,>c2=reg256#9
# asm 2: vaddpd <S2=%ymm10,<a64=%ymm5,>c2=%ymm8
# bytes: 5 uops: 1
vaddpd %ymm10,%ymm5,%ymm8

# qhasm:   4x c2 approx-= a64 *mem256[const1+32]
# asm 1: vfnmadd231pd 32(<const1=int64#7),<a64=reg256#6,<c2=reg256#9
# asm 2: vfnmadd231pd 32(<const1=%rax),<a64=%ymm5,<c2=%ymm8
# bytes: 6 uops: 1
vfnmadd231pd 32(%rax),%ymm5,%ymm8

# qhasm:   4x S3 approx+= c2 * mem256[const1 + 32]
# asm 1: vfmadd231pd 32(<const1=int64#7),<c2=reg256#9,<S3=reg256#14
# asm 2: vfmadd231pd 32(<const1=%rax),<c2=%ymm8,<S3=%ymm13
# bytes: 6 uops: 1
vfmadd231pd 32(%rax),%ymm8,%ymm13
# block pos: 1796 1826 uops: 6

# qhasm:   4x S2 approx-= c2 * mem256[const1 + 32]
# asm 1: vfnmadd231pd 32(<const1=int64#7),<c2=reg256#9,<S2=reg256#11
# asm 2: vfnmadd231pd 32(<const1=%rax),<c2=%ymm8,<S2=%ymm10
# bytes: 6 uops: 1
vfnmadd231pd 32(%rax),%ymm8,%ymm10

# qhasm:   a43 aligned= mem256[const2 - 96]
# asm 1: vmovapd   -96(<const2=int64#8),>a43=reg256#6
# asm 2: vmovapd   -96(<const2=%r10),>a43=%ymm5
# bytes: 6 uops: 1
vmovapd   -96(%r10),%ymm5

# qhasm:   4x c1 = approx S1 + a43
# asm 1: vaddpd <S1=reg256#8,<a43=reg256#6,>c1=reg256#9
# asm 2: vaddpd <S1=%ymm7,<a43=%ymm5,>c1=%ymm8
# bytes: 4 uops: 1
vaddpd %ymm7,%ymm5,%ymm8

# qhasm:   4x c1 approx-= a43
# asm 1: vsubpd <a43=reg256#6,<c1=reg256#9,>c1=reg256#6
# asm 2: vsubpd <a43=%ymm5,<c1=%ymm8,>c1=%ymm5
# bytes: 4 uops: 1
vsubpd %ymm5,%ymm8,%ymm5

# qhasm:   4x S2 approx+= c1
# asm 1: vaddpd <c1=reg256#6,<S2=reg256#11,>S2=reg256#9
# asm 2: vaddpd <c1=%ymm5,<S2=%ymm10,>S2=%ymm8
# bytes: 4 uops: 1
vaddpd %ymm5,%ymm10,%ymm8

# qhasm:   4x S1 approx-= c1 * mem256[const1 + 32]
# asm 1: vfnmadd231pd 32(<const1=int64#7),<c1=reg256#6,<S1=reg256#8
# asm 2: vfnmadd231pd 32(<const1=%rax),<c1=%ymm5,<S1=%ymm7
# bytes: 6 uops: 1
vfnmadd231pd 32(%rax),%ymm5,%ymm7
# block pos: 1826 1856 uops: 6

# qhasm:   a22 aligned= mem256[const2 - 128]
# asm 1: vmovapd   -128(<const2=int64#8),>a22=reg256#6
# asm 2: vmovapd   -128(<const2=%r10),>a22=%ymm5
# bytes: 6 uops: 1
vmovapd   -128(%r10),%ymm5

# qhasm:   4x c0 = approx S0 + a22
# asm 1: vaddpd <S0=reg256#4,<a22=reg256#6,>c0=reg256#10
# asm 2: vaddpd <S0=%ymm3,<a22=%ymm5,>c0=%ymm9
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm3,%ymm5,%ymm9

# qhasm:   4x c0 approx-= a22
# asm 1: vsubpd <a22=reg256#6,<c0=reg256#10,>c0=reg256#6
# asm 2: vsubpd <a22=%ymm5,<c0=%ymm9,>c0=%ymm5
# bytes: 4 uops: 1
vsubpd %ymm5,%ymm9,%ymm5

# qhasm:   4x S1 approx+= c0
# asm 1: vaddpd <c0=reg256#6,<S1=reg256#8,>S1=reg256#8
# asm 2: vaddpd <c0=%ymm5,<S1=%ymm7,>S1=%ymm7
# bytes: 4 uops: 1
vaddpd %ymm5,%ymm7,%ymm7

# qhasm:   4x S0 approx-= c0 * mem256[const1 + 32]
# asm 1: vfnmadd231pd 32(<const1=int64#7),<c0=reg256#6,<S0=reg256#4
# asm 2: vfnmadd231pd 32(<const1=%rax),<c0=%ymm5,<S0=%ymm3
# bytes: 6 uops: 1
vfnmadd231pd 32(%rax),%ymm5,%ymm3

# qhasm:                           a106 aligned= mem256[const2 + 0]
# asm 1: vmovapd   0(<const2=int64#8),>a106=reg256#6
# asm 2: vmovapd   0(<const2=%r10),>a106=%ymm5
# bytes: 5 uops: 1
vmovapd   0(%r10),%ymm5
# block pos: 1856 1888 uops: 6

# qhasm:                           4x A5 = approx A4 + a106
# asm 1: vaddpd <A4=reg256#1,<a106=reg256#6,>A5=reg256#10
# asm 2: vaddpd <A4=%ymm0,<a106=%ymm5,>A5=%ymm9
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddpd %ymm0,%ymm5,%ymm9

# qhasm:                           4x A5 approx-= a106
# asm 1: vsubpd <a106=reg256#6,<A5=reg256#10,>A5=reg256#6
# asm 2: vsubpd <a106=%ymm5,<A5=%ymm9,>A5=%ymm5
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm5,%ymm9,%ymm5

# qhasm:                           4x A4 approx-= A5
# asm 1: vsubpd <A5=reg256#6,<A4=reg256#1,>A4=reg256#1
# asm 2: vsubpd <A5=%ymm5,<A4=%ymm0,>A4=%ymm0
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm5,%ymm0,%ymm0

# qhasm:                           a64 aligned= mem256[const2 - 64]
# asm 1: vmovapd   -64(<const2=int64#8),>a64=reg256#10
# asm 2: vmovapd   -64(<const2=%r10),>a64=%ymm9
# bytes: 6 uops: 1
vmovapd   -64(%r10),%ymm9

# qhasm:                           4x A3 = approx A2 + a64
# asm 1: vaddpd <A2=reg256#2,<a64=reg256#10,>A3=reg256#11
# asm 2: vaddpd <A2=%ymm1,<a64=%ymm9,>A3=%ymm10
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm1,%ymm9,%ymm10

# qhasm:                           4x A3 approx-= a64
# asm 1: vsubpd <a64=reg256#10,<A3=reg256#11,>A3=reg256#10
# asm 2: vsubpd <a64=%ymm9,<A3=%ymm10,>A3=%ymm9
# bytes: 5 uops: 1
vsubpd %ymm9,%ymm10,%ymm9
# block pos: 1888 1920 uops: 6

# qhasm:                           4x A2 approx-= A3
# asm 1: vsubpd <A3=reg256#10,<A2=reg256#2,>A2=reg256#2
# asm 2: vsubpd <A3=%ymm9,<A2=%ymm1,>A2=%ymm1
# bytes: 5 uops: 1
vsubpd %ymm9,%ymm1,%ymm1

# qhasm:                           a22 aligned= mem256[const2 - 128]
# asm 1: vmovapd   -128(<const2=int64#8),>a22=reg256#11
# asm 2: vmovapd   -128(<const2=%r10),>a22=%ymm10
# bytes: 6 uops: 1
vmovapd   -128(%r10),%ymm10

# qhasm:                           4x A1 = approx A0 + a22
# asm 1: vaddpd <A0=reg256#3,<a22=reg256#11,>A1=reg256#12
# asm 2: vaddpd <A0=%ymm2,<a22=%ymm10,>A1=%ymm11
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm2,%ymm10,%ymm11

# qhasm:                           4x A1 approx-= a22
# asm 1: vsubpd <a22=reg256#11,<A1=reg256#12,>A1=reg256#11
# asm 2: vsubpd <a22=%ymm10,<A1=%ymm11,>A1=%ymm10
# bytes: 5 uops: 1
vsubpd %ymm10,%ymm11,%ymm10

# qhasm:                           4x A0 approx-= A1
# asm 1: vsubpd <A1=reg256#11,<A0=reg256#3,>A0=reg256#3
# asm 2: vsubpd <A1=%ymm10,<A0=%ymm2,>A0=%ymm2
# bytes: 5 uops: 1
vsubpd %ymm10,%ymm2,%ymm2

# qhasm:   abcd aligned= mem256[const2 + 96]
# asm 1: vmovapd   96(<const2=int64#8),>abcd=reg256#12
# asm 2: vmovapd   96(<const2=%r10),>abcd=%ymm11
# bytes: 6 uops: 1
vmovapd   96(%r10),%ymm11
# block pos: 1920 1952 uops: 6

# qhasm:   4x S5 = approx S5 * abcd
# asm 1: vmulpd <S5=reg256#7,<abcd=reg256#12,>S5=reg256#7
# asm 2: vmulpd <S5=%ymm6,<abcd=%ymm11,>S5=%ymm6
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm6,%ymm11,%ymm6

# qhasm:   4x S3 = approx S3 * abcd
# asm 1: vmulpd <S3=reg256#14,<abcd=reg256#12,>S3=reg256#13
# asm 2: vmulpd <S3=%ymm13,<abcd=%ymm11,>S3=%ymm12
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm13,%ymm11,%ymm12

# qhasm:   4x S1 = approx S1 * abcd
# asm 1: vmulpd <S1=reg256#8,<abcd=reg256#12,>S1=reg256#8
# asm 2: vmulpd <S1=%ymm7,<abcd=%ymm11,>S1=%ymm7
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm7,%ymm11,%ymm7

# qhasm:   4x S4 = approx S4 * abcd
# asm 1: vmulpd <S4=reg256#5,<abcd=reg256#12,>S4=reg256#5
# asm 2: vmulpd <S4=%ymm4,<abcd=%ymm11,>S4=%ymm4
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm4,%ymm11,%ymm4

# qhasm:   4x S2 = approx S2 * abcd
# asm 1: vmulpd <S2=reg256#9,<abcd=reg256#12,>S2=reg256#9
# asm 2: vmulpd <S2=%ymm8,<abcd=%ymm11,>S2=%ymm8
# bytes: 5 uops: 1
vmulpd %ymm8,%ymm11,%ymm8

# qhasm:   4x S0 = approx S0 * abcd
# asm 1: vmulpd <S0=reg256#4,<abcd=reg256#12,>S0=reg256#4
# asm 2: vmulpd <S0=%ymm3,<abcd=%ymm11,>S0=%ymm3
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm3,%ymm11,%ymm3
# block pos: 1952 1984 uops: 6

# qhasm:   a127 aligned= mem256[const2 + 32]
# asm 1: vmovapd   32(<const2=int64#8),>a127=reg256#12
# asm 2: vmovapd   32(<const2=%r10),>a127=%ymm11
# bytes: 6 uops: 1
vmovapd   32(%r10),%ymm11

# qhasm:   4x c5 = approx S5 + a127
# asm 1: vaddpd <S5=reg256#7,<a127=reg256#12,>c5=reg256#14
# asm 2: vaddpd <S5=%ymm6,<a127=%ymm11,>c5=%ymm13
# bytes: 4 uops: 1
vaddpd %ymm6,%ymm11,%ymm13

# qhasm:   4x c5 approx-= a127
# asm 1: vsubpd <a127=reg256#12,<c5=reg256#14,>c5=reg256#12
# asm 2: vsubpd <a127=%ymm11,<c5=%ymm13,>c5=%ymm11
# bytes: 5 uops: 1
vsubpd %ymm11,%ymm13,%ymm11

# qhasm:   4x S5 approx-= c5
# asm 1: vsubpd <c5=reg256#12,<S5=reg256#7,>S5=reg256#7
# asm 2: vsubpd <c5=%ymm11,<S5=%ymm6,>S5=%ymm6
# bytes: 5 uops: 1
vsubpd %ymm11,%ymm6,%ymm6

# qhasm:   4x S0 approx+= c5 * mem256[const1 - 128]
# asm 1: vfmadd231pd -128(<const1=int64#7),<c5=reg256#12,<S0=reg256#4
# asm 2: vfmadd231pd -128(<const1=%rax),<c5=%ymm11,<S0=%ymm3
# bytes: 6 uops: 1
vfmadd231pd -128(%rax),%ymm11,%ymm3

# qhasm:   a85 aligned= mem256[const2 - 32]
# asm 1: vmovapd   -32(<const2=int64#8),>a85=reg256#12
# asm 2: vmovapd   -32(<const2=%r10),>a85=%ymm11
# bytes: 6 uops: 1
vmovapd   -32(%r10),%ymm11
# block pos: 1984 2016 uops: 6

# qhasm:   4x c3 = approx S3 + a85
# asm 1: vaddpd <S3=reg256#13,<a85=reg256#12,>c3=reg256#14
# asm 2: vaddpd <S3=%ymm12,<a85=%ymm11,>c3=%ymm13
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm12,%ymm11,%ymm13

# qhasm:   4x c3 approx-= a85
# asm 1: vsubpd <a85=reg256#12,<c3=reg256#14,>c3=reg256#12
# asm 2: vsubpd <a85=%ymm11,<c3=%ymm13,>c3=%ymm11
# bytes: 5 uops: 1
vsubpd %ymm11,%ymm13,%ymm11

# qhasm:   4x S4 approx+= c3
# asm 1: vaddpd <c3=reg256#12,<S4=reg256#5,>S4=reg256#5
# asm 2: vaddpd <c3=%ymm11,<S4=%ymm4,>S4=%ymm4
# bytes: 5 uops: 1
vaddpd %ymm11,%ymm4,%ymm4

# qhasm:   4x S3 approx-= c3
# asm 1: vsubpd <c3=reg256#12,<S3=reg256#13,>S3=reg256#12
# asm 2: vsubpd <c3=%ymm11,<S3=%ymm12,>S3=%ymm11
# bytes: 5 uops: 1
vsubpd %ymm11,%ymm12,%ymm11

# qhasm:   a43 aligned= mem256[const2 - 96]
# asm 1: vmovapd   -96(<const2=int64#8),>a43=reg256#13
# asm 2: vmovapd   -96(<const2=%r10),>a43=%ymm12
# bytes: 6 uops: 1
vmovapd   -96(%r10),%ymm12

# qhasm:   4x c1 = approx S1 + a43
# asm 1: vaddpd <S1=reg256#8,<a43=reg256#13,>c1=reg256#14
# asm 2: vaddpd <S1=%ymm7,<a43=%ymm12,>c1=%ymm13
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm7,%ymm12,%ymm13
# block pos: 2016 2048 uops: 6

# qhasm:   4x c1 approx-= a43
# asm 1: vsubpd <a43=reg256#13,<c1=reg256#14,>c1=reg256#13
# asm 2: vsubpd <a43=%ymm12,<c1=%ymm13,>c1=%ymm12
# bytes: 6 uops: 1
.byte 0x3e
vsubpd %ymm12,%ymm13,%ymm12

# qhasm:   4x S2 approx+= c1
# asm 1: vaddpd <c1=reg256#13,<S2=reg256#9,>S2=reg256#9
# asm 2: vaddpd <c1=%ymm12,<S2=%ymm8,>S2=%ymm8
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm12,%ymm8,%ymm8

# qhasm:   4x S1 approx-= c1
# asm 1: vsubpd <c1=reg256#13,<S1=reg256#8,>S1=reg256#8
# asm 2: vsubpd <c1=%ymm12,<S1=%ymm7,>S1=%ymm7
# bytes: 5 uops: 1
vsubpd %ymm12,%ymm7,%ymm7

# qhasm:   4x S4 approx+= S5
# asm 1: vaddpd <S5=reg256#7,<S4=reg256#5,>S4=reg256#5
# asm 2: vaddpd <S5=%ymm6,<S4=%ymm4,>S4=%ymm4
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm6,%ymm4,%ymm4

# qhasm:   4x S2 approx+= S3
# asm 1: vaddpd <S3=reg256#12,<S2=reg256#9,>S2=reg256#7
# asm 2: vaddpd <S3=%ymm11,<S2=%ymm8,>S2=%ymm6
# bytes: 5 uops: 1
vaddpd %ymm11,%ymm8,%ymm6

# qhasm:   4x S0 approx+= S1
# asm 1: vaddpd <S1=reg256#8,<S0=reg256#4,>S0=reg256#4
# asm 2: vaddpd <S1=%ymm7,<S0=%ymm3,>S0=%ymm3
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm7,%ymm3,%ymm3
# block pos: 2048 2082 uops: 10

# qhasm:                signed<? pos -= 1
# asm 1: sub  $1,<pos=int64#9
# asm 2: sub  $1,<pos=%r11
# bytes: 4 uops: 1
sub  $1,%r11
# comment:fp stack unchanged by jump

# qhasm: goto noload if signed<
# bytes: 2 uops: 1
jl ._noload

# qhasm:   i = pos
# asm 1: mov  <pos=int64#9,>i=int64#4
# asm 2: mov  <pos=%r11,>i=%rcx
# bytes: 3 uops: 1
mov  %r11,%rcx

# qhasm:   (uint64) i >>= 3
# asm 1: shr  $3,<i=int64#4
# asm 2: shr  $3,<i=%rcx
# bytes: 4 uops: 1
shr  $3,%rcx

# qhasm:   bit = *(uint8 *) (input_1 + i)
# asm 1: movzbq (<input_1=int64#2,<i=int64#4),>bit=int64#11
# asm 2: movzbq (<input_1=%rsi,<i=%rcx),>bit=%r13
# bytes: 5 uops: 1
movzbq (%rsi,%rcx),%r13

# qhasm:   j = pos
# asm 1: mov  <pos=int64#9,>j=int64#4
# asm 2: mov  <pos=%r11,>j=%rcx
# bytes: 3 uops: 1
mov  %r11,%rcx

# qhasm:   (uint32) j &= 7
# asm 1: and  $7,<j=int64#4d
# asm 2: and  $7,<j=%ecx
# bytes: 3 uops: 1
and  $7,%ecx

# qhasm:   (uint64) bit >>= j
# asm 1: shr  %cl,<bit=int64#11
# asm 2: shr  %cl,<bit=%r13
# bytes: 3 uops: 1
shr  %cl,%r13

# qhasm:   (uint32) bit &= 1
# asm 1: and  $1,<bit=int64#11d
# asm 2: and  $1,<bit=%r13d
# bytes: 4 uops: 1
and  $1,%r13d

# qhasm:   bit ^= prevbit
# asm 1: xor  <prevbit=int64#10,<bit=int64#11
# asm 2: xor  <prevbit=%r12,<bit=%r13
# bytes: 3 uops: 1
xor  %r12,%r13
# block pos: 2082 2112 uops: 5

# qhasm:   prevbit ^= bit
# asm 1: xor  <bit=int64#11,<prevbit=int64#10
# asm 2: xor  <bit=%r13,<prevbit=%r12
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
.byte 0x3e
xor  %r13,%r12

# qhasm:   bit -= 1
# asm 1: sub  $1,<bit=int64#11
# asm 2: sub  $1,<bit=%r13
# bytes: 5 uops: 1
.byte 0x3e
sub  $1,%r13

# qhasm:   b_stack = bit
# asm 1: movq <bit=int64#11,>b_stack=stack64#8
# asm 2: movq <bit=%r13,>b_stack=824(%rsp)
# bytes: 8 uops: 1
movq %r13,824(%rsp)
# comment:fp stack unchanged by fallthrough

# qhasm: noload:
._noload:

# qhasm:   yxtz4[0,1,2,3] = S4[1,0,3,2]
# asm 1: vpermilpd $0x5,<S4=reg256#5,>yxtz4=reg256#8
# asm 2: vpermilpd $0x5,<S4=%ymm4,>yxtz4=%ymm7
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm4,%ymm7

# qhasm:   abcd4[0,1,2,3] approx= S4[0]-yxtz4[0],S4[1]+yxtz4[1],S4[2]-yxtz4[2],S4[3]+yxtz4[3]
# asm 1: vaddsubpd <yxtz4=reg256#8,<S4=reg256#5,>abcd4=reg256#5
# asm 2: vaddsubpd <yxtz4=%ymm7,<S4=%ymm4,>abcd4=%ymm4
# bytes: 5 uops: 1
.byte 0x3e
vaddsubpd %ymm7,%ymm4,%ymm4
# block pos: 2112 2144 uops: 6

# qhasm:   cdab4[0,1,2,3] = abcd4[2,3],abcd4[0,1]
# asm 1: vperm2f128 $0x21,<abcd4=reg256#5,<abcd4=reg256#5,>cdab4=reg256#8
# asm 2: vperm2f128 $0x21,<abcd4=%ymm4,<abcd4=%ymm4,>cdab4=%ymm7
# bytes: 7 uops: 2
.byte 0x3e
vperm2f128 $0x21,%ymm4,%ymm4,%ymm7

# qhasm:   badc4[0,1,2,3] = abcd4[1,0,3,2]
# asm 1: vpermilpd $0x5,<abcd4=reg256#5,>badc4=reg256#5
# asm 2: vpermilpd $0x5,<abcd4=%ymm4,>badc4=%ymm4
# bytes: 7 uops: 1
.byte 0x3e
vpermilpd $0x5,%ymm4,%ymm4

# qhasm:   B4[0,1,2,3] approx= badc4[0]-cdab4[0],badc4[1]+cdab4[1],badc4[2]-cdab4[2],badc4[3]+cdab4[3]
# asm 1: vaddsubpd <cdab4=reg256#8,<badc4=reg256#5,>B4=reg256#5
# asm 2: vaddsubpd <cdab4=%ymm7,<badc4=%ymm4,>B4=%ymm4
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm7,%ymm4,%ymm4

# qhasm:   yxtz2[0,1,2,3] = S2[1,0,3,2]
# asm 1: vpermilpd $0x5,<S2=reg256#7,>yxtz2=reg256#8
# asm 2: vpermilpd $0x5,<S2=%ymm6,>yxtz2=%ymm7
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm6,%ymm7

# qhasm:   abcd2[0,1,2,3] approx= S2[0]-yxtz2[0],S2[1]+yxtz2[1],S2[2]-yxtz2[2],S2[3]+yxtz2[3]
# asm 1: vaddsubpd <yxtz2=reg256#8,<S2=reg256#7,>abcd2=reg256#7
# asm 2: vaddsubpd <yxtz2=%ymm7,<S2=%ymm6,>abcd2=%ymm6
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm7,%ymm6,%ymm6
# block pos: 2144 2176 uops: 6

# qhasm:   cdab2[0,1,2,3] = abcd2[2,3],abcd2[0,1]
# asm 1: vperm2f128 $0x21,<abcd2=reg256#7,<abcd2=reg256#7,>cdab2=reg256#8
# asm 2: vperm2f128 $0x21,<abcd2=%ymm6,<abcd2=%ymm6,>cdab2=%ymm7
# bytes: 7 uops: 2
.byte 0x3e
vperm2f128 $0x21,%ymm6,%ymm6,%ymm7

# qhasm:   badc2[0,1,2,3] = abcd2[1,0,3,2]
# asm 1: vpermilpd $0x5,<abcd2=reg256#7,>badc2=reg256#7
# asm 2: vpermilpd $0x5,<abcd2=%ymm6,>badc2=%ymm6
# bytes: 7 uops: 1
.byte 0x3e
vpermilpd $0x5,%ymm6,%ymm6

# qhasm:   B2[0,1,2,3] approx= badc2[0]-cdab2[0],badc2[1]+cdab2[1],badc2[2]-cdab2[2],badc2[3]+cdab2[3]
# asm 1: vaddsubpd <cdab2=reg256#8,<badc2=reg256#7,>B2=reg256#7
# asm 2: vaddsubpd <cdab2=%ymm7,<badc2=%ymm6,>B2=%ymm6
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm7,%ymm6,%ymm6

# qhasm:   yxtz0[0,1,2,3] = S0[1,0,3,2]
# asm 1: vpermilpd $0x5,<S0=reg256#4,>yxtz0=reg256#8
# asm 2: vpermilpd $0x5,<S0=%ymm3,>yxtz0=%ymm7
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm3,%ymm7

# qhasm:   abcd0[0,1,2,3] approx= S0[0]-yxtz0[0],S0[1]+yxtz0[1],S0[2]-yxtz0[2],S0[3]+yxtz0[3]
# asm 1: vaddsubpd <yxtz0=reg256#8,<S0=reg256#4,>abcd0=reg256#4
# asm 2: vaddsubpd <yxtz0=%ymm7,<S0=%ymm3,>abcd0=%ymm3
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm7,%ymm3,%ymm3
# block pos: 2176 2208 uops: 6

# qhasm:   cdab0[0,1,2,3] = abcd0[2,3],abcd0[0,1]
# asm 1: vperm2f128 $0x21,<abcd0=reg256#4,<abcd0=reg256#4,>cdab0=reg256#8
# asm 2: vperm2f128 $0x21,<abcd0=%ymm3,<abcd0=%ymm3,>cdab0=%ymm7
# bytes: 7 uops: 2
.byte 0x3e
vperm2f128 $0x21,%ymm3,%ymm3,%ymm7

# qhasm:   badc0[0,1,2,3] = abcd0[1,0,3,2]
# asm 1: vpermilpd $0x5,<abcd0=reg256#4,>badc0=reg256#4
# asm 2: vpermilpd $0x5,<abcd0=%ymm3,>badc0=%ymm3
# bytes: 7 uops: 1
.byte 0x3e
vpermilpd $0x5,%ymm3,%ymm3

# qhasm:   B0[0,1,2,3] approx= badc0[0]-cdab0[0],badc0[1]+cdab0[1],badc0[2]-cdab0[2],badc0[3]+cdab0[3]
# asm 1: vaddsubpd <cdab0=reg256#8,<badc0=reg256#4,>B0=reg256#4
# asm 2: vaddsubpd <cdab0=%ymm7,<badc0=%ymm3,>B0=%ymm3
# bytes: 7 uops: 1
.byte 0x3e
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm7,%ymm3,%ymm3

# qhasm:                             4x 2A5 = approx A5 * mem256[const1 + 0]
# asm 1: vmulpd 0(<const1=int64#7),<A5=reg256#6,>2A5=reg256#8
# asm 2: vmulpd 0(<const1=%rax),<A5=%ymm5,>2A5=%ymm7
# bytes: 4 uops: 1
vmulpd 0(%rax),%ymm5,%ymm7

# qhasm:                               4x C5 = approx A0 * 2A5
# asm 1: vmulpd <A0=reg256#3,<2A5=reg256#8,>C5=reg256#8
# asm 2: vmulpd <A0=%ymm2,<2A5=%ymm7,>C5=%ymm7
# bytes: 7 uops: 1
.byte 0x3e
.byte 0x3e
.byte 0x3e
vmulpd %ymm2,%ymm7,%ymm7
# block pos: 2208 2240 uops: 6

# qhasm:                             4x 2A4 = approx A4 * mem256[const1 + 0]
# asm 1: vmulpd 0(<const1=int64#7),<A4=reg256#1,>2A4=reg256#9
# asm 2: vmulpd 0(<const1=%rax),<A4=%ymm0,>2A4=%ymm8
# bytes: 4 uops: 1
vmulpd 0(%rax),%ymm0,%ymm8

# qhasm:                               4x C5 approx+= A1 * 2A4
# asm 1: vfmadd231pd <A1=reg256#11,<2A4=reg256#9,<C5=reg256#8
# asm 2: vfmadd231pd <A1=%ymm10,<2A4=%ymm8,<C5=%ymm7
# bytes: 7 uops: 1
.byte 0x3e
.byte 0x3e
vfmadd231pd %ymm10,%ymm8,%ymm7

# qhasm:                             4x 2A3 = approx A3 * mem256[const1 + 0]
# asm 1: vmulpd 0(<const1=int64#7),<A3=reg256#10,>2A3=reg256#12
# asm 2: vmulpd 0(<const1=%rax),<A3=%ymm9,>2A3=%ymm11
# bytes: 4 uops: 1
vmulpd 0(%rax),%ymm9,%ymm11

# qhasm:                               4x C5 approx+= A2 * 2A3
# asm 1: vfmadd231pd <A2=reg256#2,<2A3=reg256#12,<C5=reg256#8
# asm 2: vfmadd231pd <A2=%ymm1,<2A3=%ymm11,<C5=%ymm7
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm1,%ymm11,%ymm7

# qhasm:                             4x 127a5 = approx A5 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#7),<A5=reg256#6,>127a5=reg256#13
# asm 2: vmulpd -128(<const1=%rax),<A5=%ymm5,>127a5=%ymm12
# bytes: 5 uops: 1
vmulpd -128(%rax),%ymm5,%ymm12

# qhasm:                               4x C4 = approx A5 * 127a5
# asm 1: vmulpd <A5=reg256#6,<127a5=reg256#13,>C4=reg256#6
# asm 2: vmulpd <A5=%ymm5,<127a5=%ymm12,>C4=%ymm5
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm5,%ymm12,%ymm5
# block pos: 2240 2272 uops: 6

# qhasm:                               4x C4 approx+= A0 * 2A4
# asm 1: vfmadd231pd <A0=reg256#3,<2A4=reg256#9,<C4=reg256#6
# asm 2: vfmadd231pd <A0=%ymm2,<2A4=%ymm8,<C4=%ymm5
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm2,%ymm8,%ymm5

# qhasm:                               4x C4 approx+= A1 * 2A3
# asm 1: vfmadd231pd <A1=reg256#11,<2A3=reg256#12,<C4=reg256#6
# asm 2: vfmadd231pd <A1=%ymm10,<2A3=%ymm11,<C4=%ymm5
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm10,%ymm11,%ymm5

# qhasm:                               4x C4 approx+= A2 * A2
# asm 1: vfmadd231pd <A2=reg256#2,<A2=reg256#2,<C4=reg256#6
# asm 2: vfmadd231pd <A2=%ymm1,<A2=%ymm1,<C4=%ymm5
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm1,%ymm1,%ymm5

# qhasm:                             4x 2A2 = approx A2 * mem256[const1 + 0]
# asm 1: vmulpd 0(<const1=int64#7),<A2=reg256#2,>2A2=reg256#2
# asm 2: vmulpd 0(<const1=%rax),<A2=%ymm1,>2A2=%ymm1
# bytes: 4 uops: 1
vmulpd 0(%rax),%ymm1,%ymm1

# qhasm:                               4x C3 = approx 2A4 * 127a5
# asm 1: vmulpd <2A4=reg256#9,<127a5=reg256#13,>C3=reg256#9
# asm 2: vmulpd <2A4=%ymm8,<127a5=%ymm12,>C3=%ymm8
# bytes: 5 uops: 1
vmulpd %ymm8,%ymm12,%ymm8

# qhasm:                               4x C3 approx+= A0 * 2A3
# asm 1: vfmadd231pd <A0=reg256#3,<2A3=reg256#12,<C3=reg256#9
# asm 2: vfmadd231pd <A0=%ymm2,<2A3=%ymm11,<C3=%ymm8
# bytes: 5 uops: 1
vfmadd231pd %ymm2,%ymm11,%ymm8
# block pos: 2272 2304 uops: 6

# qhasm:                               4x C3 approx+= A1 * 2A2
# asm 1: vfmadd231pd <A1=reg256#11,<2A2=reg256#2,<C3=reg256#9
# asm 2: vfmadd231pd <A1=%ymm10,<2A2=%ymm1,<C3=%ymm8
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm10,%ymm1,%ymm8

# qhasm:                             4x 127a4 = approx A4 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#7),<A4=reg256#1,>127a4=reg256#14
# asm 2: vmulpd -128(<const1=%rax),<A4=%ymm0,>127a4=%ymm13
# bytes: 5 uops: 1
vmulpd -128(%rax),%ymm0,%ymm13

# qhasm:                               4x C2 = approx A4 * 127a4
# asm 1: vmulpd <A4=reg256#1,<127a4=reg256#14,>C2=reg256#1
# asm 2: vmulpd <A4=%ymm0,<127a4=%ymm13,>C2=%ymm0
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm0,%ymm13,%ymm0

# qhasm:                               4x C2 approx+= 2A3 * 127a5
# asm 1: vfmadd231pd <2A3=reg256#12,<127a5=reg256#13,<C2=reg256#1
# asm 2: vfmadd231pd <2A3=%ymm11,<127a5=%ymm12,<C2=%ymm0
# bytes: 5 uops: 1
vfmadd231pd %ymm11,%ymm12,%ymm0

# qhasm:                               4x C2 approx+= A0 * 2A2
# asm 1: vfmadd231pd <A0=reg256#3,<2A2=reg256#2,<C2=reg256#1
# asm 2: vfmadd231pd <A0=%ymm2,<2A2=%ymm1,<C2=%ymm0
# bytes: 5 uops: 1
vfmadd231pd %ymm2,%ymm1,%ymm0

# qhasm:                               4x C2 approx+= A1 * A1
# asm 1: vfmadd231pd <A1=reg256#11,<A1=reg256#11,<C2=reg256#1
# asm 2: vfmadd231pd <A1=%ymm10,<A1=%ymm10,<C2=%ymm0
# bytes: 5 uops: 1
vfmadd231pd %ymm10,%ymm10,%ymm0
# block pos: 2304 2336 uops: 6

# qhasm:                             4x 2A1 = approx A1 * mem256[const1 + 0]
# asm 1: vmulpd 0(<const1=int64#7),<A1=reg256#11,>2A1=reg256#11
# asm 2: vmulpd 0(<const1=%rax),<A1=%ymm10,>2A1=%ymm10
# bytes: 4 uops: 1
vmulpd 0(%rax),%ymm10,%ymm10

# qhasm:                               4x C1 = approx 2A3 * 127a4
# asm 1: vmulpd <2A3=reg256#12,<127a4=reg256#14,>C1=reg256#12
# asm 2: vmulpd <2A3=%ymm11,<127a4=%ymm13,>C1=%ymm11
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm11,%ymm13,%ymm11

# qhasm:                               4x C1 approx+= 2A2 * 127a5
# asm 1: vfmadd231pd <2A2=reg256#2,<127a5=reg256#13,<C1=reg256#12
# asm 2: vfmadd231pd <2A2=%ymm1,<127a5=%ymm12,<C1=%ymm11
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm1,%ymm12,%ymm11

# qhasm:                               4x C1 approx+= A0 * 2A1
# asm 1: vfmadd231pd <A0=reg256#3,<2A1=reg256#11,<C1=reg256#12
# asm 2: vfmadd231pd <A0=%ymm2,<2A1=%ymm10,<C1=%ymm11
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm2,%ymm10,%ymm11

# qhasm:                             4x 127a3 = approx A3 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#7),<A3=reg256#10,>127a3=reg256#15
# asm 2: vmulpd -128(<const1=%rax),<A3=%ymm9,>127a3=%ymm14
# bytes: 5 uops: 1
vmulpd -128(%rax),%ymm9,%ymm14

# qhasm:                               4x C0 = approx A3 * 127a3
# asm 1: vmulpd <A3=reg256#10,<127a3=reg256#15,>C0=reg256#10
# asm 2: vmulpd <A3=%ymm9,<127a3=%ymm14,>C0=%ymm9
# bytes: 5 uops: 1
vmulpd %ymm9,%ymm14,%ymm9
# block pos: 2336 2368 uops: 6

# qhasm:                               4x C0 approx+= 2A2 * 127a4
# asm 1: vfmadd231pd <2A2=reg256#2,<127a4=reg256#14,<C0=reg256#10
# asm 2: vfmadd231pd <2A2=%ymm1,<127a4=%ymm13,<C0=%ymm9
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm1,%ymm13,%ymm9

# qhasm:                               4x C0 approx+= 2A1 * 127a5
# asm 1: vfmadd231pd <2A1=reg256#11,<127a5=reg256#13,<C0=reg256#10
# asm 2: vfmadd231pd <2A1=%ymm10,<127a5=%ymm12,<C0=%ymm9
# bytes: 5 uops: 1
vfmadd231pd %ymm10,%ymm12,%ymm9

# qhasm:                               4x C0 approx+= A0 * A0
# asm 1: vfmadd231pd <A0=reg256#3,<A0=reg256#3,<C0=reg256#10
# asm 2: vfmadd231pd <A0=%ymm2,<A0=%ymm2,<C0=%ymm9
# bytes: 5 uops: 1
vfmadd231pd %ymm2,%ymm2,%ymm9

# qhasm:                           a127 aligned= mem256[const2 + 32]
# asm 1: vmovapd   32(<const2=int64#8),>a127=reg256#2
# asm 2: vmovapd   32(<const2=%r10),>a127=%ymm1
# bytes: 6 uops: 1
vmovapd   32(%r10),%ymm1

# qhasm:                           4x c5 = approx C5 + a127
# asm 1: vaddpd <C5=reg256#8,<a127=reg256#2,>c5=reg256#3
# asm 2: vaddpd <C5=%ymm7,<a127=%ymm1,>c5=%ymm2
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm7,%ymm1,%ymm2

# qhasm:                           4x c5 approx-= a127
# asm 1: vsubpd <a127=reg256#2,<c5=reg256#3,>c5=reg256#2
# asm 2: vsubpd <a127=%ymm1,<c5=%ymm2,>c5=%ymm1
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm1,%ymm2,%ymm1
# block pos: 2368 2400 uops: 6

# qhasm:                           4x C5 approx-= c5
# asm 1: vsubpd <c5=reg256#2,<C5=reg256#8,>C5=reg256#3
# asm 2: vsubpd <c5=%ymm1,<C5=%ymm7,>C5=%ymm2
# bytes: 4 uops: 1
vsubpd %ymm1,%ymm7,%ymm2

# qhasm:                           4x C0 approx+= c5 * mem256[const1 - 128]
# asm 1: vfmadd231pd -128(<const1=int64#7),<c5=reg256#2,<C0=reg256#10
# asm 2: vfmadd231pd -128(<const1=%rax),<c5=%ymm1,<C0=%ymm9
# bytes: 6 uops: 1
vfmadd231pd -128(%rax),%ymm1,%ymm9

# qhasm:    a22 aligned= mem256[const2 - 128]
# asm 1: vmovapd   -128(<const2=int64#8),>a22=reg256#2
# asm 2: vmovapd   -128(<const2=%r10),>a22=%ymm1
# bytes: 6 uops: 1
vmovapd   -128(%r10),%ymm1

# qhasm:    4x B1 = approx B0 + a22
# asm 1: vaddpd <B0=reg256#4,<a22=reg256#2,>B1=reg256#8
# asm 2: vaddpd <B0=%ymm3,<a22=%ymm1,>B1=%ymm7
# bytes: 4 uops: 1
vaddpd %ymm3,%ymm1,%ymm7

# qhasm:    4x B1 approx-= a22 *mem256[const1+32]
# asm 1: vfnmadd231pd 32(<const1=int64#7),<a22=reg256#2,<B1=reg256#8
# asm 2: vfnmadd231pd 32(<const1=%rax),<a22=%ymm1,<B1=%ymm7
# bytes: 6 uops: 1
vfnmadd231pd 32(%rax),%ymm1,%ymm7

# qhasm:    4x B0 approx-= B1 * mem256[const1 + 32]
# asm 1: vfnmadd231pd 32(<const1=int64#7),<B1=reg256#8,<B0=reg256#4
# asm 2: vfnmadd231pd 32(<const1=%rax),<B1=%ymm7,<B0=%ymm3
# bytes: 6 uops: 1
vfnmadd231pd 32(%rax),%ymm7,%ymm3
# block pos: 2400 2432 uops: 6

# qhasm:    a64 aligned= mem256[const2 - 64]
# asm 1: vmovapd   -64(<const2=int64#8),>a64=reg256#2
# asm 2: vmovapd   -64(<const2=%r10),>a64=%ymm1
# bytes: 6 uops: 1
vmovapd   -64(%r10),%ymm1

# qhasm:    4x B3 = approx B2 + a64
# asm 1: vaddpd <B2=reg256#7,<a64=reg256#2,>B3=reg256#11
# asm 2: vaddpd <B2=%ymm6,<a64=%ymm1,>B3=%ymm10
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm6,%ymm1,%ymm10

# qhasm:    4x B3 approx-= a64 *mem256[const1+32]
# asm 1: vfnmadd231pd 32(<const1=int64#7),<a64=reg256#2,<B3=reg256#11
# asm 2: vfnmadd231pd 32(<const1=%rax),<a64=%ymm1,<B3=%ymm10
# bytes: 6 uops: 1
vfnmadd231pd 32(%rax),%ymm1,%ymm10

# qhasm:    4x B2 approx-= B3 * mem256[const1 + 32]
# asm 1: vfnmadd231pd 32(<const1=int64#7),<B3=reg256#11,<B2=reg256#7
# asm 2: vfnmadd231pd 32(<const1=%rax),<B3=%ymm10,<B2=%ymm6
# bytes: 6 uops: 1
vfnmadd231pd 32(%rax),%ymm10,%ymm6

# qhasm:    a106 aligned= mem256[const2 + 0]
# asm 1: vmovapd   0(<const2=int64#8),>a106=reg256#2
# asm 2: vmovapd   0(<const2=%r10),>a106=%ymm1
# bytes: 5 uops: 1
vmovapd   0(%r10),%ymm1

# qhasm:    4x B5 = approx B4 + a106
# asm 1: vaddpd <B4=reg256#5,<a106=reg256#2,>B5=reg256#13
# asm 2: vaddpd <B4=%ymm4,<a106=%ymm1,>B5=%ymm12
# bytes: 4 uops: 1
vaddpd %ymm4,%ymm1,%ymm12
# block pos: 2432 2464 uops: 6

# qhasm:    4x B5 approx-= a106 *mem256[const1+32]
# asm 1: vfnmadd231pd 32(<const1=int64#7),<a106=reg256#2,<B5=reg256#13
# asm 2: vfnmadd231pd 32(<const1=%rax),<a106=%ymm1,<B5=%ymm12
# bytes: 6 uops: 1
vfnmadd231pd 32(%rax),%ymm1,%ymm12

# qhasm:    4x B4 approx-= B5 * mem256[const1 + 32]
# asm 1: vfnmadd231pd 32(<const1=int64#7),<B5=reg256#13,<B4=reg256#5
# asm 2: vfnmadd231pd 32(<const1=%rax),<B5=%ymm12,<B4=%ymm4
# bytes: 6 uops: 1
vfnmadd231pd 32(%rax),%ymm12,%ymm4

# qhasm:                           a106 aligned= mem256[const2 + 0]
# asm 1: vmovapd   0(<const2=int64#8),>a106=reg256#2
# asm 2: vmovapd   0(<const2=%r10),>a106=%ymm1
# bytes: 5 uops: 1
vmovapd   0(%r10),%ymm1

# qhasm:                           4x c4 = approx C4 + a106
# asm 1: vaddpd <C4=reg256#6,<a106=reg256#2,>c4=reg256#14
# asm 2: vaddpd <C4=%ymm5,<a106=%ymm1,>c4=%ymm13
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm5,%ymm1,%ymm13

# qhasm:                           4x c4 approx-= a106
# asm 1: vsubpd <a106=reg256#2,<c4=reg256#14,>c4=reg256#2
# asm 2: vsubpd <a106=%ymm1,<c4=%ymm13,>c4=%ymm1
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm1,%ymm13,%ymm1

# qhasm:                           4x C5 approx+= c4
# asm 1: vaddpd <c4=reg256#2,<C5=reg256#3,>C5=reg256#3
# asm 2: vaddpd <c4=%ymm1,<C5=%ymm2,>C5=%ymm2
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm1,%ymm2,%ymm2
# block pos: 2464 2496 uops: 6

# qhasm:                           4x C4 approx-= c4
# asm 1: vsubpd <c4=reg256#2,<C4=reg256#6,>C4=reg256#2
# asm 2: vsubpd <c4=%ymm1,<C4=%ymm5,>C4=%ymm1
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm1,%ymm5,%ymm1

# qhasm:                             mem256[work2 +  32] aligned= C5
# asm 1: vmovapd   <C5=reg256#3,32(<work2=int64#6)
# asm 2: vmovapd   <C5=%ymm2,32(<work2=%r9)
# bytes: 6 uops: 1
vmovapd   %ymm2,32(%r9)

# qhasm:                           a85 aligned= mem256[const2 - 32]
# asm 1: vmovapd   -32(<const2=int64#8),>a85=reg256#3
# asm 2: vmovapd   -32(<const2=%r10),>a85=%ymm2
# bytes: 6 uops: 1
vmovapd   -32(%r10),%ymm2

# qhasm:                           4x c3 = approx C3 + a85
# asm 1: vaddpd <C3=reg256#9,<a85=reg256#3,>c3=reg256#6
# asm 2: vaddpd <C3=%ymm8,<a85=%ymm2,>c3=%ymm5
# bytes: 5 uops: 1
vaddpd %ymm8,%ymm2,%ymm5

# qhasm:                           4x c3 approx-= a85
# asm 1: vsubpd <a85=reg256#3,<c3=reg256#6,>c3=reg256#3
# asm 2: vsubpd <a85=%ymm2,<c3=%ymm5,>c3=%ymm2
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm2,%ymm5,%ymm2

# qhasm:                           4x C4 approx+= c3
# asm 1: vaddpd <c3=reg256#3,<C4=reg256#2,>C4=reg256#2
# asm 2: vaddpd <c3=%ymm2,<C4=%ymm1,>C4=%ymm1
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm2,%ymm1,%ymm1
# block pos: 2496 2528 uops: 6

# qhasm:                           4x C3 approx-= c3
# asm 1: vsubpd <c3=reg256#3,<C3=reg256#9,>C3=reg256#3
# asm 2: vsubpd <c3=%ymm2,<C3=%ymm8,>C3=%ymm2
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vsubpd %ymm2,%ymm8,%ymm2

# qhasm:                             mem256[work2 +   0] aligned= C4
# asm 1: vmovapd   <C4=reg256#2,0(<work2=int64#6)
# asm 2: vmovapd   <C4=%ymm1,0(<work2=%r9)
# bytes: 5 uops: 1
vmovapd   %ymm1,0(%r9)

# qhasm:                           a64 aligned= mem256[const2 - 64]
# asm 1: vmovapd   -64(<const2=int64#8),>a64=reg256#2
# asm 2: vmovapd   -64(<const2=%r10),>a64=%ymm1
# bytes: 6 uops: 1
vmovapd   -64(%r10),%ymm1

# qhasm:                           4x c2 = approx C2 + a64
# asm 1: vaddpd <C2=reg256#1,<a64=reg256#2,>c2=reg256#6
# asm 2: vaddpd <C2=%ymm0,<a64=%ymm1,>c2=%ymm5
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm0,%ymm1,%ymm5

# qhasm:                           4x c2 approx-= a64
# asm 1: vsubpd <a64=reg256#2,<c2=reg256#6,>c2=reg256#2
# asm 2: vsubpd <a64=%ymm1,<c2=%ymm5,>c2=%ymm1
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm1,%ymm5,%ymm1

# qhasm:                           4x C3 approx+= c2
# asm 1: vaddpd <c2=reg256#2,<C3=reg256#3,>C3=reg256#3
# asm 2: vaddpd <c2=%ymm1,<C3=%ymm2,>C3=%ymm2
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm1,%ymm2,%ymm2
# block pos: 2528 2560 uops: 6

# qhasm:                           4x C2 approx-= c2
# asm 1: vsubpd <c2=reg256#2,<C2=reg256#1,>C2=reg256#1
# asm 2: vsubpd <c2=%ymm1,<C2=%ymm0,>C2=%ymm0
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vsubpd %ymm1,%ymm0,%ymm0

# qhasm:                           a43 aligned= mem256[const2 - 96]
# asm 1: vmovapd   -96(<const2=int64#8),>a43=reg256#2
# asm 2: vmovapd   -96(<const2=%r10),>a43=%ymm1
# bytes: 6 uops: 1
vmovapd   -96(%r10),%ymm1

# qhasm:                           4x c1 = approx C1 + a43
# asm 1: vaddpd <C1=reg256#12,<a43=reg256#2,>c1=reg256#6
# asm 2: vaddpd <C1=%ymm11,<a43=%ymm1,>c1=%ymm5
# bytes: 5 uops: 1
vaddpd %ymm11,%ymm1,%ymm5

# qhasm:                           4x c1 approx-= a43
# asm 1: vsubpd <a43=reg256#2,<c1=reg256#6,>c1=reg256#2
# asm 2: vsubpd <a43=%ymm1,<c1=%ymm5,>c1=%ymm1
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm1,%ymm5,%ymm1

# qhasm:                           4x C2 approx+= c1
# asm 1: vaddpd <c1=reg256#2,<C2=reg256#1,>C2=reg256#1
# asm 2: vaddpd <c1=%ymm1,<C2=%ymm0,>C2=%ymm0
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm1,%ymm0,%ymm0

# qhasm:                           4x C1 approx-= c1
# asm 1: vsubpd <c1=reg256#2,<C1=reg256#12,>C1=reg256#2
# asm 2: vsubpd <c1=%ymm1,<C1=%ymm11,>C1=%ymm1
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm1,%ymm11,%ymm1
# block pos: 2560 2592 uops: 6

# qhasm:                           a22 aligned= mem256[const2 - 128]
# asm 1: vmovapd   -128(<const2=int64#8),>a22=reg256#6
# asm 2: vmovapd   -128(<const2=%r10),>a22=%ymm5
# bytes: 6 uops: 1
vmovapd   -128(%r10),%ymm5

# qhasm:                           4x c0 = approx C0 + a22
# asm 1: vaddpd <C0=reg256#10,<a22=reg256#6,>c0=reg256#9
# asm 2: vaddpd <C0=%ymm9,<a22=%ymm5,>c0=%ymm8
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm9,%ymm5,%ymm8

# qhasm:                           4x c0 approx-= a22
# asm 1: vsubpd <a22=reg256#6,<c0=reg256#9,>c0=reg256#6
# asm 2: vsubpd <a22=%ymm5,<c0=%ymm8,>c0=%ymm5
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vsubpd %ymm5,%ymm8,%ymm5

# qhasm:                           4x C1 approx+= c0
# asm 1: vaddpd <c0=reg256#6,<C1=reg256#2,>C1=reg256#2
# asm 2: vaddpd <c0=%ymm5,<C1=%ymm1,>C1=%ymm1
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm5,%ymm1,%ymm1

# qhasm:                           4x C0 approx-= c0
# asm 1: vsubpd <c0=reg256#6,<C0=reg256#10,>C0=reg256#6
# asm 2: vsubpd <c0=%ymm5,<C0=%ymm9,>C0=%ymm5
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm5,%ymm9,%ymm5

# qhasm:     4x 2B5 = approx B5 * mem256[const1 + 0]
# asm 1: vmulpd 0(<const1=int64#7),<B5=reg256#13,>2B5=reg256#9
# asm 2: vmulpd 0(<const1=%rax),<B5=%ymm12,>2B5=%ymm8
# bytes: 4 uops: 1
vmulpd 0(%rax),%ymm12,%ymm8
# block pos: 2592 2624 uops: 6

# qhasm:     4x 2B4 = approx B4 * mem256[const1 + 0]
# asm 1: vmulpd 0(<const1=int64#7),<B4=reg256#5,>2B4=reg256#10
# asm 2: vmulpd 0(<const1=%rax),<B4=%ymm4,>2B4=%ymm9
# bytes: 4 uops: 1
vmulpd 0(%rax),%ymm4,%ymm9

# qhasm:     4x 2B3 = approx B3 * mem256[const1 + 0]
# asm 1: vmulpd 0(<const1=int64#7),<B3=reg256#11,>2B3=reg256#12
# asm 2: vmulpd 0(<const1=%rax),<B3=%ymm10,>2B3=%ymm11
# bytes: 4 uops: 1
vmulpd 0(%rax),%ymm10,%ymm11

# qhasm:       4x D5 = approx B0 * 2B5
# asm 1: vmulpd <B0=reg256#4,<2B5=reg256#9,>D5=reg256#9
# asm 2: vmulpd <B0=%ymm3,<2B5=%ymm8,>D5=%ymm8
# bytes: 7 uops: 1
.byte 0x3e
.byte 0x3e
.byte 0x3e
vmulpd %ymm3,%ymm8,%ymm8

# qhasm:       4x D5 approx+= B1 * 2B4
# asm 1: vfmadd231pd <B1=reg256#8,<2B4=reg256#10,<D5=reg256#9
# asm 2: vfmadd231pd <B1=%ymm7,<2B4=%ymm9,<D5=%ymm8
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm7,%ymm9,%ymm8

# qhasm:       4x D5 approx+= B2 * 2B3
# asm 1: vfmadd231pd <B2=reg256#7,<2B3=reg256#12,<D5=reg256#9
# asm 2: vfmadd231pd <B2=%ymm6,<2B3=%ymm11,<D5=%ymm8
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm6,%ymm11,%ymm8

# qhasm:     4x 127B5 = approx B5 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#7),<B5=reg256#13,>127B5=reg256#14
# asm 2: vmulpd -128(<const1=%rax),<B5=%ymm12,>127B5=%ymm13
# bytes: 5 uops: 1
vmulpd -128(%rax),%ymm12,%ymm13
# block pos: 2624 2656 uops: 6

# qhasm:       4x D4 =approx B2 * B2
# asm 1: vmulpd <B2=reg256#7,<B2=reg256#7,>D4=reg256#15
# asm 2: vmulpd <B2=%ymm6,<B2=%ymm6,>D4=%ymm14
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm6,%ymm6,%ymm14

# qhasm:       4x D4 approx+= B0 * 2B4
# asm 1: vfmadd231pd <B0=reg256#4,<2B4=reg256#10,<D4=reg256#15
# asm 2: vfmadd231pd <B0=%ymm3,<2B4=%ymm9,<D4=%ymm14
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm3,%ymm9,%ymm14

# qhasm:       4x D4 approx+= B1 * 2B3
# asm 1: vfmadd231pd <B1=reg256#8,<2B3=reg256#12,<D4=reg256#15
# asm 2: vfmadd231pd <B1=%ymm7,<2B3=%ymm11,<D4=%ymm14
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm7,%ymm11,%ymm14

# qhasm:       4x D4 approx+= B5 * 127B5
# asm 1: vfmadd231pd <B5=reg256#13,<127B5=reg256#14,<D4=reg256#15
# asm 2: vfmadd231pd <B5=%ymm12,<127B5=%ymm13,<D4=%ymm14
# bytes: 5 uops: 1
vfmadd231pd %ymm12,%ymm13,%ymm14

# qhasm:     4x 2B2 = approx B2 * mem256[const1 + 0]
# asm 1: vmulpd 0(<const1=int64#7),<B2=reg256#7,>2B2=reg256#7
# asm 2: vmulpd 0(<const1=%rax),<B2=%ymm6,>2B2=%ymm6
# bytes: 4 uops: 1
vmulpd 0(%rax),%ymm6,%ymm6

# qhasm:       4x D3 = approx 2B4 * 127B5
# asm 1: vmulpd <2B4=reg256#10,<127B5=reg256#14,>D3=reg256#10
# asm 2: vmulpd <2B4=%ymm9,<127B5=%ymm13,>D3=%ymm9
# bytes: 5 uops: 1
vmulpd %ymm9,%ymm13,%ymm9
# block pos: 2656 2688 uops: 6

# qhasm:       4x D3 approx+= B0 * 2B3
# asm 1: vfmadd231pd <B0=reg256#4,<2B3=reg256#12,<D3=reg256#10
# asm 2: vfmadd231pd <B0=%ymm3,<2B3=%ymm11,<D3=%ymm9
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm3,%ymm11,%ymm9

# qhasm:       4x D3 approx+= B1 * 2B2
# asm 1: vfmadd231pd <B1=reg256#8,<2B2=reg256#7,<D3=reg256#10
# asm 2: vfmadd231pd <B1=%ymm7,<2B2=%ymm6,<D3=%ymm9
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm7,%ymm6,%ymm9

# qhasm:     4x 127B4 = approx B4 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#7),<B4=reg256#5,>127B4=reg256#13
# asm 2: vmulpd -128(<const1=%rax),<B4=%ymm4,>127B4=%ymm12
# bytes: 5 uops: 1
vmulpd -128(%rax),%ymm4,%ymm12

# qhasm:       4x D2 = approx B1 * B1
# asm 1: vmulpd <B1=reg256#8,<B1=reg256#8,>D2=reg256#16
# asm 2: vmulpd <B1=%ymm7,<B1=%ymm7,>D2=%ymm15
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm7,%ymm7,%ymm15

# qhasm:       4x D2 approx+= 2B3 * 127B5
# asm 1: vfmadd231pd <2B3=reg256#12,<127B5=reg256#14,<D2=reg256#16
# asm 2: vfmadd231pd <2B3=%ymm11,<127B5=%ymm13,<D2=%ymm15
# bytes: 5 uops: 1
vfmadd231pd %ymm11,%ymm13,%ymm15

# qhasm:       4x D2 approx+= B0 * 2B2
# asm 1: vfmadd231pd <B0=reg256#4,<2B2=reg256#7,<D2=reg256#16
# asm 2: vfmadd231pd <B0=%ymm3,<2B2=%ymm6,<D2=%ymm15
# bytes: 5 uops: 1
vfmadd231pd %ymm3,%ymm6,%ymm15
# block pos: 2688 2720 uops: 6

# qhasm:       4x D2 approx+= B4 * 127B4
# asm 1: vfmadd231pd <B4=reg256#5,<127B4=reg256#13,<D2=reg256#16
# asm 2: vfmadd231pd <B4=%ymm4,<127B4=%ymm12,<D2=%ymm15
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm4,%ymm12,%ymm15

# qhasm:     4x 2B1 = approx B1 * mem256[const1 + 0]
# asm 1: vmulpd 0(<const1=int64#7),<B1=reg256#8,>2B1=reg256#5
# asm 2: vmulpd 0(<const1=%rax),<B1=%ymm7,>2B1=%ymm4
# bytes: 4 uops: 1
vmulpd 0(%rax),%ymm7,%ymm4

# qhasm:       4x D1 = approx 2B3 * 127B4
# asm 1: vmulpd <2B3=reg256#12,<127B4=reg256#13,>D1=reg256#8
# asm 2: vmulpd <2B3=%ymm11,<127B4=%ymm12,>D1=%ymm7
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm11,%ymm12,%ymm7

# qhasm:       4x D1 approx+= 2B2 * 127B5
# asm 1: vfmadd231pd <2B2=reg256#7,<127B5=reg256#14,<D1=reg256#8
# asm 2: vfmadd231pd <2B2=%ymm6,<127B5=%ymm13,<D1=%ymm7
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm6,%ymm13,%ymm7

# qhasm:       4x D1 approx+= B0 * 2B1
# asm 1: vfmadd231pd <B0=reg256#4,<2B1=reg256#5,<D1=reg256#8
# asm 2: vfmadd231pd <B0=%ymm3,<2B1=%ymm4,<D1=%ymm7
# bytes: 5 uops: 1
vfmadd231pd %ymm3,%ymm4,%ymm7

# qhasm:     4x 127B3 = approx B3 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#7),<B3=reg256#11,>127B3=reg256#12
# asm 2: vmulpd -128(<const1=%rax),<B3=%ymm10,>127B3=%ymm11
# bytes: 5 uops: 1
vmulpd -128(%rax),%ymm10,%ymm11
# block pos: 2720 2752 uops: 6

# qhasm:       4x D0 = approx B0 * B0
# asm 1: vmulpd <B0=reg256#4,<B0=reg256#4,>D0=reg256#4
# asm 2: vmulpd <B0=%ymm3,<B0=%ymm3,>D0=%ymm3
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm3,%ymm3,%ymm3

# qhasm:       4x D0 approx+= 2B1 * 127B5
# asm 1: vfmadd231pd <2B1=reg256#5,<127B5=reg256#14,<D0=reg256#4
# asm 2: vfmadd231pd <2B1=%ymm4,<127B5=%ymm13,<D0=%ymm3
# bytes: 5 uops: 1
vfmadd231pd %ymm4,%ymm13,%ymm3

# qhasm:       4x D0 approx+= 2B2 * 127B4
# asm 1: vfmadd231pd <2B2=reg256#7,<127B4=reg256#13,<D0=reg256#4
# asm 2: vfmadd231pd <2B2=%ymm6,<127B4=%ymm12,<D0=%ymm3
# bytes: 5 uops: 1
vfmadd231pd %ymm6,%ymm12,%ymm3

# qhasm:       4x D0 approx+= B3 * 127B3
# asm 1: vfmadd231pd <B3=reg256#11,<127B3=reg256#12,<D0=reg256#4
# asm 2: vfmadd231pd <B3=%ymm10,<127B3=%ymm11,<D0=%ymm3
# bytes: 5 uops: 1
vfmadd231pd %ymm10,%ymm11,%ymm3

# qhasm:   a127 aligned= mem256[const2 + 32]
# asm 1: vmovapd   32(<const2=int64#8),>a127=reg256#5
# asm 2: vmovapd   32(<const2=%r10),>a127=%ymm4
# bytes: 6 uops: 1
vmovapd   32(%r10),%ymm4

# qhasm:   4x c5 = approx D5 + a127
# asm 1: vaddpd <D5=reg256#9,<a127=reg256#5,>c5=reg256#7
# asm 2: vaddpd <D5=%ymm8,<a127=%ymm4,>c5=%ymm6
# bytes: 5 uops: 1
vaddpd %ymm8,%ymm4,%ymm6
# block pos: 2752 2784 uops: 6

# qhasm:   4x c5 approx-= a127
# asm 1: vsubpd <a127=reg256#5,<c5=reg256#7,>c5=reg256#5
# asm 2: vsubpd <a127=%ymm4,<c5=%ymm6,>c5=%ymm4
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm4,%ymm6,%ymm4

# qhasm:   4x D5 approx-= c5 * mem256[const1 + 32]
# asm 1: vfnmadd231pd 32(<const1=int64#7),<c5=reg256#5,<D5=reg256#9
# asm 2: vfnmadd231pd 32(<const1=%rax),<c5=%ymm4,<D5=%ymm8
# bytes: 6 uops: 1
vfnmadd231pd 32(%rax),%ymm4,%ymm8

# qhasm:   a106 aligned= mem256[const2 + 0]
# asm 1: vmovapd   0(<const2=int64#8),>a106=reg256#7
# asm 2: vmovapd   0(<const2=%r10),>a106=%ymm6
# bytes: 5 uops: 1
vmovapd   0(%r10),%ymm6

# qhasm:   4x c4 = approx D4 + a106
# asm 1: vaddpd <D4=reg256#15,<a106=reg256#7,>c4=reg256#11
# asm 2: vaddpd <D4=%ymm14,<a106=%ymm6,>c4=%ymm10
# bytes: 5 uops: 1
vaddpd %ymm14,%ymm6,%ymm10

# qhasm:   4x c4 approx-= a106
# asm 1: vsubpd <a106=reg256#7,<c4=reg256#11,>c4=reg256#7
# asm 2: vsubpd <a106=%ymm6,<c4=%ymm10,>c4=%ymm6
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm6,%ymm10,%ymm6

# qhasm:   4x D5 approx+= c4 * mem256[const1 + 32]
# asm 1: vfmadd231pd 32(<const1=int64#7),<c4=reg256#7,<D5=reg256#9
# asm 2: vfmadd231pd 32(<const1=%rax),<c4=%ymm6,<D5=%ymm8
# bytes: 6 uops: 1
vfmadd231pd 32(%rax),%ymm6,%ymm8
# block pos: 2784 2816 uops: 6

# qhasm:   4x D4 approx-= c4
# asm 1: vsubpd <c4=reg256#7,<D4=reg256#15,>D4=reg256#7
# asm 2: vsubpd <c4=%ymm6,<D4=%ymm14,>D4=%ymm6
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm6,%ymm14,%ymm6

# qhasm:   a85 aligned= mem256[const2 - 32]
# asm 1: vmovapd   -32(<const2=int64#8),>a85=reg256#11
# asm 2: vmovapd   -32(<const2=%r10),>a85=%ymm10
# bytes: 6 uops: 1
vmovapd   -32(%r10),%ymm10

# qhasm:   4x c3 = approx D3 + a85
# asm 1: vaddpd <D3=reg256#10,<a85=reg256#11,>c3=reg256#12
# asm 2: vaddpd <D3=%ymm9,<a85=%ymm10,>c3=%ymm11
# bytes: 5 uops: 1
vaddpd %ymm9,%ymm10,%ymm11

# qhasm:   4x c3 approx-= a85
# asm 1: vsubpd <a85=reg256#11,<c3=reg256#12,>c3=reg256#11
# asm 2: vsubpd <a85=%ymm10,<c3=%ymm11,>c3=%ymm10
# bytes: 5 uops: 1
vsubpd %ymm10,%ymm11,%ymm10

# qhasm:   4x D4 approx+= c3 * mem256[const1 + 32]
# asm 1: vfmadd231pd 32(<const1=int64#7),<c3=reg256#11,<D4=reg256#7
# asm 2: vfmadd231pd 32(<const1=%rax),<c3=%ymm10,<D4=%ymm6
# bytes: 6 uops: 1
vfmadd231pd 32(%rax),%ymm10,%ymm6

# qhasm:   4x D3 approx-= c3
# asm 1: vsubpd <c3=reg256#11,<D3=reg256#10,>D3=reg256#10
# asm 2: vsubpd <c3=%ymm10,<D3=%ymm9,>D3=%ymm9
# bytes: 5 uops: 1
vsubpd %ymm10,%ymm9,%ymm9
# block pos: 2816 2849 uops: 6

# qhasm:   a64 aligned= mem256[const2 - 64]
# asm 1: vmovapd   -64(<const2=int64#8),>a64=reg256#11
# asm 2: vmovapd   -64(<const2=%r10),>a64=%ymm10
# bytes: 6 uops: 1
vmovapd   -64(%r10),%ymm10

# qhasm:   4x c2 = approx D2 + a64
# asm 1: vaddpd <D2=reg256#16,<a64=reg256#11,>c2=reg256#12
# asm 2: vaddpd <D2=%ymm15,<a64=%ymm10,>c2=%ymm11
# bytes: 5 uops: 1
vaddpd %ymm15,%ymm10,%ymm11

# qhasm:   4x c2 approx-= a64
# asm 1: vsubpd <a64=reg256#11,<c2=reg256#12,>c2=reg256#11
# asm 2: vsubpd <a64=%ymm10,<c2=%ymm11,>c2=%ymm10
# bytes: 5 uops: 1
vsubpd %ymm10,%ymm11,%ymm10

# qhasm:   4x D3 approx+= c2 * mem256[const1 + 32]
# asm 1: vfmadd231pd 32(<const1=int64#7),<c2=reg256#11,<D3=reg256#10
# asm 2: vfmadd231pd 32(<const1=%rax),<c2=%ymm10,<D3=%ymm9
# bytes: 6 uops: 1
vfmadd231pd 32(%rax),%ymm10,%ymm9

# qhasm:   4x D2 approx-= c2
# asm 1: vsubpd <c2=reg256#11,<D2=reg256#16,>D2=reg256#11
# asm 2: vsubpd <c2=%ymm10,<D2=%ymm15,>D2=%ymm10
# bytes: 5 uops: 1
vsubpd %ymm10,%ymm15,%ymm10

# qhasm:     mem256[work1 - 32] aligned= D3
# asm 1: vmovapd   <D3=reg256#10,-32(<work1=int64#5)
# asm 2: vmovapd   <D3=%ymm9,-32(<work1=%r8)
# bytes: 6 uops: 1
vmovapd   %ymm9,-32(%r8)
# block pos: 2849 2881 uops: 6

# qhasm:   a43 aligned= mem256[const2 - 96]
# asm 1: vmovapd   -96(<const2=int64#8),>a43=reg256#10
# asm 2: vmovapd   -96(<const2=%r10),>a43=%ymm9
# bytes: 6 uops: 1
vmovapd   -96(%r10),%ymm9

# qhasm:   4x c1 = approx D1 + a43
# asm 1: vaddpd <D1=reg256#8,<a43=reg256#10,>c1=reg256#12
# asm 2: vaddpd <D1=%ymm7,<a43=%ymm9,>c1=%ymm11
# bytes: 4 uops: 1
vaddpd %ymm7,%ymm9,%ymm11

# qhasm:   4x c1 approx-= a43
# asm 1: vsubpd <a43=reg256#10,<c1=reg256#12,>c1=reg256#10
# asm 2: vsubpd <a43=%ymm9,<c1=%ymm11,>c1=%ymm9
# bytes: 5 uops: 1
vsubpd %ymm9,%ymm11,%ymm9

# qhasm:   4x D2 approx+= c1 * mem256[const1 + 32]
# asm 1: vfmadd231pd 32(<const1=int64#7),<c1=reg256#10,<D2=reg256#11
# asm 2: vfmadd231pd 32(<const1=%rax),<c1=%ymm9,<D2=%ymm10
# bytes: 6 uops: 1
vfmadd231pd 32(%rax),%ymm9,%ymm10

# qhasm:   4x D1 approx-= c1
# asm 1: vsubpd <c1=reg256#10,<D1=reg256#8,>D1=reg256#8
# asm 2: vsubpd <c1=%ymm9,<D1=%ymm7,>D1=%ymm7
# bytes: 5 uops: 1
vsubpd %ymm9,%ymm7,%ymm7

# qhasm:     mem256[work1 - 64] aligned= D2
# asm 1: vmovapd   <D2=reg256#11,-64(<work1=int64#5)
# asm 2: vmovapd   <D2=%ymm10,-64(<work1=%r8)
# bytes: 6 uops: 1
vmovapd   %ymm10,-64(%r8)
# block pos: 2881 2912 uops: 6

# qhasm:   a22 aligned= mem256[const2 - 128]
# asm 1: vmovapd   -128(<const2=int64#8),>a22=reg256#10
# asm 2: vmovapd   -128(<const2=%r10),>a22=%ymm9
# bytes: 6 uops: 1
vmovapd   -128(%r10),%ymm9

# qhasm:   4x c0 = approx D0 + a22
# asm 1: vaddpd <D0=reg256#4,<a22=reg256#10,>c0=reg256#11
# asm 2: vaddpd <D0=%ymm3,<a22=%ymm9,>c0=%ymm10
# bytes: 4 uops: 1
vaddpd %ymm3,%ymm9,%ymm10

# qhasm:   4x D0 approx+= c5 * mem256[const1 - 128]
# asm 1: vfmadd231pd -128(<const1=int64#7),<c5=reg256#5,<D0=reg256#4
# asm 2: vfmadd231pd -128(<const1=%rax),<c5=%ymm4,<D0=%ymm3
# bytes: 6 uops: 1
vfmadd231pd -128(%rax),%ymm4,%ymm3

# qhasm:   4x c0 approx-= a22
# asm 1: vsubpd <a22=reg256#10,<c0=reg256#11,>c0=reg256#5
# asm 2: vsubpd <a22=%ymm9,<c0=%ymm10,>c0=%ymm4
# bytes: 5 uops: 1
vsubpd %ymm9,%ymm10,%ymm4

# qhasm:   4x D1 approx+= c0 * mem256[const1 + 32]
# asm 1: vfmadd231pd 32(<const1=int64#7),<c0=reg256#5,<D1=reg256#8
# asm 2: vfmadd231pd 32(<const1=%rax),<c0=%ymm4,<D1=%ymm7
# bytes: 6 uops: 1
vfmadd231pd 32(%rax),%ymm4,%ymm7

# qhasm:   4x D0 approx-= c0
# asm 1: vsubpd <c0=reg256#5,<D0=reg256#4,>D0=reg256#4
# asm 2: vsubpd <c0=%ymm4,<D0=%ymm3,>D0=%ymm3
# bytes: 4 uops: 1
vsubpd %ymm4,%ymm3,%ymm3
# block pos: 2912 2944 uops: 6

# qhasm:     mem256[work1 - 96] aligned= D1
# asm 1: vmovapd   <D1=reg256#8,-96(<work1=int64#5)
# asm 2: vmovapd   <D1=%ymm7,-96(<work1=%r8)
# bytes: 6 uops: 1
vmovapd   %ymm7,-96(%r8)

# qhasm:     mem256[work1 - 128] aligned= D0
# asm 1: vmovapd   <D0=reg256#4,-128(<work1=int64#5)
# asm 2: vmovapd   <D0=%ymm3,-128(<work1=%r8)
# bytes: 6 uops: 1
vmovapd   %ymm3,-128(%r8)

# qhasm:                           a0 aligned= mem256[work0 - 128]
# asm 1: vmovapd   -128(<work0=int64#3),>a0=reg256#4
# asm 2: vmovapd   -128(<work0=%rdx),>a0=%ymm3
# bytes: 5 uops: 1
vmovapd   -128(%rdx),%ymm3

# qhasm:                           C4 aligned= mem256[work2 +   0]
# asm 1: vmovapd   0(<work2=int64#6),>C4=reg256#5
# asm 2: vmovapd   0(<work2=%r9),>C4=%ymm4
# bytes: 5 uops: 1
vmovapd   0(%r9),%ymm4

# qhasm:                           C5 aligned= mem256[work2 +  32]
# asm 1: vmovapd   32(<work2=int64#6),>C5=reg256#8
# asm 2: vmovapd   32(<work2=%r9),>C5=%ymm7
# bytes: 6 uops: 1
vmovapd   32(%r9),%ymm7

# qhasm:                                     4x E0 = approx a0 * C0
# asm 1: vmulpd <a0=reg256#4,<C0=reg256#6,>E0=reg256#10
# asm 2: vmulpd <a0=%ymm3,<C0=%ymm5,>E0=%ymm9
# bytes: 4 uops: 1
vmulpd %ymm3,%ymm5,%ymm9
# block pos: 2944 2976 uops: 6

# qhasm:                                   4x E1 = approx a0 * C1
# asm 1: vmulpd <a0=reg256#4,<C1=reg256#2,>E1=reg256#11
# asm 2: vmulpd <a0=%ymm3,<C1=%ymm1,>E1=%ymm10
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm3,%ymm1,%ymm10

# qhasm:                                 4x E2 = approx a0 * C2
# asm 1: vmulpd <a0=reg256#4,<C2=reg256#1,>E2=reg256#12
# asm 2: vmulpd <a0=%ymm3,<C2=%ymm0,>E2=%ymm11
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm3,%ymm0,%ymm11

# qhasm:                               4x E3 = approx a0 * C3
# asm 1: vmulpd <a0=reg256#4,<C3=reg256#3,>E3=reg256#13
# asm 2: vmulpd <a0=%ymm3,<C3=%ymm2,>E3=%ymm12
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm3,%ymm2,%ymm12

# qhasm:                             4x E4 = approx a0 * C4
# asm 1: vmulpd <a0=reg256#4,<C4=reg256#5,>E4=reg256#14
# asm 2: vmulpd <a0=%ymm3,<C4=%ymm4,>E4=%ymm13
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm3,%ymm4,%ymm13

# qhasm:                           4x E5 = approx a0 * C5
# asm 1: vmulpd <a0=reg256#4,<C5=reg256#8,>E5=reg256#15
# asm 2: vmulpd <a0=%ymm3,<C5=%ymm7,>E5=%ymm14
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm3,%ymm7,%ymm14

# qhasm:                                     127a1 aligned= mem256[work3 + 0]
# asm 1: vmovapd   0(<work3=int64#1),>127a1=reg256#4
# asm 2: vmovapd   0(<work3=%rdi),>127a1=%ymm3
# bytes: 4 uops: 1
vmovapd   0(%rdi),%ymm3
# block pos: 2976 3008 uops: 6

# qhasm:                                     4x E0 approx+= 127a1 * C5
# asm 1: vfmadd231pd <127a1=reg256#4,<C5=reg256#8,<E0=reg256#10
# asm 2: vfmadd231pd <127a1=%ymm3,<C5=%ymm7,<E0=%ymm9
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm3,%ymm7,%ymm9

# qhasm:                           a1 aligned= mem256[work0 - 96]
# asm 1: vmovapd   -96(<work0=int64#3),>a1=reg256#4
# asm 2: vmovapd   -96(<work0=%rdx),>a1=%ymm3
# bytes: 5 uops: 1
vmovapd   -96(%rdx),%ymm3

# qhasm: 			          4x E1 approx+= a1 * C0
# asm 1: vfmadd231pd <a1=reg256#4,<C0=reg256#6,<E1=reg256#11
# asm 2: vfmadd231pd <a1=%ymm3,<C0=%ymm5,<E1=%ymm10
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm3,%ymm5,%ymm10

# qhasm:                                 4x E2 approx+= a1 * C1
# asm 1: vfmadd231pd <a1=reg256#4,<C1=reg256#2,<E2=reg256#12
# asm 2: vfmadd231pd <a1=%ymm3,<C1=%ymm1,<E2=%ymm11
# bytes: 5 uops: 1
vfmadd231pd %ymm3,%ymm1,%ymm11

# qhasm:                               4x E3 approx+= a1 * C2
# asm 1: vfmadd231pd <a1=reg256#4,<C2=reg256#1,<E3=reg256#13
# asm 2: vfmadd231pd <a1=%ymm3,<C2=%ymm0,<E3=%ymm12
# bytes: 5 uops: 1
vfmadd231pd %ymm3,%ymm0,%ymm12

# qhasm:                             4x E4 approx+= a1 * C3
# asm 1: vfmadd231pd <a1=reg256#4,<C3=reg256#3,<E4=reg256#14
# asm 2: vfmadd231pd <a1=%ymm3,<C3=%ymm2,<E4=%ymm13
# bytes: 5 uops: 1
vfmadd231pd %ymm3,%ymm2,%ymm13
# block pos: 3008 3040 uops: 6

# qhasm:                           4x E5 approx+= a1 * C4
# asm 1: vfmadd231pd <a1=reg256#4,<C4=reg256#5,<E5=reg256#15
# asm 2: vfmadd231pd <a1=%ymm3,<C4=%ymm4,<E5=%ymm14
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm3,%ymm4,%ymm14

# qhasm:                                   127a2 aligned= mem256[work3 - 32]
# asm 1: vmovapd   -32(<work3=int64#1),>127a2=reg256#4
# asm 2: vmovapd   -32(<work3=%rdi),>127a2=%ymm3
# bytes: 5 uops: 1
vmovapd   -32(%rdi),%ymm3

# qhasm:                                     4x E0 approx+= 127a2 * C4
# asm 1: vfmadd231pd <127a2=reg256#4,<C4=reg256#5,<E0=reg256#10
# asm 2: vfmadd231pd <127a2=%ymm3,<C4=%ymm4,<E0=%ymm9
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm3,%ymm4,%ymm9

# qhasm:                                   4x E1 approx+= 127a2 * C5
# asm 1: vfmadd231pd <127a2=reg256#4,<C5=reg256#8,<E1=reg256#11
# asm 2: vfmadd231pd <127a2=%ymm3,<C5=%ymm7,<E1=%ymm10
# bytes: 5 uops: 1
vfmadd231pd %ymm3,%ymm7,%ymm10

# qhasm:                           a2 aligned= mem256[work0 - 64]
# asm 1: vmovapd   -64(<work0=int64#3),>a2=reg256#4
# asm 2: vmovapd   -64(<work0=%rdx),>a2=%ymm3
# bytes: 5 uops: 1
vmovapd   -64(%rdx),%ymm3

# qhasm: 			        4x E2 approx+= a2 * C0
# asm 1: vfmadd231pd <a2=reg256#4,<C0=reg256#6,<E2=reg256#12
# asm 2: vfmadd231pd <a2=%ymm3,<C0=%ymm5,<E2=%ymm11
# bytes: 5 uops: 1
vfmadd231pd %ymm3,%ymm5,%ymm11
# block pos: 3040 3072 uops: 6

# qhasm:                               4x E3 approx+= a2 * C1
# asm 1: vfmadd231pd <a2=reg256#4,<C1=reg256#2,<E3=reg256#13
# asm 2: vfmadd231pd <a2=%ymm3,<C1=%ymm1,<E3=%ymm12
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm3,%ymm1,%ymm12

# qhasm:                             4x E4 approx+= a2 * C2
# asm 1: vfmadd231pd <a2=reg256#4,<C2=reg256#1,<E4=reg256#14
# asm 2: vfmadd231pd <a2=%ymm3,<C2=%ymm0,<E4=%ymm13
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm3,%ymm0,%ymm13

# qhasm:                           4x E5 approx+= a2 * C3
# asm 1: vfmadd231pd <a2=reg256#4,<C3=reg256#3,<E5=reg256#15
# asm 2: vfmadd231pd <a2=%ymm3,<C3=%ymm2,<E5=%ymm14
# bytes: 5 uops: 1
vfmadd231pd %ymm3,%ymm2,%ymm14

# qhasm:                                 127a3 aligned= mem256[work3 - 64]
# asm 1: vmovapd   -64(<work3=int64#1),>127a3=reg256#4
# asm 2: vmovapd   -64(<work3=%rdi),>127a3=%ymm3
# bytes: 5 uops: 1
vmovapd   -64(%rdi),%ymm3

# qhasm:                                     4x E0 approx+= 127a3 * C3
# asm 1: vfmadd231pd <127a3=reg256#4,<C3=reg256#3,<E0=reg256#10
# asm 2: vfmadd231pd <127a3=%ymm3,<C3=%ymm2,<E0=%ymm9
# bytes: 5 uops: 1
vfmadd231pd %ymm3,%ymm2,%ymm9

# qhasm:                                   4x E1 approx+= 127a3 * C4
# asm 1: vfmadd231pd <127a3=reg256#4,<C4=reg256#5,<E1=reg256#11
# asm 2: vfmadd231pd <127a3=%ymm3,<C4=%ymm4,<E1=%ymm10
# bytes: 5 uops: 1
vfmadd231pd %ymm3,%ymm4,%ymm10
# block pos: 3072 3104 uops: 6

# qhasm:                                 4x E2 approx+= 127a3 * C5
# asm 1: vfmadd231pd <127a3=reg256#4,<C5=reg256#8,<E2=reg256#12
# asm 2: vfmadd231pd <127a3=%ymm3,<C5=%ymm7,<E2=%ymm11
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm3,%ymm7,%ymm11

# qhasm:                           a3 aligned= mem256[work0 - 32]
# asm 1: vmovapd   -32(<work0=int64#3),>a3=reg256#4
# asm 2: vmovapd   -32(<work0=%rdx),>a3=%ymm3
# bytes: 5 uops: 1
vmovapd   -32(%rdx),%ymm3

# qhasm: 			      4x E3 approx+= a3 * C0
# asm 1: vfmadd231pd <a3=reg256#4,<C0=reg256#6,<E3=reg256#13
# asm 2: vfmadd231pd <a3=%ymm3,<C0=%ymm5,<E3=%ymm12
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm3,%ymm5,%ymm12

# qhasm:                             4x E4 approx+= a3 * C1
# asm 1: vfmadd231pd <a3=reg256#4,<C1=reg256#2,<E4=reg256#14
# asm 2: vfmadd231pd <a3=%ymm3,<C1=%ymm1,<E4=%ymm13
# bytes: 5 uops: 1
vfmadd231pd %ymm3,%ymm1,%ymm13

# qhasm:                           4x E5 approx+= a3 * C2
# asm 1: vfmadd231pd <a3=reg256#4,<C2=reg256#1,<E5=reg256#15
# asm 2: vfmadd231pd <a3=%ymm3,<C2=%ymm0,<E5=%ymm14
# bytes: 5 uops: 1
vfmadd231pd %ymm3,%ymm0,%ymm14

# qhasm:                               127a4 aligned= mem256[work3 - 96]
# asm 1: vmovapd   -96(<work3=int64#1),>127a4=reg256#4
# asm 2: vmovapd   -96(<work3=%rdi),>127a4=%ymm3
# bytes: 5 uops: 1
vmovapd   -96(%rdi),%ymm3
# block pos: 3104 3136 uops: 6

# qhasm:                                     4x E0 approx+= 127a4 * C2
# asm 1: vfmadd231pd <127a4=reg256#4,<C2=reg256#1,<E0=reg256#10
# asm 2: vfmadd231pd <127a4=%ymm3,<C2=%ymm0,<E0=%ymm9
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm3,%ymm0,%ymm9

# qhasm:                                   4x E1 approx+= 127a4 * C3
# asm 1: vfmadd231pd <127a4=reg256#4,<C3=reg256#3,<E1=reg256#11
# asm 2: vfmadd231pd <127a4=%ymm3,<C3=%ymm2,<E1=%ymm10
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm3,%ymm2,%ymm10

# qhasm:                                 4x E2 approx+= 127a4 * C4
# asm 1: vfmadd231pd <127a4=reg256#4,<C4=reg256#5,<E2=reg256#12
# asm 2: vfmadd231pd <127a4=%ymm3,<C4=%ymm4,<E2=%ymm11
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm3,%ymm4,%ymm11

# qhasm:                               4x E3 approx+= 127a4 * C5
# asm 1: vfmadd231pd <127a4=reg256#4,<C5=reg256#8,<E3=reg256#13
# asm 2: vfmadd231pd <127a4=%ymm3,<C5=%ymm7,<E3=%ymm12
# bytes: 5 uops: 1
vfmadd231pd %ymm3,%ymm7,%ymm12

# qhasm:                           a4 aligned= mem256[work0 + 0]
# asm 1: vmovapd   0(<work0=int64#3),>a4=reg256#4
# asm 2: vmovapd   0(<work0=%rdx),>a4=%ymm3
# bytes: 4 uops: 1
vmovapd   0(%rdx),%ymm3

# qhasm: 			    4x E4 approx+= a4 * C0
# asm 1: vfmadd231pd <a4=reg256#4,<C0=reg256#6,<E4=reg256#14
# asm 2: vfmadd231pd <a4=%ymm3,<C0=%ymm5,<E4=%ymm13
# bytes: 5 uops: 1
vfmadd231pd %ymm3,%ymm5,%ymm13
# block pos: 3136 3168 uops: 6

# qhasm:                           4x E5 approx+= a4 * C1
# asm 1: vfmadd231pd <a4=reg256#4,<C1=reg256#2,<E5=reg256#15
# asm 2: vfmadd231pd <a4=%ymm3,<C1=%ymm1,<E5=%ymm14
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm3,%ymm1,%ymm14

# qhasm:                             127a5 aligned= mem256[work3 - 128]
# asm 1: vmovapd   -128(<work3=int64#1),>127a5=reg256#4
# asm 2: vmovapd   -128(<work3=%rdi),>127a5=%ymm3
# bytes: 5 uops: 1
vmovapd   -128(%rdi),%ymm3

# qhasm:                                     4x E0 approx+= 127a5 * C1
# asm 1: vfmadd231pd <127a5=reg256#4,<C1=reg256#2,<E0=reg256#10
# asm 2: vfmadd231pd <127a5=%ymm3,<C1=%ymm1,<E0=%ymm9
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm3,%ymm1,%ymm9

# qhasm:                                   4x E1 approx+= 127a5 * C2
# asm 1: vfmadd231pd <127a5=reg256#4,<C2=reg256#1,<E1=reg256#11
# asm 2: vfmadd231pd <127a5=%ymm3,<C2=%ymm0,<E1=%ymm10
# bytes: 5 uops: 1
vfmadd231pd %ymm3,%ymm0,%ymm10

# qhasm:                                 4x E2 approx+= 127a5 * C3
# asm 1: vfmadd231pd <127a5=reg256#4,<C3=reg256#3,<E2=reg256#12
# asm 2: vfmadd231pd <127a5=%ymm3,<C3=%ymm2,<E2=%ymm11
# bytes: 5 uops: 1
vfmadd231pd %ymm3,%ymm2,%ymm11

# qhasm:                               4x E3 approx+= 127a5 * C4
# asm 1: vfmadd231pd <127a5=reg256#4,<C4=reg256#5,<E3=reg256#13
# asm 2: vfmadd231pd <127a5=%ymm3,<C4=%ymm4,<E3=%ymm12
# bytes: 5 uops: 1
vfmadd231pd %ymm3,%ymm4,%ymm12
# block pos: 3168 3200 uops: 6

# qhasm:                             4x E4 approx+= 127a5 * C5
# asm 1: vfmadd231pd <127a5=reg256#4,<C5=reg256#8,<E4=reg256#14
# asm 2: vfmadd231pd <127a5=%ymm3,<C5=%ymm7,<E4=%ymm13
# bytes: 6 uops: 1
.byte 0x3e
vfmadd231pd %ymm3,%ymm7,%ymm13

# qhasm:                           a5 aligned= mem256[work0 + 32]
# asm 1: vmovapd   32(<work0=int64#3),>a5=reg256#1
# asm 2: vmovapd   32(<work0=%rdx),>a5=%ymm0
# bytes: 5 uops: 1
vmovapd   32(%rdx),%ymm0

# qhasm: 			  4x E5 approx+= a5 * C0
# asm 1: vfmadd231pd <a5=reg256#1,<C0=reg256#6,<E5=reg256#15
# asm 2: vfmadd231pd <a5=%ymm0,<C0=%ymm5,<E5=%ymm14
# bytes: 5 uops: 1
vfmadd231pd %ymm0,%ymm5,%ymm14

# qhasm: 					    a22 aligned= mem256[const2 - 128]
# asm 1: vmovapd   -128(<const2=int64#8),>a22=reg256#1
# asm 2: vmovapd   -128(<const2=%r10),>a22=%ymm0
# bytes: 6 uops: 1
vmovapd   -128(%r10),%ymm0

# qhasm:                                             4x c0 = approx E0 + a22
# asm 1: vaddpd <E0=reg256#10,<a22=reg256#1,>c0=reg256#2
# asm 2: vaddpd <E0=%ymm9,<a22=%ymm0,>c0=%ymm1
# bytes: 5 uops: 1
vaddpd %ymm9,%ymm0,%ymm1

# qhasm:                                             4x c0 approx-= a22
# asm 1: vsubpd <a22=reg256#1,<c0=reg256#2,>c0=reg256#1
# asm 2: vsubpd <a22=%ymm0,<c0=%ymm1,>c0=%ymm0
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm0,%ymm1,%ymm0
# block pos: 3200 3232 uops: 6

# qhasm:                                             4x E1 approx+= c0 *mem256[const1+32]
# asm 1: vfmadd231pd 32(<const1=int64#7),<c0=reg256#1,<E1=reg256#11
# asm 2: vfmadd231pd 32(<const1=%rax),<c0=%ymm0,<E1=%ymm10
# bytes: 6 uops: 1
vfmadd231pd 32(%rax),%ymm0,%ymm10

# qhasm:                                             a64 aligned= mem256[const2 - 64]
# asm 1: vmovapd   -64(<const2=int64#8),>a64=reg256#2
# asm 2: vmovapd   -64(<const2=%r10),>a64=%ymm1
# bytes: 6 uops: 1
vmovapd   -64(%r10),%ymm1

# qhasm:                                             4x c2 = approx E2 + a64
# asm 1: vaddpd <E2=reg256#12,<a64=reg256#2,>c2=reg256#3
# asm 2: vaddpd <E2=%ymm11,<a64=%ymm1,>c2=%ymm2
# bytes: 5 uops: 1
vaddpd %ymm11,%ymm1,%ymm2

# qhasm:                                             4x c2 approx-= a64
# asm 1: vsubpd <a64=reg256#2,<c2=reg256#3,>c2=reg256#2
# asm 2: vsubpd <a64=%ymm1,<c2=%ymm2,>c2=%ymm1
# bytes: 4 uops: 1
vsubpd %ymm1,%ymm2,%ymm1

# qhasm:                                             4x E3 approx+= c2 *mem256[const1+32]
# asm 1: vfmadd231pd 32(<const1=int64#7),<c2=reg256#2,<E3=reg256#13
# asm 2: vfmadd231pd 32(<const1=%rax),<c2=%ymm1,<E3=%ymm12
# bytes: 6 uops: 1
vfmadd231pd 32(%rax),%ymm1,%ymm12

# qhasm:                                             a106 aligned= mem256[const2 + 0]
# asm 1: vmovapd   0(<const2=int64#8),>a106=reg256#3
# asm 2: vmovapd   0(<const2=%r10),>a106=%ymm2
# bytes: 5 uops: 1
vmovapd   0(%r10),%ymm2
# block pos: 3232 3264 uops: 6

# qhasm:                                             4x c4 = approx E4 + a106
# asm 1: vaddpd <E4=reg256#14,<a106=reg256#3,>c4=reg256#4
# asm 2: vaddpd <E4=%ymm13,<a106=%ymm2,>c4=%ymm3
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm13,%ymm2,%ymm3

# qhasm:                                             4x c4 approx-= a106
# asm 1: vsubpd <a106=reg256#3,<c4=reg256#4,>c4=reg256#3
# asm 2: vsubpd <a106=%ymm2,<c4=%ymm3,>c4=%ymm2
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm2,%ymm3,%ymm2

# qhasm:                                             4x E5 approx+= c4 *mem256[const1+32]
# asm 1: vfmadd231pd 32(<const1=int64#7),<c4=reg256#3,<E5=reg256#15
# asm 2: vfmadd231pd 32(<const1=%rax),<c4=%ymm2,<E5=%ymm14
# bytes: 6 uops: 1
vfmadd231pd 32(%rax),%ymm2,%ymm14

# qhasm:                                             4x E0 approx-= c0
# asm 1: vsubpd <c0=reg256#1,<E0=reg256#10,>E0=reg256#1
# asm 2: vsubpd <c0=%ymm0,<E0=%ymm9,>E0=%ymm0
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm0,%ymm9,%ymm0

# qhasm:                                             4x E2 approx-= c2
# asm 1: vsubpd <c2=reg256#2,<E2=reg256#12,>E2=reg256#2
# asm 2: vsubpd <c2=%ymm1,<E2=%ymm11,>E2=%ymm1
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm1,%ymm11,%ymm1

# qhasm:                                             4x E4 approx-= c4
# asm 1: vsubpd <c4=reg256#3,<E4=reg256#14,>E4=reg256#3
# asm 2: vsubpd <c4=%ymm2,<E4=%ymm13,>E4=%ymm2
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm2,%ymm13,%ymm2
# block pos: 3264 3297 uops: 6

# qhasm:   ABCD aligned= mem256[const2 + 64]
# asm 1: vmovapd   64(<const2=int64#8),>ABCD=reg256#5
# asm 2: vmovapd   64(<const2=%r10),>ABCD=%ymm4
# bytes: 6 uops: 1
vmovapd   64(%r10),%ymm4

# qhasm:   4x F5 = approx D5 * ABCD
# asm 1: vmulpd <D5=reg256#9,<ABCD=reg256#5,>F5=reg256#8
# asm 2: vmulpd <D5=%ymm8,<ABCD=%ymm4,>F5=%ymm7
# bytes: 5 uops: 1
vmulpd %ymm8,%ymm4,%ymm7

# qhasm:   4x F4 = approx D4 * ABCD
# asm 1: vmulpd <D4=reg256#7,<ABCD=reg256#5,>F4=reg256#4
# asm 2: vmulpd <D4=%ymm6,<ABCD=%ymm4,>F4=%ymm3
# bytes: 4 uops: 1
vmulpd %ymm6,%ymm4,%ymm3

# qhasm:   4x F3 = approx ABCD * mem256[work1 - 32]
# asm 1: vmulpd -32(<work1=int64#5),<ABCD=reg256#5,>F3=reg256#6
# asm 2: vmulpd -32(<work1=%r8),<ABCD=%ymm4,>F3=%ymm5
# bytes: 6 uops: 1
vmulpd -32(%r8),%ymm4,%ymm5

# qhasm:   4x F2 = approx ABCD * mem256[work1 - 64]
# asm 1: vmulpd -64(<work1=int64#5),<ABCD=reg256#5,>F2=reg256#7
# asm 2: vmulpd -64(<work1=%r8),<ABCD=%ymm4,>F2=%ymm6
# bytes: 6 uops: 1
vmulpd -64(%r8),%ymm4,%ymm6

# qhasm:   4x F1 = approx ABCD * mem256[work1 - 96]
# asm 1: vmulpd -96(<work1=int64#5),<ABCD=reg256#5,>F1=reg256#9
# asm 2: vmulpd -96(<work1=%r8),<ABCD=%ymm4,>F1=%ymm8
# bytes: 6 uops: 1
vmulpd -96(%r8),%ymm4,%ymm8
# block pos: 3297 3331 uops: 6

# qhasm:   4x F0 = approx ABCD * mem256[work1 - 128]
# asm 1: vmulpd -128(<work1=int64#5),<ABCD=reg256#5,>F0=reg256#5
# asm 2: vmulpd -128(<work1=%r8),<ABCD=%ymm4,>F0=%ymm4
# bytes: 6 uops: 1
vmulpd -128(%r8),%ymm4,%ymm4

# qhasm:                                             a127 aligned= mem256[const2 + 32]
# asm 1: vmovapd   32(<const2=int64#8),>a127=reg256#10
# asm 2: vmovapd   32(<const2=%r10),>a127=%ymm9
# bytes: 6 uops: 1
vmovapd   32(%r10),%ymm9

# qhasm:                                             4x c5 = approx E5 + a127
# asm 1: vaddpd <E5=reg256#15,<a127=reg256#10,>c5=reg256#12
# asm 2: vaddpd <E5=%ymm14,<a127=%ymm9,>c5=%ymm11
# bytes: 5 uops: 1
vaddpd %ymm14,%ymm9,%ymm11

# qhasm:                                             4x c5 approx-= a127
# asm 1: vsubpd <a127=reg256#10,<c5=reg256#12,>c5=reg256#12
# asm 2: vsubpd <a127=%ymm9,<c5=%ymm11,>c5=%ymm11
# bytes: 5 uops: 1
vsubpd %ymm9,%ymm11,%ymm11

# qhasm:                                             4x E5 approx-= c5 *mem256[const1+32]
# asm 1: vfnmadd231pd 32(<const1=int64#7),<c5=reg256#12,<E5=reg256#15
# asm 2: vfnmadd231pd 32(<const1=%rax),<c5=%ymm11,<E5=%ymm14
# bytes: 6 uops: 1
vfnmadd231pd 32(%rax),%ymm11,%ymm14

# qhasm:                                             4x E0 approx+= c5 * mem256[const1 - 128]
# asm 1: vfmadd231pd -128(<const1=int64#7),<c5=reg256#12,<E0=reg256#1
# asm 2: vfmadd231pd -128(<const1=%rax),<c5=%ymm11,<E0=%ymm0
# bytes: 6 uops: 1
vfmadd231pd -128(%rax),%ymm11,%ymm0
# block pos: 3331 3364 uops: 6

# qhasm:   4x c5 = approx F5 + a127
# asm 1: vaddpd <F5=reg256#8,<a127=reg256#10,>c5=reg256#12
# asm 2: vaddpd <F5=%ymm7,<a127=%ymm9,>c5=%ymm11
# bytes: 4 uops: 1
vaddpd %ymm7,%ymm9,%ymm11

# qhasm:   4x c5 approx-= a127 *mem256[const1+32]
# asm 1: vfnmadd231pd 32(<const1=int64#7),<a127=reg256#10,<c5=reg256#12
# asm 2: vfnmadd231pd 32(<const1=%rax),<a127=%ymm9,<c5=%ymm11
# bytes: 6 uops: 1
vfnmadd231pd 32(%rax),%ymm9,%ymm11

# qhasm:   4x F5 approx-= c5 *mem256[const1+32]
# asm 1: vfnmadd231pd 32(<const1=int64#7),<c5=reg256#12,<F5=reg256#8
# asm 2: vfnmadd231pd 32(<const1=%rax),<c5=%ymm11,<F5=%ymm7
# bytes: 6 uops: 1
vfnmadd231pd 32(%rax),%ymm11,%ymm7

# qhasm:   4x F0 approx+= c5 * mem256[const1 - 128]
# asm 1: vfmadd231pd -128(<const1=int64#7),<c5=reg256#12,<F0=reg256#5
# asm 2: vfmadd231pd -128(<const1=%rax),<c5=%ymm11,<F0=%ymm4
# bytes: 6 uops: 1
vfmadd231pd -128(%rax),%ymm11,%ymm4

# qhasm:                                             a43 aligned= mem256[const2 - 96]
# asm 1: vmovapd   -96(<const2=int64#8),>a43=reg256#10
# asm 2: vmovapd   -96(<const2=%r10),>a43=%ymm9
# bytes: 6 uops: 1
vmovapd   -96(%r10),%ymm9

# qhasm:                                             4x c1 = approx E1 + a43
# asm 1: vaddpd <E1=reg256#11,<a43=reg256#10,>c1=reg256#12
# asm 2: vaddpd <E1=%ymm10,<a43=%ymm9,>c1=%ymm11
# bytes: 5 uops: 1
vaddpd %ymm10,%ymm9,%ymm11
# block pos: 3364 3397 uops: 6

# qhasm:                                             4x c1 approx-= a43 *mem256[const1+32]
# asm 1: vfnmadd231pd 32(<const1=int64#7),<a43=reg256#10,<c1=reg256#12
# asm 2: vfnmadd231pd 32(<const1=%rax),<a43=%ymm9,<c1=%ymm11
# bytes: 6 uops: 1
vfnmadd231pd 32(%rax),%ymm9,%ymm11

# qhasm:                                             4x E2 approx+= c1
# asm 1: vaddpd <c1=reg256#12,<E2=reg256#2,>E2=reg256#2
# asm 2: vaddpd <c1=%ymm11,<E2=%ymm1,>E2=%ymm1
# bytes: 5 uops: 1
vaddpd %ymm11,%ymm1,%ymm1

# qhasm: 					    4x E1 approx-= c1
# asm 1: vsubpd <c1=reg256#12,<E1=reg256#11,>E1=reg256#10
# asm 2: vsubpd <c1=%ymm11,<E1=%ymm10,>E1=%ymm9
# bytes: 5 uops: 1
vsubpd %ymm11,%ymm10,%ymm9

# qhasm:                                             a85 aligned= mem256[const2 - 32]
# asm 1: vmovapd   -32(<const2=int64#8),>a85=reg256#11
# asm 2: vmovapd   -32(<const2=%r10),>a85=%ymm10
# bytes: 6 uops: 1
vmovapd   -32(%r10),%ymm10

# qhasm:                                             4x c3 = approx E3 + a85
# asm 1: vaddpd <E3=reg256#13,<a85=reg256#11,>c3=reg256#12
# asm 2: vaddpd <E3=%ymm12,<a85=%ymm10,>c3=%ymm11
# bytes: 5 uops: 1
vaddpd %ymm12,%ymm10,%ymm11

# qhasm:                                             4x c3 approx-= a85 *mem256[const1+32]
# asm 1: vfnmadd231pd 32(<const1=int64#7),<a85=reg256#11,<c3=reg256#12
# asm 2: vfnmadd231pd 32(<const1=%rax),<a85=%ymm10,<c3=%ymm11
# bytes: 6 uops: 1
vfnmadd231pd 32(%rax),%ymm10,%ymm11
# block pos: 3397 3428 uops: 6

# qhasm:                                             4x E4 approx+= c3
# asm 1: vaddpd <c3=reg256#12,<E4=reg256#3,>E4=reg256#11
# asm 2: vaddpd <c3=%ymm11,<E4=%ymm2,>E4=%ymm10
# bytes: 5 uops: 1
vaddpd %ymm11,%ymm2,%ymm10

# qhasm: 					    4x E3 approx-= c3
# asm 1: vsubpd <c3=reg256#12,<E3=reg256#13,>E3=reg256#12
# asm 2: vsubpd <c3=%ymm11,<E3=%ymm12,>E3=%ymm11
# bytes: 5 uops: 1
vsubpd %ymm11,%ymm12,%ymm11

# qhasm:                                           4x E0 approx+= E1
# asm 1: vaddpd <E1=reg256#10,<E0=reg256#1,>E0=reg256#3
# asm 2: vaddpd <E1=%ymm9,<E0=%ymm0,>E0=%ymm2
# bytes: 5 uops: 1
vaddpd %ymm9,%ymm0,%ymm2

# qhasm:                                           4x E2 approx+= E3
# asm 1: vaddpd <E3=reg256#12,<E2=reg256#2,>E2=reg256#2
# asm 2: vaddpd <E3=%ymm11,<E2=%ymm1,>E2=%ymm1
# bytes: 5 uops: 1
vaddpd %ymm11,%ymm1,%ymm1

# qhasm:                                           4x E4 approx+= E5
# asm 1: vaddpd <E5=reg256#15,<E4=reg256#11,>E4=reg256#1
# asm 2: vaddpd <E5=%ymm14,<E4=%ymm10,>E4=%ymm0
# bytes: 5 uops: 1
vaddpd %ymm14,%ymm10,%ymm0

# qhasm:   a43 aligned= mem256[const2 - 96]
# asm 1: vmovapd   -96(<const2=int64#8),>a43=reg256#10
# asm 2: vmovapd   -96(<const2=%r10),>a43=%ymm9
# bytes: 6 uops: 1
vmovapd   -96(%r10),%ymm9
# block pos: 3428 3456 uops: 5

# qhasm:   4x c1 = approx F1 + a43
# asm 1: vaddpd <F1=reg256#9,<a43=reg256#10,>c1=reg256#11
# asm 2: vaddpd <F1=%ymm8,<a43=%ymm9,>c1=%ymm10
# bytes: 5 uops: 1
vaddpd %ymm8,%ymm9,%ymm10

# qhasm:   4x c1 approx-= a43 *mem256[const1+32]
# asm 1: vfnmadd231pd 32(<const1=int64#7),<a43=reg256#10,<c1=reg256#11
# asm 2: vfnmadd231pd 32(<const1=%rax),<a43=%ymm9,<c1=%ymm10
# bytes: 6 uops: 1
vfnmadd231pd 32(%rax),%ymm9,%ymm10

# qhasm:   4x F2 approx+= c1 *mem256[const1+32]
# asm 1: vfmadd231pd 32(<const1=int64#7),<c1=reg256#11,<F2=reg256#7
# asm 2: vfmadd231pd 32(<const1=%rax),<c1=%ymm10,<F2=%ymm6
# bytes: 6 uops: 1
vfmadd231pd 32(%rax),%ymm10,%ymm6

# qhasm:   4x F1 approx-= c1
# asm 1: vsubpd <c1=reg256#11,<F1=reg256#9,>F1=reg256#9
# asm 2: vsubpd <c1=%ymm10,<F1=%ymm8,>F1=%ymm8
# bytes: 5 uops: 1
vsubpd %ymm10,%ymm8,%ymm8

# qhasm:   a85 aligned= mem256[const2 - 32]
# asm 1: vmovapd   -32(<const2=int64#8),>a85=reg256#10
# asm 2: vmovapd   -32(<const2=%r10),>a85=%ymm9
# bytes: 6 uops: 1
vmovapd   -32(%r10),%ymm9
# block pos: 3456 3488 uops: 6

# qhasm:   4x c3 = approx F3 + a85
# asm 1: vaddpd <F3=reg256#6,<a85=reg256#10,>c3=reg256#11
# asm 2: vaddpd <F3=%ymm5,<a85=%ymm9,>c3=%ymm10
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm5,%ymm9,%ymm10

# qhasm:   4x c3 approx-= a85 *mem256[const1+32]
# asm 1: vfnmadd231pd 32(<const1=int64#7),<a85=reg256#10,<c3=reg256#11
# asm 2: vfnmadd231pd 32(<const1=%rax),<a85=%ymm9,<c3=%ymm10
# bytes: 6 uops: 1
vfnmadd231pd 32(%rax),%ymm9,%ymm10

# qhasm:   4x F4 approx+= c3 *mem256[const1+32]
# asm 1: vfmadd231pd 32(<const1=int64#7),<c3=reg256#11,<F4=reg256#4
# asm 2: vfmadd231pd 32(<const1=%rax),<c3=%ymm10,<F4=%ymm3
# bytes: 6 uops: 1
vfmadd231pd 32(%rax),%ymm10,%ymm3

# qhasm:   4x F3 approx-= c3
# asm 1: vsubpd <c3=reg256#11,<F3=reg256#6,>F3=reg256#10
# asm 2: vsubpd <c3=%ymm10,<F3=%ymm5,>F3=%ymm9
# bytes: 5 uops: 1
vsubpd %ymm10,%ymm5,%ymm9

# qhasm:   4x F0 approx+= F1
# asm 1: vaddpd <F1=reg256#9,<F0=reg256#5,>F0=reg256#6
# asm 2: vaddpd <F1=%ymm8,<F0=%ymm4,>F0=%ymm5
# bytes: 5 uops: 1
vaddpd %ymm8,%ymm4,%ymm5

# qhasm:   4x F2 approx+= F3
# asm 1: vaddpd <F3=reg256#10,<F2=reg256#7,>F2=reg256#5
# asm 2: vaddpd <F3=%ymm9,<F2=%ymm6,>F2=%ymm4
# bytes: 5 uops: 1
vaddpd %ymm9,%ymm6,%ymm4
# block pos: 3488 3520 uops: 6

# qhasm:   4x F4 approx+= F5 *mem256[const1+32]
# asm 1: vfmadd231pd 32(<const1=int64#7),<F5=reg256#8,<F4=reg256#4
# asm 2: vfmadd231pd 32(<const1=%rax),<F5=%ymm7,<F4=%ymm3
# bytes: 6 uops: 1
vfmadd231pd 32(%rax),%ymm7,%ymm3

# qhasm:                   signed<? pos - 0
# asm 1: cmp  $0,<pos=int64#9
# asm 2: cmp  $0,<pos=%r11
# bytes: 4 uops: 1
cmp  $0,%r11
# comment:fp stack unchanged by jump

# qhasm: goto mainloop if !signed<
# bytes: 6 uops: 1
jge ._mainloop

# qhasm:   prevbit -= 1
# asm 1: sub  $1,<prevbit=int64#10
# asm 2: sub  $1,<prevbit=%r12
# bytes: 4 uops: 1
sub  $1,%r12

# qhasm:   b_stack = prevbit
# asm 1: movq <prevbit=int64#10,>b_stack=stack64#8
# asm 2: movq <prevbit=%r12,>b_stack=824(%rsp)
# bytes: 8 uops: 1
movq %r12,824(%rsp)

# qhasm:   t4 = F4 ^ E4
# asm 1: vxorpd <F4=reg256#4,<E4=reg256#1,>t4=reg256#4
# asm 2: vxorpd <F4=%ymm3,<E4=%ymm0,>t4=%ymm3
# bytes: 4 uops: 1
vxorpd %ymm3,%ymm0,%ymm3
# block pos: 3520 3552 uops: 6

# qhasm:   t2 = F2 ^ E2
# asm 1: vxorpd <F2=reg256#5,<E2=reg256#2,>t2=reg256#5
# asm 2: vxorpd <F2=%ymm4,<E2=%ymm1,>t2=%ymm4
# bytes: 5 uops: 1
.byte 0x3e
vxorpd %ymm4,%ymm1,%ymm4

# qhasm:   t0 = F0 ^ E0
# asm 1: vxorpd <F0=reg256#6,<E0=reg256#3,>t0=reg256#6
# asm 2: vxorpd <F0=%ymm5,<E0=%ymm2,>t0=%ymm5
# bytes: 5 uops: 1
.byte 0x3e
vxorpd %ymm5,%ymm2,%ymm5

# qhasm:   b = b_stack,b_stack,b_stack,b_stack
# asm 1: vbroadcastsd <b_stack=stack64#8,>b=reg256#7
# asm 2: vbroadcastsd <b_stack=824(%rsp),>b=%ymm6
# bytes: 10 uops: 1
vbroadcastsd 824(%rsp),%ymm6

# qhasm:   t4 &= b
# asm 1: vandpd <b=reg256#7,<t4=reg256#4,<t4=reg256#4
# asm 2: vandpd <b=%ymm6,<t4=%ymm3,<t4=%ymm3
# bytes: 4 uops: 1
vandpd %ymm6,%ymm3,%ymm3

# qhasm:   E4 ^= t4
# asm 1: vxorpd <t4=reg256#4,<E4=reg256#1,<E4=reg256#1
# asm 2: vxorpd <t4=%ymm3,<E4=%ymm0,<E4=%ymm0
# bytes: 4 uops: 1
vxorpd %ymm3,%ymm0,%ymm0

# qhasm:   t2 &= b
# asm 1: vandpd <b=reg256#7,<t2=reg256#5,<t2=reg256#5
# asm 2: vandpd <b=%ymm6,<t2=%ymm4,<t2=%ymm4
# bytes: 4 uops: 1
vandpd %ymm6,%ymm4,%ymm4
# block pos: 3552 3584 uops: 6

# qhasm:   E2 ^= t2
# asm 1: vxorpd <t2=reg256#5,<E2=reg256#2,<E2=reg256#2
# asm 2: vxorpd <t2=%ymm4,<E2=%ymm1,<E2=%ymm1
# bytes: 5 uops: 1
.byte 0x3e
vxorpd %ymm4,%ymm1,%ymm1

# qhasm:   t0 &= b
# asm 1: vandpd <b=reg256#7,<t0=reg256#6,<t0=reg256#6
# asm 2: vandpd <b=%ymm6,<t0=%ymm5,<t0=%ymm5
# bytes: 5 uops: 1
.byte 0x3e
vandpd %ymm6,%ymm5,%ymm5

# qhasm:   E0 ^= t0
# asm 1: vxorpd <t0=reg256#6,<E0=reg256#3,<E0=reg256#3
# asm 2: vxorpd <t0=%ymm5,<E0=%ymm2,<E0=%ymm2
# bytes: 5 uops: 1
.byte 0x3e
vxorpd %ymm5,%ymm2,%ymm2

# qhasm:   mem256[work1 + 0] aligned= E4
# asm 1: vmovapd   <E4=reg256#1,0(<work1=int64#5)
# asm 2: vmovapd   <E4=%ymm0,0(<work1=%r8)
# bytes: 5 uops: 1
vmovapd   %ymm0,0(%r8)

# qhasm:   mem256[work1 - 64] aligned= E2
# asm 1: vmovapd   <E2=reg256#2,-64(<work1=int64#5)
# asm 2: vmovapd   <E2=%ymm1,-64(<work1=%r8)
# bytes: 6 uops: 1
vmovapd   %ymm1,-64(%r8)

# qhasm:   mem256[work1 - 128] aligned= E0
# asm 1: vmovapd   <E0=reg256#3,-128(<work1=int64#5)
# asm 2: vmovapd   <E0=%ymm2,-128(<work1=%r8)
# bytes: 6 uops: 1
vmovapd   %ymm2,-128(%r8)
# block pos: 3584 3616 uops: 4

# qhasm:   caller_r11 = stack_r11
# asm 1: movq <stack_r11=stack64#1,>caller_r11=int64#9
# asm 2: movq <stack_r11=768(%rsp),>caller_r11=%r11
# bytes: 8 uops: 1
movq 768(%rsp),%r11

# qhasm:   caller_r12 = stack_r12
# asm 1: movq <stack_r12=stack64#2,>caller_r12=int64#10
# asm 2: movq <stack_r12=776(%rsp),>caller_r12=%r12
# bytes: 8 uops: 1
movq 776(%rsp),%r12

# qhasm:   caller_r13 = stack_r13
# asm 1: movq <stack_r13=stack64#3,>caller_r13=int64#11
# asm 2: movq <stack_r13=784(%rsp),>caller_r13=%r13
# bytes: 8 uops: 1
movq 784(%rsp),%r13

# qhasm:   caller_r14 = stack_r14
# asm 1: movq <stack_r14=stack64#4,>caller_r14=int64#12
# asm 2: movq <stack_r14=792(%rsp),>caller_r14=%r14
# bytes: 8 uops: 1
movq 792(%rsp),%r14
# block pos: 3616 3644 uops: 5

# qhasm:   caller_r15 = stack_r15
# asm 1: movq <stack_r15=stack64#5,>caller_r15=int64#13
# asm 2: movq <stack_r15=800(%rsp),>caller_r15=%r15
# bytes: 8 uops: 1
movq 800(%rsp),%r15

# qhasm:   caller_rbx = stack_rbx
# asm 1: movq <stack_rbx=stack64#6,>caller_rbx=int64#14
# asm 2: movq <stack_rbx=808(%rsp),>caller_rbx=%rbx
# bytes: 8 uops: 1
movq 808(%rsp),%rbx

# qhasm:   caller_rbp = stack_rbp
# asm 1: movq <stack_rbp=stack64#7,>caller_rbp=int64#15
# asm 2: movq <stack_rbp=816(%rsp),>caller_rbp=%rbp
# bytes: 8 uops: 1
movq 816(%rsp),%rbp

# qhasm: return
# bytes: 3 uops: 1
add %r11,%rsp
# bytes: 1 uops: 1
ret
