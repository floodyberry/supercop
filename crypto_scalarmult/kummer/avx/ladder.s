# block pos: 0 33 uops: 6

# qhasm: int64 input_0

# qhasm: int64 input_1

# qhasm: int64 input_2

# qhasm: int64 input_3

# qhasm: int64 input_4

# qhasm: int64 input_5

# qhasm: stack64 input_6

# qhasm: stack64 input_7

# qhasm: int64 caller_r11

# qhasm: int64 caller_r12

# qhasm: int64 caller_r13

# qhasm: int64 caller_r14

# qhasm: int64 caller_r15

# qhasm: int64 caller_rbx

# qhasm: int64 caller_rbp

# qhasm: stack64 stack_r11

# qhasm: stack64 stack_r12

# qhasm: stack64 stack_r13

# qhasm: stack64 stack_r14

# qhasm: stack64 stack_r15

# qhasm: stack64 stack_rbx

# qhasm: stack64 stack_rbp

# qhasm: int64 pos

# qhasm: int64 i

# qhasm: int64 j

# qhasm: int64 bit

# qhasm: int64 prevbit

# qhasm: reg256 x0

# qhasm: reg256 x1

# qhasm: reg256 x2

# qhasm: reg256 x3

# qhasm: reg256 x4

# qhasm: reg256 x5

# qhasm: reg256 y0

# qhasm: reg256 y1

# qhasm: reg256 y2

# qhasm: reg256 y3

# qhasm: reg256 y4

# qhasm: reg256 y5

# qhasm: reg256 b

# qhasm: reg256 two

# qhasm: reg256 2p22

# qhasm: reg256 2p43

# qhasm: reg256 2p64

# qhasm: reg256 2p85

# qhasm: reg256 2p106

# qhasm: reg256 2p127

# qhasm: reg256 2pm22

# qhasm: reg256 2pm43

# qhasm: reg256 2pm64

# qhasm: reg256 2pm85

# qhasm: reg256 2pm106

# qhasm: reg256 2pm127

# qhasm: reg256 a22

# qhasm: reg256 a43

# qhasm: reg256 a64

# qhasm: reg256 a85

# qhasm: reg256 a106

# qhasm: reg256 a127

# qhasm: reg256 abcd

# qhasm: reg256 ABCD

# qhasm: int64 const0

# qhasm: stack2048 const0_storage

# qhasm: int64 const1

# qhasm: stack2048 const1_storage

# qhasm: int64 const2

# qhasm: stack2048 const2_storage

# qhasm: int64 work0

# qhasm: int64 work1

# qhasm: int64 work2

# qhasm: int64 work3

# qhasm: reg256 P0

# qhasm: reg256 P1

# qhasm: reg256 P2

# qhasm: reg256 P3

# qhasm: reg256 P4

# qhasm: reg256 P5

# qhasm: reg256 Q0

# qhasm: reg256 Q1

# qhasm: reg256 Q2

# qhasm: reg256 Q3

# qhasm: reg256 Q4

# qhasm: reg256 Q5

# qhasm: reg256 H0

# qhasm: reg256 H1

# qhasm: reg256 H2

# qhasm: reg256 H3

# qhasm: reg256 H4

# qhasm: reg256 H5

# qhasm: reg256 I0

# qhasm: reg256 I1

# qhasm: reg256 I2

# qhasm: reg256 I3

# qhasm: reg256 I4

# qhasm: reg256 I5

# qhasm: reg256 R0

# qhasm: reg256 R1

# qhasm: reg256 R2

# qhasm: reg256 R3

# qhasm: reg256 R4

# qhasm: reg256 R5

# qhasm: reg256 S0

# qhasm: reg256 S1

# qhasm: reg256 S2

# qhasm: reg256 S3

# qhasm: reg256 S4

# qhasm: reg256 S5

# qhasm: reg256 A0

# qhasm: reg256 A1

# qhasm: reg256 A2

# qhasm: reg256 A3

# qhasm: reg256 A4

# qhasm: reg256 A5

# qhasm: reg256 B0

# qhasm: reg256 B1

# qhasm: reg256 B2

# qhasm: reg256 B3

# qhasm: reg256 B4

# qhasm: reg256 B5

# qhasm: reg256 C0

# qhasm: reg256 C1

# qhasm: reg256 C2

# qhasm: reg256 C3

# qhasm: reg256 C4

# qhasm: reg256 C5

# qhasm: reg256 D0

# qhasm: reg256 D1

# qhasm: reg256 D2

# qhasm: reg256 D3

# qhasm: reg256 D4

# qhasm: reg256 D5

# qhasm: reg256 E0

# qhasm: reg256 E1

# qhasm: reg256 E2

# qhasm: reg256 E3

# qhasm: reg256 E4

# qhasm: reg256 E5

# qhasm: reg256 F0

# qhasm: reg256 F1

# qhasm: reg256 F2

# qhasm: reg256 F3

# qhasm: reg256 F4

# qhasm: reg256 F5

# qhasm: reg256 xyzt0

# qhasm: reg256 yxtz0

# qhasm: reg256 abcd0

# qhasm: reg256 cdab0

# qhasm: reg256 badc0

# qhasm: reg256 xtzy0

# qhasm: reg256 xyzt1

# qhasm: reg256 yxtz1

# qhasm: reg256 abcd1

# qhasm: reg256 cdab1

# qhasm: reg256 badc1

# qhasm: reg256 xtzy1

# qhasm: reg256 xyzt2

# qhasm: reg256 yxtz2

# qhasm: reg256 abcd2

# qhasm: reg256 cdab2

# qhasm: reg256 badc2

# qhasm: reg256 xtzy2

# qhasm: reg256 xyzt3

# qhasm: reg256 yxtz3

# qhasm: reg256 abcd3

# qhasm: reg256 cdab3

# qhasm: reg256 badc3

# qhasm: reg256 xtzy3

# qhasm: reg256 xyzt4

# qhasm: reg256 yxtz4

# qhasm: reg256 abcd4

# qhasm: reg256 cdab4

# qhasm: reg256 badc4

# qhasm: reg256 xtzy4

# qhasm: reg256 xyzt5

# qhasm: reg256 yxtz5

# qhasm: reg256 abcd5

# qhasm: reg256 cdab5

# qhasm: reg256 badc5

# qhasm: reg256 xtzy5

# qhasm: reg256 a0

# qhasm: reg256 a1

# qhasm: reg256 a2

# qhasm: reg256 a3

# qhasm: reg256 a4

# qhasm: reg256 a5

# qhasm: reg256 const

# qhasm: reg256 c0

# qhasm: reg256 c1

# qhasm: reg256 c2

# qhasm: reg256 c3

# qhasm: reg256 c4

# qhasm: reg256 c5

# qhasm: reg256 r0

# qhasm: reg256 r1

# qhasm: reg256 r2

# qhasm: reg256 r3

# qhasm: reg256 r4

# qhasm: reg256 r5

# qhasm: reg256 2Q0

# qhasm: reg256 2Q1

# qhasm: reg256 2Q2

# qhasm: reg256 2Q3

# qhasm: reg256 2Q4

# qhasm: reg256 2Q5

# qhasm: reg256 2a0

# qhasm: reg256 2a1

# qhasm: reg256 2a2

# qhasm: reg256 2a3

# qhasm: reg256 2a4

# qhasm: reg256 2a5

# qhasm: reg256 2A0

# qhasm: reg256 2A1

# qhasm: reg256 2A2

# qhasm: reg256 2A3

# qhasm: reg256 2A4

# qhasm: reg256 2A5

# qhasm: reg256 2B0

# qhasm: reg256 2B1

# qhasm: reg256 2B2

# qhasm: reg256 2B3

# qhasm: reg256 2B4

# qhasm: reg256 2B5

# qhasm: reg256 a0a0

# qhasm: reg256 a1a1

# qhasm: reg256 a2a2

# qhasm: reg256 2a0a1

# qhasm: reg256 2a0a2

# qhasm: reg256 2a0a3

# qhasm: reg256 2a0a4

# qhasm: reg256 2a1a2

# qhasm: reg256 2a1a3

# qhasm: reg256 2a1a4

# qhasm: reg256 2a1a5

# qhasm: reg256 2a2a3

# qhasm: reg256 2a2a4

# qhasm: reg256 2a2a5

# qhasm: reg256 2a3a5

# qhasm: reg256 Q0Q0

# qhasm: reg256 Q1Q1

# qhasm: reg256 Q2Q2

# qhasm: reg256 Q3Q3

# qhasm: reg256 Q4Q4

# qhasm: reg256 Q5Q5

# qhasm: reg256 2Q0Q1

# qhasm: reg256 2Q0Q2

# qhasm: reg256 2Q0Q3

# qhasm: reg256 2Q0Q4

# qhasm: reg256 2Q0Q5

# qhasm: reg256 2Q1Q2

# qhasm: reg256 2Q1Q3

# qhasm: reg256 2Q1Q4

# qhasm: reg256 2Q1Q5

# qhasm: reg256 2Q2Q3

# qhasm: reg256 2Q2Q4

# qhasm: reg256 2Q2Q5

# qhasm: reg256 2Q3Q4

# qhasm: reg256 2Q3Q5

# qhasm: reg256 2Q4Q5

# qhasm: reg256 B0B0

# qhasm: reg256 B1B1

# qhasm: reg256 B2B2

# qhasm: reg256 B3B3

# qhasm: reg256 B4B4

# qhasm: reg256 B5B5

# qhasm: reg256 2B0B1

# qhasm: reg256 2B0B2

# qhasm: reg256 2B0B3

# qhasm: reg256 2B0B4

# qhasm: reg256 2B0B5

# qhasm: reg256 2B1B2

# qhasm: reg256 2B1B3

# qhasm: reg256 2B1B4

# qhasm: reg256 2B1B5

# qhasm: reg256 2B2B3

# qhasm: reg256 2B2B4

# qhasm: reg256 2B2B5

# qhasm: reg256 2B3B4

# qhasm: reg256 2B3B5

# qhasm: reg256 2B4B5

# qhasm: reg256 127Q1

# qhasm: reg256 127Q2

# qhasm: reg256 127Q3

# qhasm: reg256 127Q4

# qhasm: reg256 127Q5

# qhasm: reg256 127B1

# qhasm: reg256 127B2

# qhasm: reg256 127B3

# qhasm: reg256 127B4

# qhasm: reg256 127B5

# qhasm: reg256 127I1

# qhasm: reg256 127I2

# qhasm: reg256 127I3

# qhasm: reg256 127I4

# qhasm: reg256 127I5

# qhasm: reg256 127a1

# qhasm: reg256 127a2

# qhasm: reg256 127a3

# qhasm: reg256 127a4

# qhasm: reg256 127a5

# qhasm: reg256 b0

# qhasm: reg256 b1

# qhasm: reg256 b2

# qhasm: reg256 b3

# qhasm: reg256 b4

# qhasm: reg256 b5

# qhasm: reg256 a0b0

# qhasm: reg256 a0b1

# qhasm: reg256 a0b2

# qhasm: reg256 a0b3

# qhasm: reg256 a0b4

# qhasm: reg256 a0b5

# qhasm: reg256 a1b0

# qhasm: reg256 a1b1

# qhasm: reg256 a1b2

# qhasm: reg256 a1b3

# qhasm: reg256 a1b4

# qhasm: reg256 a1b5

# qhasm: reg256 a2b0

# qhasm: reg256 a2b1

# qhasm: reg256 a2b2

# qhasm: reg256 a2b3

# qhasm: reg256 a2b4

# qhasm: reg256 a2b5

# qhasm: reg256 a3b0

# qhasm: reg256 a3b1

# qhasm: reg256 a3b2

# qhasm: reg256 a3b3

# qhasm: reg256 a3b4

# qhasm: reg256 a3b5

# qhasm: reg256 a4b0

# qhasm: reg256 a4b1

# qhasm: reg256 a4b2

# qhasm: reg256 a4b3

# qhasm: reg256 a4b4

# qhasm: reg256 a4b5

# qhasm: reg256 a5b0

# qhasm: reg256 a5b1

# qhasm: reg256 a5b2

# qhasm: reg256 a5b3

# qhasm: reg256 a5b4

# qhasm: reg256 a5b5

# qhasm: stack256 127I1_stack

# qhasm: stack256 127I2_stack

# qhasm: stack256 127I3_stack

# qhasm: stack256 127I4_stack

# qhasm: stack256 127I5_stack

# qhasm: enter ladder
.p2align 5
.global _ladder
.global ladder
_ladder:
ladder:
# bytes: 3 uops: 1
mov %rsp,%r11
# bytes: 4 uops: 1
and $31,%r11
# bytes: 7 uops: 1
add $960,%r11
# bytes: 3 uops: 1
sub %r11,%rsp

# qhasm:   stack_r11 = caller_r11
# asm 1: movq <caller_r11=int64#9,>stack_r11=stack64#1
# asm 2: movq <caller_r11=%r11,>stack_r11=896(%rsp)
# bytes: 8 uops: 1
movq %r11,896(%rsp)

# qhasm:   stack_r12 = caller_r12
# asm 1: movq <caller_r12=int64#10,>stack_r12=stack64#2
# asm 2: movq <caller_r12=%r12,>stack_r12=904(%rsp)
# bytes: 8 uops: 1
movq %r12,904(%rsp)
# block pos: 33 65 uops: 4

# qhasm:   stack_r13 = caller_r13
# asm 1: movq <caller_r13=int64#11,>stack_r13=stack64#3
# asm 2: movq <caller_r13=%r13,>stack_r13=912(%rsp)
# bytes: 8 uops: 1
movq %r13,912(%rsp)

# qhasm:   stack_r14 = caller_r14
# asm 1: movq <caller_r14=int64#12,>stack_r14=stack64#4
# asm 2: movq <caller_r14=%r14,>stack_r14=920(%rsp)
# bytes: 8 uops: 1
movq %r14,920(%rsp)

# qhasm:   stack_r15 = caller_r15
# asm 1: movq <caller_r15=int64#13,>stack_r15=stack64#5
# asm 2: movq <caller_r15=%r15,>stack_r15=928(%rsp)
# bytes: 8 uops: 1
movq %r15,928(%rsp)

# qhasm:   stack_rbx = caller_rbx
# asm 1: movq <caller_rbx=int64#14,>stack_rbx=stack64#6
# asm 2: movq <caller_rbx=%rbx,>stack_rbx=936(%rsp)
# bytes: 8 uops: 1
movq %rbx,936(%rsp)
# block pos: 65 101 uops: 5

# qhasm:   stack_rbp = caller_rbp
# asm 1: movq <caller_rbp=int64#15,>stack_rbp=stack64#7
# asm 2: movq <caller_rbp=%rbp,>stack_rbp=944(%rsp)
# bytes: 8 uops: 1
movq %rbp,944(%rsp)

# qhasm:   work0 = input_0 + 128
# asm 1: lea  128(<input_0=int64#1),>work0=int64#3
# asm 2: lea  128(<input_0=%rdi),>work0=%rdx
# bytes: 7 uops: 1
lea  128(%rdi),%rdx

# qhasm:   work1 = input_0 + 320
# asm 1: lea  320(<input_0=int64#1),>work1=int64#5
# asm 2: lea  320(<input_0=%rdi),>work1=%r8
# bytes: 7 uops: 1
lea  320(%rdi),%r8

# qhasm:   work2 = input_0 + 512
# asm 1: lea  512(<input_0=int64#1),>work2=int64#6
# asm 2: lea  512(<input_0=%rdi),>work2=%r9
# bytes: 7 uops: 1
lea  512(%rdi),%r9

# qhasm:   work3 = input_0 + 704
# asm 1: lea  704(<input_0=int64#1),>work3=int64#1
# asm 2: lea  704(<input_0=%rdi),>work3=%rdi
# bytes: 7 uops: 1
lea  704(%rdi),%rdi
# block pos: 101 130 uops: 4

# qhasm:   new const0_storage

# qhasm:   new const1_storage

# qhasm:   new const2_storage

# qhasm:   const0 = &const0_storage
# asm 1: leaq <const0_storage=stack2048#1,>const0=int64#7
# asm 2: leaq <const0_storage=128(%rsp),>const0=%rax
# bytes: 8 uops: 1
leaq 128(%rsp),%rax

# qhasm:   const0 += 128
# asm 1: add  $128,<const0=int64#7
# asm 2: add  $128,<const0=%rax
# bytes: 6 uops: 1
add  $128,%rax

# qhasm:   const1 = &const1_storage
# asm 1: leaq <const1_storage=stack2048#2,>const1=int64#8
# asm 2: leaq <const1_storage=384(%rsp),>const1=%r10
# bytes: 8 uops: 1
leaq 384(%rsp),%r10

# qhasm:   const1 += 128
# asm 1: add  $128,<const1=int64#8
# asm 2: add  $128,<const1=%r10
# bytes: 7 uops: 1
add  $128,%r10
# block pos: 130 163 uops: 4

# qhasm:   const2 = &const2_storage
# asm 1: leaq <const2_storage=stack2048#3,>const2=int64#9
# asm 2: leaq <const2_storage=640(%rsp),>const2=%r11
# bytes: 8 uops: 1
leaq 640(%rsp),%r11

# qhasm:   const2 += 128
# asm 1: add  $128,<const2=int64#9
# asm 2: add  $128,<const2=%r11
# bytes: 7 uops: 1
add  $128,%r11

# qhasm:   2p22 aligned= mem256[_2p22]
# asm 1: vmovapd _2p22,>2p22=reg256#1
# asm 2: vmovapd _2p22,>2p22=%ymm0
# bytes: 9 uops: 1
vmovapd _2p22,%ymm0

# qhasm:   2p43 aligned= mem256[_2p43]
# asm 1: vmovapd _2p43,>2p43=reg256#2
# asm 2: vmovapd _2p43,>2p43=%ymm1
# bytes: 9 uops: 1
vmovapd _2p43,%ymm1
# block pos: 163 199 uops: 4

# qhasm:   2p64 aligned= mem256[_2p64]
# asm 1: vmovapd _2p64,>2p64=reg256#3
# asm 2: vmovapd _2p64,>2p64=%ymm2
# bytes: 9 uops: 1
vmovapd _2p64,%ymm2

# qhasm:   2p85 aligned= mem256[_2p85]
# asm 1: vmovapd _2p85,>2p85=reg256#4
# asm 2: vmovapd _2p85,>2p85=%ymm3
# bytes: 9 uops: 1
vmovapd _2p85,%ymm3

# qhasm:   2p106 aligned= mem256[_2p106]
# asm 1: vmovapd _2p106,>2p106=reg256#5
# asm 2: vmovapd _2p106,>2p106=%ymm4
# bytes: 9 uops: 1
vmovapd _2p106,%ymm4

# qhasm:   2p127 aligned= mem256[_2p127]
# asm 1: vmovapd _2p127,>2p127=reg256#6
# asm 2: vmovapd _2p127,>2p127=%ymm5
# bytes: 9 uops: 1
vmovapd _2p127,%ymm5
# block pos: 199 226 uops: 3

# qhasm:   2pm22 aligned= mem256[_2pm22]
# asm 1: vmovapd _2pm22,>2pm22=reg256#7
# asm 2: vmovapd _2pm22,>2pm22=%ymm6
# bytes: 9 uops: 1
vmovapd _2pm22,%ymm6

# qhasm:   2pm43 aligned= mem256[_2pm43]
# asm 1: vmovapd _2pm43,>2pm43=reg256#8
# asm 2: vmovapd _2pm43,>2pm43=%ymm7
# bytes: 9 uops: 1
vmovapd _2pm43,%ymm7

# qhasm:   2pm64 aligned= mem256[_2pm64]
# asm 1: vmovapd _2pm64,>2pm64=reg256#9
# asm 2: vmovapd _2pm64,>2pm64=%ymm8
# bytes: 9 uops: 1
vmovapd _2pm64,%ymm8
# block pos: 226 258 uops: 4

# qhasm:   2pm85 aligned= mem256[_2pm85]
# asm 1: vmovapd _2pm85,>2pm85=reg256#10
# asm 2: vmovapd _2pm85,>2pm85=%ymm9
# bytes: 9 uops: 1
vmovapd _2pm85,%ymm9

# qhasm:   2pm106 aligned= mem256[_2pm106]
# asm 1: vmovapd _2pm106,>2pm106=reg256#11
# asm 2: vmovapd _2pm106,>2pm106=%ymm10
# bytes: 9 uops: 1
vmovapd _2pm106,%ymm10

# qhasm:   two aligned= mem256[_two]
# asm 1: vmovapd _two,>two=reg256#12
# asm 2: vmovapd _two,>two=%ymm11
# bytes: 9 uops: 1
vmovapd _two,%ymm11

# qhasm:   mem256[const0 - 128] aligned= 2p22
# asm 1: vmovapd   <2p22=reg256#1,-128(<const0=int64#7)
# asm 2: vmovapd   <2p22=%ymm0,-128(<const0=%rax)
# bytes: 5 uops: 1
vmovapd   %ymm0,-128(%rax)
# block pos: 258 292 uops: 7

# qhasm:   mem256[const0 - 96] aligned= 2p43
# asm 1: vmovapd   <2p43=reg256#2,-96(<const0=int64#7)
# asm 2: vmovapd   <2p43=%ymm1,-96(<const0=%rax)
# bytes: 5 uops: 1
vmovapd   %ymm1,-96(%rax)

# qhasm:   mem256[const0 - 64] aligned= 2p64
# asm 1: vmovapd   <2p64=reg256#3,-64(<const0=int64#7)
# asm 2: vmovapd   <2p64=%ymm2,-64(<const0=%rax)
# bytes: 5 uops: 1
vmovapd   %ymm2,-64(%rax)

# qhasm:   mem256[const0 - 32] aligned= 2p85
# asm 1: vmovapd   <2p85=reg256#4,-32(<const0=int64#7)
# asm 2: vmovapd   <2p85=%ymm3,-32(<const0=%rax)
# bytes: 5 uops: 1
vmovapd   %ymm3,-32(%rax)

# qhasm:   mem256[const0 + 0] aligned= 2p106
# asm 1: vmovapd   <2p106=reg256#5,0(<const0=int64#7)
# asm 2: vmovapd   <2p106=%ymm4,0(<const0=%rax)
# bytes: 4 uops: 1
vmovapd   %ymm4,0(%rax)

# qhasm:   mem256[const0 + 32] aligned= 2p127
# asm 1: vmovapd   <2p127=reg256#6,32(<const0=int64#7)
# asm 2: vmovapd   <2p127=%ymm5,32(<const0=%rax)
# bytes: 5 uops: 1
vmovapd   %ymm5,32(%rax)

# qhasm:   mem256[const0 + 64] aligned= 2pm22
# asm 1: vmovapd   <2pm22=reg256#7,64(<const0=int64#7)
# asm 2: vmovapd   <2pm22=%ymm6,64(<const0=%rax)
# bytes: 5 uops: 1
vmovapd   %ymm6,64(%rax)

# qhasm:   mem256[const0 + 96] aligned= 2pm43
# asm 1: vmovapd   <2pm43=reg256#8,96(<const0=int64#7)
# asm 2: vmovapd   <2pm43=%ymm7,96(<const0=%rax)
# bytes: 5 uops: 1
vmovapd   %ymm7,96(%rax)
# block pos: 292 324 uops: 5

# qhasm:   mem256[const1 - 96] aligned= 2pm64
# asm 1: vmovapd   <2pm64=reg256#9,-96(<const1=int64#8)
# asm 2: vmovapd   <2pm64=%ymm8,-96(<const1=%r10)
# bytes: 6 uops: 1
vmovapd   %ymm8,-96(%r10)

# qhasm:   mem256[const1 - 64] aligned= 2pm85
# asm 1: vmovapd   <2pm85=reg256#10,-64(<const1=int64#8)
# asm 2: vmovapd   <2pm85=%ymm9,-64(<const1=%r10)
# bytes: 6 uops: 1
vmovapd   %ymm9,-64(%r10)

# qhasm:   mem256[const1 - 32] aligned= 2pm106
# asm 1: vmovapd   <2pm106=reg256#11,-32(<const1=int64#8)
# asm 2: vmovapd   <2pm106=%ymm10,-32(<const1=%r10)
# bytes: 6 uops: 1
vmovapd   %ymm10,-32(%r10)

# qhasm:   mem256[const1 + 0] aligned= two
# asm 1: vmovapd   <two=reg256#12,0(<const1=int64#8)
# asm 2: vmovapd   <two=%ymm11,0(<const1=%r10)
# bytes: 5 uops: 1
vmovapd   %ymm11,0(%r10)

# qhasm:   2pm127 aligned= mem256[_2pm127]
# asm 1: vmovapd _2pm127,>2pm127=reg256#1
# asm 2: vmovapd _2pm127,>2pm127=%ymm0
# bytes: 9 uops: 1
vmovapd _2pm127,%ymm0
# block pos: 324 354 uops: 6

# qhasm:   4x 127a5 = approx 2pm127 * mem256[work0 + 32]
# asm 1: vmulpd 32(<work0=int64#3),<2pm127=reg256#1,>127a5=reg256#2
# asm 2: vmulpd 32(<work0=%rdx),<2pm127=%ymm0,>127a5=%ymm1
# bytes: 5 uops: 1
vmulpd 32(%rdx),%ymm0,%ymm1

# qhasm:   4x 127a4 = approx 2pm127 * mem256[work0 + 0]
# asm 1: vmulpd 0(<work0=int64#3),<2pm127=reg256#1,>127a4=reg256#3
# asm 2: vmulpd 0(<work0=%rdx),<2pm127=%ymm0,>127a4=%ymm2
# bytes: 4 uops: 1
vmulpd 0(%rdx),%ymm0,%ymm2

# qhasm:   4x 127a3 = approx 2pm127 * mem256[work0 - 32]
# asm 1: vmulpd -32(<work0=int64#3),<2pm127=reg256#1,>127a3=reg256#4
# asm 2: vmulpd -32(<work0=%rdx),<2pm127=%ymm0,>127a3=%ymm3
# bytes: 5 uops: 1
vmulpd -32(%rdx),%ymm0,%ymm3

# qhasm:   4x 127a2 = approx 2pm127 * mem256[work0 - 64]
# asm 1: vmulpd -64(<work0=int64#3),<2pm127=reg256#1,>127a2=reg256#5
# asm 2: vmulpd -64(<work0=%rdx),<2pm127=%ymm0,>127a2=%ymm4
# bytes: 5 uops: 1
vmulpd -64(%rdx),%ymm0,%ymm4

# qhasm:   4x 127a1 = approx 2pm127 * mem256[work0 - 96]
# asm 1: vmulpd -96(<work0=int64#3),<2pm127=reg256#1,>127a1=reg256#6
# asm 2: vmulpd -96(<work0=%rdx),<2pm127=%ymm0,>127a1=%ymm5
# bytes: 5 uops: 1
vmulpd -96(%rdx),%ymm0,%ymm5

# qhasm:   mem256[const1 - 128] aligned= 2pm127
# asm 1: vmovapd   <2pm127=reg256#1,-128(<const1=int64#8)
# asm 2: vmovapd   <2pm127=%ymm0,-128(<const1=%r10)
# bytes: 6 uops: 1
vmovapd   %ymm0,-128(%r10)
# block pos: 354 390 uops: 4

# qhasm:   a22 aligned= mem256[alpha22]
# asm 1: vmovapd alpha22,>a22=reg256#1
# asm 2: vmovapd alpha22,>a22=%ymm0
# bytes: 9 uops: 1
vmovapd alpha22,%ymm0

# qhasm:   a64 aligned= mem256[alpha64]
# asm 1: vmovapd alpha64,>a64=reg256#7
# asm 2: vmovapd alpha64,>a64=%ymm6
# bytes: 9 uops: 1
vmovapd alpha64,%ymm6

# qhasm:   a106 aligned= mem256[alpha106]
# asm 1: vmovapd alpha106,>a106=reg256#8
# asm 2: vmovapd alpha106,>a106=%ymm7
# bytes: 9 uops: 1
vmovapd alpha106,%ymm7

# qhasm:   abcd aligned= mem256[newabcd]
# asm 1: vmovapd newabcd,>abcd=reg256#9
# asm 2: vmovapd newabcd,>abcd=%ymm8
# bytes: 9 uops: 1
vmovapd newabcd,%ymm8
# block pos: 390 419 uops: 5

# qhasm:   ABCD aligned= mem256[newABCD]
# asm 1: vmovapd newABCD,>ABCD=reg256#10
# asm 2: vmovapd newABCD,>ABCD=%ymm9
# bytes: 9 uops: 1
vmovapd newABCD,%ymm9

# qhasm:   mem256[work3 - 128] aligned= 127a5
# asm 1: vmovapd   <127a5=reg256#2,-128(<work3=int64#1)
# asm 2: vmovapd   <127a5=%ymm1,-128(<work3=%rdi)
# bytes: 5 uops: 1
vmovapd   %ymm1,-128(%rdi)

# qhasm:   mem256[work3 - 96] aligned= 127a4
# asm 1: vmovapd   <127a4=reg256#3,-96(<work3=int64#1)
# asm 2: vmovapd   <127a4=%ymm2,-96(<work3=%rdi)
# bytes: 5 uops: 1
vmovapd   %ymm2,-96(%rdi)

# qhasm:   mem256[work3 - 64] aligned= 127a3
# asm 1: vmovapd   <127a3=reg256#4,-64(<work3=int64#1)
# asm 2: vmovapd   <127a3=%ymm3,-64(<work3=%rdi)
# bytes: 5 uops: 1
vmovapd   %ymm3,-64(%rdi)

# qhasm:   mem256[work3 - 32] aligned= 127a2
# asm 1: vmovapd   <127a2=reg256#5,-32(<work3=int64#1)
# asm 2: vmovapd   <127a2=%ymm4,-32(<work3=%rdi)
# bytes: 5 uops: 1
vmovapd   %ymm4,-32(%rdi)
# block pos: 419 452 uops: 6

# qhasm:   mem256[work3 + 0] aligned= 127a1
# asm 1: vmovapd   <127a1=reg256#6,0(<work3=int64#1)
# asm 2: vmovapd   <127a1=%ymm5,0(<work3=%rdi)
# bytes: 4 uops: 1
vmovapd   %ymm5,0(%rdi)

# qhasm:   mem256[const2 - 128] aligned= a22
# asm 1: vmovapd   <a22=reg256#1,-128(<const2=int64#9)
# asm 2: vmovapd   <a22=%ymm0,-128(<const2=%r11)
# bytes: 6 uops: 1
vmovapd   %ymm0,-128(%r11)

# qhasm:   mem256[const2 - 64] aligned= a64
# asm 1: vmovapd   <a64=reg256#7,-64(<const2=int64#9)
# asm 2: vmovapd   <a64=%ymm6,-64(<const2=%r11)
# bytes: 6 uops: 1
vmovapd   %ymm6,-64(%r11)

# qhasm:   mem256[const2 + 0] aligned= a106
# asm 1: vmovapd   <a106=reg256#8,0(<const2=int64#9)
# asm 2: vmovapd   <a106=%ymm7,0(<const2=%r11)
# bytes: 5 uops: 1
vmovapd   %ymm7,0(%r11)

# qhasm:   mem256[const2 + 64] aligned= abcd
# asm 1: vmovapd   <abcd=reg256#9,64(<const2=int64#9)
# asm 2: vmovapd   <abcd=%ymm8,64(<const2=%r11)
# bytes: 6 uops: 1
vmovapd   %ymm8,64(%r11)

# qhasm:   mem256[const2 + 96] aligned= ABCD
# asm 1: vmovapd   <ABCD=reg256#10,96(<const2=int64#9)
# asm 2: vmovapd   <ABCD=%ymm9,96(<const2=%r11)
# bytes: 6 uops: 1
vmovapd   %ymm9,96(%r11)
# block pos: 452 480 uops: 6

# qhasm:   pos = 250
# asm 1: mov  $250,>pos=int64#10
# asm 2: mov  $250,>pos=%r12
# bytes: 7 uops: 1
mov  $250,%r12

# qhasm:   bit = *(uint8 *) (input_1 + 31)
# asm 1: movzbq 31(<input_1=int64#2),>bit=int64#4
# asm 2: movzbq 31(<input_1=%rsi),>bit=%rcx
# bytes: 5 uops: 1
movzbq 31(%rsi),%rcx

# qhasm:   (uint64) bit >>= 2
# asm 1: shr  $2,<bit=int64#4
# asm 2: shr  $2,<bit=%rcx
# bytes: 4 uops: 1
shr  $2,%rcx

# qhasm:   (uint32) bit &= 1
# asm 1: and  $1,<bit=int64#4d
# asm 2: and  $1,<bit=%ecx
# bytes: 4 uops: 1
.byte 0x3e
and  $1,%ecx

# qhasm:   prevbit = bit
# asm 1: mov  <bit=int64#4,>prevbit=int64#11
# asm 2: mov  <bit=%rcx,>prevbit=%r13
# bytes: 4 uops: 1
.byte 0x3e
mov  %rcx,%r13

# qhasm:   bit -= 1
# asm 1: sub  $1,<bit=int64#4
# asm 2: sub  $1,<bit=%rcx
# bytes: 4 uops: 1
sub  $1,%rcx
# block pos: 480 514 uops: 6

# qhasm:   mem64[work3 + 32] = bit
# asm 1: movq   <bit=int64#4,32(<work3=int64#1)
# asm 2: movq   <bit=%rcx,32(<work3=%rdi)
# bytes: 4 uops: 1
movq   %rcx,32(%rdi)

# qhasm:   E4 aligned= mem256[work2 +   0]
# asm 1: vmovapd   0(<work2=int64#6),>E4=reg256#1
# asm 2: vmovapd   0(<work2=%r9),>E4=%ymm0
# bytes: 5 uops: 1
vmovapd   0(%r9),%ymm0

# qhasm:   E2 aligned= mem256[work2 -  64]
# asm 1: vmovapd   -64(<work2=int64#6),>E2=reg256#2
# asm 2: vmovapd   -64(<work2=%r9),>E2=%ymm1
# bytes: 6 uops: 1
vmovapd   -64(%r9),%ymm1

# qhasm:   E0 aligned= mem256[work2 - 128]
# asm 1: vmovapd   -128(<work2=int64#6),>E0=reg256#3
# asm 2: vmovapd   -128(<work2=%r9),>E0=%ymm2
# bytes: 6 uops: 1
vmovapd   -128(%r9),%ymm2

# qhasm:   a127 aligned= mem256[alpha127]
# asm 1: vmovapd alpha127,>a127=reg256#4
# asm 2: vmovapd alpha127,>a127=%ymm3
# bytes: 9 uops: 1
vmovapd alpha127,%ymm3

# qhasm:           4x c4 = approx E4 + a127
# asm 1: vaddpd <E4=reg256#1,<a127=reg256#4,>c4=reg256#5
# asm 2: vaddpd <E4=%ymm0,<a127=%ymm3,>c4=%ymm4
# bytes: 4 uops: 1
vaddpd %ymm0,%ymm3,%ymm4
# block pos: 514 547 uops: 6

# qhasm:           4x c4 approx-= a127
# asm 1: vsubpd <a127=reg256#4,<c4=reg256#5,>c4=reg256#5
# asm 2: vsubpd <a127=%ymm3,<c4=%ymm4,>c4=%ymm4
# bytes: 4 uops: 1
vsubpd %ymm3,%ymm4,%ymm4

# qhasm:   mem256[const2 + 32] aligned= a127
# asm 1: vmovapd   <a127=reg256#4,32(<const2=int64#9)
# asm 2: vmovapd   <a127=%ymm3,32(<const2=%r11)
# bytes: 6 uops: 1
vmovapd   %ymm3,32(%r11)

# qhasm:           4x E4 approx-= c4
# asm 1: vsubpd <c4=reg256#5,<E4=reg256#1,>E4=reg256#1
# asm 2: vsubpd <c4=%ymm4,<E4=%ymm0,>E4=%ymm0
# bytes: 4 uops: 1
vsubpd %ymm4,%ymm0,%ymm0

# qhasm: 	  4x c4 approx*= mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#8),<c4=reg256#5,>c4=reg256#4
# asm 2: vmulpd -128(<const1=%r10),<c4=%ymm4,>c4=%ymm3
# bytes: 6 uops: 1
vmulpd -128(%r10),%ymm4,%ymm3

# qhasm:           4x E0 approx+= c4
# asm 1: vaddpd <c4=reg256#4,<E0=reg256#3,>E0=reg256#3
# asm 2: vaddpd <c4=%ymm3,<E0=%ymm2,>E0=%ymm2
# bytes: 4 uops: 1
vaddpd %ymm3,%ymm2,%ymm2

# qhasm:   a85 aligned= mem256[alpha85]
# asm 1: vmovapd alpha85,>a85=reg256#4
# asm 2: vmovapd alpha85,>a85=%ymm3
# bytes: 9 uops: 1
vmovapd alpha85,%ymm3
# block pos: 547 578 uops: 6

# qhasm:           4x c2 = approx E2 + a85
# asm 1: vaddpd <E2=reg256#2,<a85=reg256#4,>c2=reg256#5
# asm 2: vaddpd <E2=%ymm1,<a85=%ymm3,>c2=%ymm4
# bytes: 4 uops: 1
vaddpd %ymm1,%ymm3,%ymm4

# qhasm:           4x c2 approx-= a85
# asm 1: vsubpd <a85=reg256#4,<c2=reg256#5,>c2=reg256#5
# asm 2: vsubpd <a85=%ymm3,<c2=%ymm4,>c2=%ymm4
# bytes: 4 uops: 1
vsubpd %ymm3,%ymm4,%ymm4

# qhasm:   mem256[const2 - 32] aligned= a85
# asm 1: vmovapd   <a85=reg256#4,-32(<const2=int64#9)
# asm 2: vmovapd   <a85=%ymm3,-32(<const2=%r11)
# bytes: 6 uops: 1
vmovapd   %ymm3,-32(%r11)

# qhasm:           4x E4 approx+= c2
# asm 1: vaddpd <c2=reg256#5,<E4=reg256#1,>E4=reg256#1
# asm 2: vaddpd <c2=%ymm4,<E4=%ymm0,>E4=%ymm0
# bytes: 4 uops: 1
vaddpd %ymm4,%ymm0,%ymm0

# qhasm:           4x E2 approx-= c2
# asm 1: vsubpd <c2=reg256#5,<E2=reg256#2,>E2=reg256#2
# asm 2: vsubpd <c2=%ymm4,<E2=%ymm1,>E2=%ymm1
# bytes: 4 uops: 1
vsubpd %ymm4,%ymm1,%ymm1

# qhasm:   a43 aligned= mem256[alpha43]
# asm 1: vmovapd alpha43,>a43=reg256#4
# asm 2: vmovapd alpha43,>a43=%ymm3
# bytes: 9 uops: 1
vmovapd alpha43,%ymm3
# block pos: 578 608 uops: 6

# qhasm:           4x c0 = approx E0 + a43
# asm 1: vaddpd <E0=reg256#3,<a43=reg256#4,>c0=reg256#5
# asm 2: vaddpd <E0=%ymm2,<a43=%ymm3,>c0=%ymm4
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm2,%ymm3,%ymm4

# qhasm:           4x c0 approx-= a43
# asm 1: vsubpd <a43=reg256#4,<c0=reg256#5,>c0=reg256#5
# asm 2: vsubpd <a43=%ymm3,<c0=%ymm4,>c0=%ymm4
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm3,%ymm4,%ymm4

# qhasm:   mem256[const2 - 96] aligned= a43
# asm 1: vmovapd   <a43=reg256#4,-96(<const2=int64#9)
# asm 2: vmovapd   <a43=%ymm3,-96(<const2=%r11)
# bytes: 6 uops: 1
vmovapd   %ymm3,-96(%r11)

# qhasm:           4x E2 approx+= c0
# asm 1: vaddpd <c0=reg256#5,<E2=reg256#2,>E2=reg256#2
# asm 2: vaddpd <c0=%ymm4,<E2=%ymm1,>E2=%ymm1
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm4,%ymm1,%ymm1

# qhasm:           4x E0 approx-= c0
# asm 1: vsubpd <c0=reg256#5,<E0=reg256#3,>E0=reg256#3
# asm 2: vsubpd <c0=%ymm4,<E0=%ymm2,>E0=%ymm2
# bytes: 4 uops: 1
vsubpd %ymm4,%ymm2,%ymm2

# qhasm:   F4 aligned= mem256[work1 +   0]
# asm 1: vmovapd   0(<work1=int64#5),>F4=reg256#4
# asm 2: vmovapd   0(<work1=%r8),>F4=%ymm3
# bytes: 5 uops: 1
vmovapd   0(%r8),%ymm3
# block pos: 608 640 uops: 6

# qhasm:   F2 aligned= mem256[work1 -  64]
# asm 1: vmovapd   -64(<work1=int64#5),>F2=reg256#5
# asm 2: vmovapd   -64(<work1=%r8),>F2=%ymm4
# bytes: 6 uops: 1
vmovapd   -64(%r8),%ymm4

# qhasm:   F0 aligned= mem256[work1 - 128]
# asm 1: vmovapd   -128(<work1=int64#5),>F0=reg256#6
# asm 2: vmovapd   -128(<work1=%r8),>F0=%ymm5
# bytes: 6 uops: 1
vmovapd   -128(%r8),%ymm5

# qhasm: mainloop:
._mainloop:

# qhasm:   yxtz4[0,1,2,3] = F4[1,0,3,2]
# asm 1: vpermilpd $0x5,<F4=reg256#4,>yxtz4=reg256#7
# asm 2: vpermilpd $0x5,<F4=%ymm3,>yxtz4=%ymm6
# bytes: 7 uops: 1
.byte 0x3e
vpermilpd $0x5,%ymm3,%ymm6

# qhasm:   abcd4[0,1,2,3] approx= F4[0]-yxtz4[0],F4[1]+yxtz4[1],F4[2]-yxtz4[2],F4[3]+yxtz4[3]
# asm 1: vaddsubpd <yxtz4=reg256#7,<F4=reg256#4,>abcd4=reg256#4
# asm 2: vaddsubpd <yxtz4=%ymm6,<F4=%ymm3,>abcd4=%ymm3
# bytes: 7 uops: 1
.byte 0x3e
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm6,%ymm3,%ymm3

# qhasm:   cdab4[0,1,2,3] = abcd4[2,3],abcd4[0,1]
# asm 1: vperm2f128 $0x21,<abcd4=reg256#4,<abcd4=reg256#4,>cdab4=reg256#7
# asm 2: vperm2f128 $0x21,<abcd4=%ymm3,<abcd4=%ymm3,>cdab4=%ymm6
# bytes: 6 uops: 2
vperm2f128 $0x21,%ymm3,%ymm3,%ymm6
# block pos: 640 672 uops: 6

# qhasm:   badc4[0,1,2,3] = abcd4[1,0,3,2]
# asm 1: vpermilpd $0x5,<abcd4=reg256#4,>badc4=reg256#4
# asm 2: vpermilpd $0x5,<abcd4=%ymm3,>badc4=%ymm3
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm3,%ymm3

# qhasm:   I4[0,1,2,3] approx= badc4[0]-cdab4[0],badc4[1]+cdab4[1],badc4[2]-cdab4[2],badc4[3]+cdab4[3]
# asm 1: vaddsubpd <cdab4=reg256#7,<badc4=reg256#4,>I4=reg256#4
# asm 2: vaddsubpd <cdab4=%ymm6,<badc4=%ymm3,>I4=%ymm3
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm6,%ymm3,%ymm3

# qhasm:   a106 aligned= mem256[const2 + 0]
# asm 1: vmovapd   0(<const2=int64#9),>a106=reg256#7
# asm 2: vmovapd   0(<const2=%r11),>a106=%ymm6
# bytes: 5 uops: 1
vmovapd   0(%r11),%ymm6

# qhasm:   4x I5 = approx I4 + a106
# asm 1: vaddpd <I4=reg256#4,<a106=reg256#7,>I5=reg256#8
# asm 2: vaddpd <I4=%ymm3,<a106=%ymm6,>I5=%ymm7
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm3,%ymm6,%ymm7

# qhasm:   4x I5 approx-= a106
# asm 1: vsubpd <a106=reg256#7,<I5=reg256#8,>I5=reg256#7
# asm 2: vsubpd <a106=%ymm6,<I5=%ymm7,>I5=%ymm6
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm6,%ymm7,%ymm6

# qhasm:   4x I4 approx-= I5
# asm 1: vsubpd <I5=reg256#7,<I4=reg256#4,>I4=reg256#4
# asm 2: vsubpd <I5=%ymm6,<I4=%ymm3,>I4=%ymm3
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm6,%ymm3,%ymm3
# block pos: 672 707 uops: 6

# qhasm:     4x 127I5 = approx I5 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#8),<I5=reg256#7,>127I5=reg256#8
# asm 2: vmulpd -128(<const1=%r10),<I5=%ymm6,>127I5=%ymm7
# bytes: 6 uops: 1
vmulpd -128(%r10),%ymm6,%ymm7

# qhasm:     127I5_stack aligned= 127I5
# asm 1: vmovapd <127I5=reg256#8,>127I5_stack=stack256#1
# asm 2: vmovapd <127I5=%ymm7,>127I5_stack=0(%rsp)
# bytes: 5 uops: 1
vmovapd %ymm7,0(%rsp)

# qhasm:       4x 127I4 = approx I4 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#8),<I4=reg256#4,>127I4=reg256#8
# asm 2: vmulpd -128(<const1=%r10),<I4=%ymm3,>127I4=%ymm7
# bytes: 6 uops: 1
vmulpd -128(%r10),%ymm3,%ymm7

# qhasm:       127I4_stack aligned= 127I4
# asm 1: vmovapd <127I4=reg256#8,>127I4_stack=stack256#2
# asm 2: vmovapd <127I4=%ymm7,>127I4_stack=32(%rsp)
# bytes: 6 uops: 1
vmovapd %ymm7,32(%rsp)

# qhasm:   yxtz0[0,1,2,3] = F0[1,0,3,2]
# asm 1: vpermilpd $0x5,<F0=reg256#6,>yxtz0=reg256#8
# asm 2: vpermilpd $0x5,<F0=%ymm5,>yxtz0=%ymm7
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm5,%ymm7

# qhasm:   yxtz2[0,1,2,3] = F2[1,0,3,2]
# asm 1: vpermilpd $0x5,<F2=reg256#5,>yxtz2=reg256#9
# asm 2: vpermilpd $0x5,<F2=%ymm4,>yxtz2=%ymm8
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm4,%ymm8
# block pos: 707 736 uops: 6

# qhasm:   abcd2[0,1,2,3] approx= F2[0]-yxtz2[0],F2[1]+yxtz2[1],F2[2]-yxtz2[2],F2[3]+yxtz2[3]
# asm 1: vaddsubpd <yxtz2=reg256#9,<F2=reg256#5,>abcd2=reg256#5
# asm 2: vaddsubpd <yxtz2=%ymm8,<F2=%ymm4,>abcd2=%ymm4
# bytes: 6 uops: 1
.byte 0x3e
vaddsubpd %ymm8,%ymm4,%ymm4

# qhasm:   cdab2[0,1,2,3] = abcd2[2,3],abcd2[0,1]
# asm 1: vperm2f128 $0x21,<abcd2=reg256#5,<abcd2=reg256#5,>cdab2=reg256#9
# asm 2: vperm2f128 $0x21,<abcd2=%ymm4,<abcd2=%ymm4,>cdab2=%ymm8
# bytes: 6 uops: 2
vperm2f128 $0x21,%ymm4,%ymm4,%ymm8

# qhasm:   badc2[0,1,2,3] = abcd2[1,0,3,2]
# asm 1: vpermilpd $0x5,<abcd2=reg256#5,>badc2=reg256#5
# asm 2: vpermilpd $0x5,<abcd2=%ymm4,>badc2=%ymm4
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm4,%ymm4

# qhasm:   I2[0,1,2,3] approx= badc2[0]-cdab2[0],badc2[1]+cdab2[1],badc2[2]-cdab2[2],badc2[3]+cdab2[3]
# asm 1: vaddsubpd <cdab2=reg256#9,<badc2=reg256#5,>I2=reg256#5
# asm 2: vaddsubpd <cdab2=%ymm8,<badc2=%ymm4,>I2=%ymm4
# bytes: 5 uops: 1
vaddsubpd %ymm8,%ymm4,%ymm4

# qhasm:   a64 aligned= mem256[const2 - 64]
# asm 1: vmovapd   -64(<const2=int64#9),>a64=reg256#9
# asm 2: vmovapd   -64(<const2=%r11),>a64=%ymm8
# bytes: 6 uops: 1
vmovapd   -64(%r11),%ymm8
# block pos: 736 768 uops: 6

# qhasm:   4x I3 = approx I2 + a64
# asm 1: vaddpd <I2=reg256#5,<a64=reg256#9,>I3=reg256#10
# asm 2: vaddpd <I2=%ymm4,<a64=%ymm8,>I3=%ymm9
# bytes: 4 uops: 1
vaddpd %ymm4,%ymm8,%ymm9

# qhasm:   4x I3 approx-= a64
# asm 1: vsubpd <a64=reg256#9,<I3=reg256#10,>I3=reg256#9
# asm 2: vsubpd <a64=%ymm8,<I3=%ymm9,>I3=%ymm8
# bytes: 5 uops: 1
vsubpd %ymm8,%ymm9,%ymm8

# qhasm:   4x I2 approx-= I3
# asm 1: vsubpd <I3=reg256#9,<I2=reg256#5,>I2=reg256#5
# asm 2: vsubpd <I3=%ymm8,<I2=%ymm4,>I2=%ymm4
# bytes: 5 uops: 1
vsubpd %ymm8,%ymm4,%ymm4

# qhasm:         4x 127I3 = approx I3 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#8),<I3=reg256#9,>127I3=reg256#10
# asm 2: vmulpd -128(<const1=%r10),<I3=%ymm8,>127I3=%ymm9
# bytes: 6 uops: 1
vmulpd -128(%r10),%ymm8,%ymm9

# qhasm: 	127I3_stack aligned= 127I3
# asm 1: vmovapd <127I3=reg256#10,>127I3_stack=stack256#3
# asm 2: vmovapd <127I3=%ymm9,>127I3_stack=64(%rsp)
# bytes: 6 uops: 1
vmovapd %ymm9,64(%rsp)

# qhasm:           4x 127I2 = approx I2 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#8),<I2=reg256#5,>127I2=reg256#10
# asm 2: vmulpd -128(<const1=%r10),<I2=%ymm4,>127I2=%ymm9
# bytes: 6 uops: 1
vmulpd -128(%r10),%ymm4,%ymm9
# block pos: 768 800 uops: 6

# qhasm: 	  127I2_stack aligned= 127I2
# asm 1: vmovapd <127I2=reg256#10,>127I2_stack=stack256#4
# asm 2: vmovapd <127I2=%ymm9,>127I2_stack=96(%rsp)
# bytes: 6 uops: 1
vmovapd %ymm9,96(%rsp)

# qhasm:   abcd0[0,1,2,3] approx= F0[0]-yxtz0[0],F0[1]+yxtz0[1],F0[2]-yxtz0[2],F0[3]+yxtz0[3]
# asm 1: vaddsubpd <yxtz0=reg256#8,<F0=reg256#6,>abcd0=reg256#6
# asm 2: vaddsubpd <yxtz0=%ymm7,<F0=%ymm5,>abcd0=%ymm5
# bytes: 7 uops: 1
.byte 0x3e
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm7,%ymm5,%ymm5

# qhasm:   cdab0[0,1,2,3] = abcd0[2,3],abcd0[0,1]
# asm 1: vperm2f128 $0x21,<abcd0=reg256#6,<abcd0=reg256#6,>cdab0=reg256#8
# asm 2: vperm2f128 $0x21,<abcd0=%ymm5,<abcd0=%ymm5,>cdab0=%ymm7
# bytes: 7 uops: 2
.byte 0x3e
vperm2f128 $0x21,%ymm5,%ymm5,%ymm7

# qhasm:   badc0[0,1,2,3] = abcd0[1,0,3,2]
# asm 1: vpermilpd $0x5,<abcd0=reg256#6,>badc0=reg256#6
# asm 2: vpermilpd $0x5,<abcd0=%ymm5,>badc0=%ymm5
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm5,%ymm5

# qhasm:   I0[0,1,2,3] approx= badc0[0]-cdab0[0],badc0[1]+cdab0[1],badc0[2]-cdab0[2],badc0[3]+cdab0[3]
# asm 1: vaddsubpd <cdab0=reg256#8,<badc0=reg256#6,>I0=reg256#6
# asm 2: vaddsubpd <cdab0=%ymm7,<badc0=%ymm5,>I0=%ymm5
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm7,%ymm5,%ymm5
# block pos: 800 832 uops: 6

# qhasm:   a22 aligned= mem256[const2 - 128]
# asm 1: vmovapd   -128(<const2=int64#9),>a22=reg256#8
# asm 2: vmovapd   -128(<const2=%r11),>a22=%ymm7
# bytes: 6 uops: 1
vmovapd   -128(%r11),%ymm7

# qhasm:   4x I1 = approx I0 + a22
# asm 1: vaddpd <I0=reg256#6,<a22=reg256#8,>I1=reg256#10
# asm 2: vaddpd <I0=%ymm5,<a22=%ymm7,>I1=%ymm9
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm5,%ymm7,%ymm9

# qhasm:   4x I1 approx-= a22
# asm 1: vsubpd <a22=reg256#8,<I1=reg256#10,>I1=reg256#8
# asm 2: vsubpd <a22=%ymm7,<I1=%ymm9,>I1=%ymm7
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm7,%ymm9,%ymm7

# qhasm:   4x I0 approx-= I1
# asm 1: vsubpd <I1=reg256#8,<I0=reg256#6,>I0=reg256#6
# asm 2: vsubpd <I1=%ymm7,<I0=%ymm5,>I0=%ymm5
# bytes: 4 uops: 1
vsubpd %ymm7,%ymm5,%ymm5

# qhasm:             4x 127I1 = approx I1 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#8),<I1=reg256#8,>127I1=reg256#10
# asm 2: vmulpd -128(<const1=%r10),<I1=%ymm7,>127I1=%ymm9
# bytes: 6 uops: 1
vmulpd -128(%r10),%ymm7,%ymm9

# qhasm: 	    mem256[const1 + 96] aligned= 127I1
# asm 1: vmovapd   <127I1=reg256#10,96(<const1=int64#8)
# asm 2: vmovapd   <127I1=%ymm9,96(<const1=%r10)
# bytes: 6 uops: 1
vmovapd   %ymm9,96(%r10)
# block pos: 832 864 uops: 6

# qhasm:                           yxtz4[0,1,2,3] = E4[1,0,3,2]
# asm 1: vpermilpd $0x5,<E4=reg256#1,>yxtz4=reg256#10
# asm 2: vpermilpd $0x5,<E4=%ymm0,>yxtz4=%ymm9
# bytes: 7 uops: 1
.byte 0x3e
vpermilpd $0x5,%ymm0,%ymm9

# qhasm:                           abcd4[0,1,2,3] approx= E4[0]-yxtz4[0],E4[1]+yxtz4[1],E4[2]-yxtz4[2],E4[3]+yxtz4[3]
# asm 1: vaddsubpd <yxtz4=reg256#10,<E4=reg256#1,>abcd4=reg256#1
# asm 2: vaddsubpd <yxtz4=%ymm9,<E4=%ymm0,>abcd4=%ymm0
# bytes: 7 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm9,%ymm0,%ymm0

# qhasm:                           cdab4[0,1,2,3] = abcd4[2,3],abcd4[0,1]
# asm 1: vperm2f128 $0x21,<abcd4=reg256#1,<abcd4=reg256#1,>cdab4=reg256#10
# asm 2: vperm2f128 $0x21,<abcd4=%ymm0,<abcd4=%ymm0,>cdab4=%ymm9
# bytes: 6 uops: 2
vperm2f128 $0x21,%ymm0,%ymm0,%ymm9

# qhasm:                           badc4[0,1,2,3] = abcd4[1,0,3,2]
# asm 1: vpermilpd $0x5,<abcd4=reg256#1,>badc4=reg256#1
# asm 2: vpermilpd $0x5,<abcd4=%ymm0,>badc4=%ymm0
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm0,%ymm0

# qhasm:                           H4[0,1,2,3] approx= badc4[0]-cdab4[0],badc4[1]+cdab4[1],badc4[2]-cdab4[2],badc4[3]+cdab4[3]
# asm 1: vaddsubpd <cdab4=reg256#10,<badc4=reg256#1,>H4=reg256#1
# asm 2: vaddsubpd <cdab4=%ymm9,<badc4=%ymm0,>H4=%ymm0
# bytes: 6 uops: 1
.byte 0x3e
vaddsubpd %ymm9,%ymm0,%ymm0
# block pos: 864 896 uops: 6

# qhasm:                           yxtz2[0,1,2,3] = E2[1,0,3,2]
# asm 1: vpermilpd $0x5,<E2=reg256#2,>yxtz2=reg256#10
# asm 2: vpermilpd $0x5,<E2=%ymm1,>yxtz2=%ymm9
# bytes: 7 uops: 1
.byte 0x3e
vpermilpd $0x5,%ymm1,%ymm9

# qhasm:                           abcd2[0,1,2,3] approx= E2[0]-yxtz2[0],E2[1]+yxtz2[1],E2[2]-yxtz2[2],E2[3]+yxtz2[3]
# asm 1: vaddsubpd <yxtz2=reg256#10,<E2=reg256#2,>abcd2=reg256#2
# asm 2: vaddsubpd <yxtz2=%ymm9,<E2=%ymm1,>abcd2=%ymm1
# bytes: 7 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm9,%ymm1,%ymm1

# qhasm:                           cdab2[0,1,2,3] = abcd2[2,3],abcd2[0,1]
# asm 1: vperm2f128 $0x21,<abcd2=reg256#2,<abcd2=reg256#2,>cdab2=reg256#10
# asm 2: vperm2f128 $0x21,<abcd2=%ymm1,<abcd2=%ymm1,>cdab2=%ymm9
# bytes: 6 uops: 2
vperm2f128 $0x21,%ymm1,%ymm1,%ymm9

# qhasm:                           badc2[0,1,2,3] = abcd2[1,0,3,2]
# asm 1: vpermilpd $0x5,<abcd2=reg256#2,>badc2=reg256#2
# asm 2: vpermilpd $0x5,<abcd2=%ymm1,>badc2=%ymm1
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm1,%ymm1

# qhasm:                           H2[0,1,2,3] approx= badc2[0]-cdab2[0],badc2[1]+cdab2[1],badc2[2]-cdab2[2],badc2[3]+cdab2[3]
# asm 1: vaddsubpd <cdab2=reg256#10,<badc2=reg256#2,>H2=reg256#2
# asm 2: vaddsubpd <cdab2=%ymm9,<badc2=%ymm1,>H2=%ymm1
# bytes: 6 uops: 1
.byte 0x3e
vaddsubpd %ymm9,%ymm1,%ymm1
# block pos: 896 928 uops: 6

# qhasm:                           yxtz0[0,1,2,3] = E0[1,0,3,2]
# asm 1: vpermilpd $0x5,<E0=reg256#3,>yxtz0=reg256#10
# asm 2: vpermilpd $0x5,<E0=%ymm2,>yxtz0=%ymm9
# bytes: 7 uops: 1
.byte 0x3e
vpermilpd $0x5,%ymm2,%ymm9

# qhasm:                           abcd0[0,1,2,3] approx= E0[0]-yxtz0[0],E0[1]+yxtz0[1],E0[2]-yxtz0[2],E0[3]+yxtz0[3]
# asm 1: vaddsubpd <yxtz0=reg256#10,<E0=reg256#3,>abcd0=reg256#3
# asm 2: vaddsubpd <yxtz0=%ymm9,<E0=%ymm2,>abcd0=%ymm2
# bytes: 7 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm9,%ymm2,%ymm2

# qhasm:                           cdab0[0,1,2,3] = abcd0[2,3],abcd0[0,1]
# asm 1: vperm2f128 $0x21,<abcd0=reg256#3,<abcd0=reg256#3,>cdab0=reg256#10
# asm 2: vperm2f128 $0x21,<abcd0=%ymm2,<abcd0=%ymm2,>cdab0=%ymm9
# bytes: 6 uops: 2
vperm2f128 $0x21,%ymm2,%ymm2,%ymm9

# qhasm:                           badc0[0,1,2,3] = abcd0[1,0,3,2]
# asm 1: vpermilpd $0x5,<abcd0=reg256#3,>badc0=reg256#3
# asm 2: vpermilpd $0x5,<abcd0=%ymm2,>badc0=%ymm2
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm2,%ymm2

# qhasm:                           H0[0,1,2,3] approx= badc0[0]-cdab0[0],badc0[1]+cdab0[1],badc0[2]-cdab0[2],badc0[3]+cdab0[3]
# asm 1: vaddsubpd <cdab0=reg256#10,<badc0=reg256#3,>H0=reg256#3
# asm 2: vaddsubpd <cdab0=%ymm9,<badc0=%ymm2,>H0=%ymm2
# bytes: 6 uops: 1
.byte 0x3e
vaddsubpd %ymm9,%ymm2,%ymm2
# block pos: 928 960 uops: 6

# qhasm:                           a106 aligned= mem256[const2 + 0]
# asm 1: vmovapd   0(<const2=int64#9),>a106=reg256#10
# asm 2: vmovapd   0(<const2=%r11),>a106=%ymm9
# bytes: 5 uops: 1
vmovapd   0(%r11),%ymm9

# qhasm:                           4x H5 = approx H4 + a106
# asm 1: vaddpd <H4=reg256#1,<a106=reg256#10,>H5=reg256#11
# asm 2: vaddpd <H4=%ymm0,<a106=%ymm9,>H5=%ymm10
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddpd %ymm0,%ymm9,%ymm10

# qhasm:                           4x H5 approx-= a106
# asm 1: vsubpd <a106=reg256#10,<H5=reg256#11,>H5=reg256#10
# asm 2: vsubpd <a106=%ymm9,<H5=%ymm10,>H5=%ymm9
# bytes: 5 uops: 1
vsubpd %ymm9,%ymm10,%ymm9

# qhasm:                           4x H4 approx-= H5
# asm 1: vsubpd <H5=reg256#10,<H4=reg256#1,>H4=reg256#1
# asm 2: vsubpd <H5=%ymm9,<H4=%ymm0,>H4=%ymm0
# bytes: 5 uops: 1
vsubpd %ymm9,%ymm0,%ymm0

# qhasm:                           a64 aligned= mem256[const2 - 64]
# asm 1: vmovapd   -64(<const2=int64#9),>a64=reg256#11
# asm 2: vmovapd   -64(<const2=%r11),>a64=%ymm10
# bytes: 6 uops: 1
vmovapd   -64(%r11),%ymm10

# qhasm:                           4x H3 = approx H2 + a64
# asm 1: vaddpd <H2=reg256#2,<a64=reg256#11,>H3=reg256#12
# asm 2: vaddpd <H2=%ymm1,<a64=%ymm10,>H3=%ymm11
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm1,%ymm10,%ymm11
# block pos: 960 992 uops: 6

# qhasm:                           4x H3 approx-= a64
# asm 1: vsubpd <a64=reg256#11,<H3=reg256#12,>H3=reg256#11
# asm 2: vsubpd <a64=%ymm10,<H3=%ymm11,>H3=%ymm10
# bytes: 6 uops: 1
.byte 0x3e
vsubpd %ymm10,%ymm11,%ymm10

# qhasm:                           4x H2 approx-= H3
# asm 1: vsubpd <H3=reg256#11,<H2=reg256#2,>H2=reg256#2
# asm 2: vsubpd <H3=%ymm10,<H2=%ymm1,>H2=%ymm1
# bytes: 5 uops: 1
vsubpd %ymm10,%ymm1,%ymm1

# qhasm:                           a22 aligned= mem256[const2 - 128]
# asm 1: vmovapd   -128(<const2=int64#9),>a22=reg256#12
# asm 2: vmovapd   -128(<const2=%r11),>a22=%ymm11
# bytes: 6 uops: 1
vmovapd   -128(%r11),%ymm11

# qhasm:                           4x H1 = approx H0 + a22
# asm 1: vaddpd <H0=reg256#3,<a22=reg256#12,>H1=reg256#13
# asm 2: vaddpd <H0=%ymm2,<a22=%ymm11,>H1=%ymm12
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm2,%ymm11,%ymm12

# qhasm:                           4x H1 approx-= a22
# asm 1: vsubpd <a22=reg256#12,<H1=reg256#13,>H1=reg256#12
# asm 2: vsubpd <a22=%ymm11,<H1=%ymm12,>H1=%ymm11
# bytes: 5 uops: 1
vsubpd %ymm11,%ymm12,%ymm11

# qhasm:                           4x H0 approx-= H1
# asm 1: vsubpd <H1=reg256#12,<H0=reg256#3,>H0=reg256#3
# asm 2: vsubpd <H1=%ymm11,<H0=%ymm2,>H0=%ymm2
# bytes: 5 uops: 1
vsubpd %ymm11,%ymm2,%ymm2
# block pos: 992 1024 uops: 6

# qhasm:   b = mem64[work3 + 32],mem64[work3 + 32],mem64[work3 + 32],mem64[work3 + 32]
# asm 1: vbroadcastsd 32(<work3=int64#1),>b=reg256#13
# asm 2: vbroadcastsd 32(<work3=%rdi),>b=%ymm12
# bytes: 6 uops: 1
vbroadcastsd 32(%rdi),%ymm12

# qhasm: 	      4x Q5 = I5 if b<0 else H5
# asm 1: vblendvpd <b=reg256#13,<I5=reg256#7,<H5=reg256#10,>Q5=reg256#14
# asm 2: vblendvpd <b=%ymm12,<I5=%ymm6,<H5=%ymm9,>Q5=%ymm13
# bytes: 10 uops: 2
.byte 0x3e
.byte 0x3e
.byte 0x3e
.byte 0x3e
vblendvpd %ymm12,%ymm6,%ymm9,%ymm13

# qhasm:               mem256[work1 + 32] aligned= Q5
# asm 1: vmovapd   <Q5=reg256#14,32(<work1=int64#5)
# asm 2: vmovapd   <Q5=%ymm13,32(<work1=%r8)
# bytes: 6 uops: 1
vmovapd   %ymm13,32(%r8)

# qhasm: 	      4x Q4 = I4 if b<0 else H4
# asm 1: vblendvpd <b=reg256#13,<I4=reg256#4,<H4=reg256#1,>Q4=reg256#14
# asm 2: vblendvpd <b=%ymm12,<I4=%ymm3,<H4=%ymm0,>Q4=%ymm13
# bytes: 10 uops: 2
.byte 0x3e
.byte 0x3e
.byte 0x3e
.byte 0x3e
vblendvpd %ymm12,%ymm3,%ymm0,%ymm13
# block pos: 1024 1056 uops: 6

# qhasm:               mem256[work1 + 0] aligned= Q4
# asm 1: vmovapd   <Q4=reg256#14,0(<work1=int64#5)
# asm 2: vmovapd   <Q4=%ymm13,0(<work1=%r8)
# bytes: 5 uops: 1
vmovapd   %ymm13,0(%r8)

# qhasm: 	      4x Q3 = I3 if b<0 else H3
# asm 1: vblendvpd <b=reg256#13,<I3=reg256#9,<H3=reg256#11,>Q3=reg256#14
# asm 2: vblendvpd <b=%ymm12,<I3=%ymm8,<H3=%ymm10,>Q3=%ymm13
# bytes: 11 uops: 2
.byte 0x3e
.byte 0x3e
.byte 0x3e
.byte 0x3e
.byte 0x3e
vblendvpd %ymm12,%ymm8,%ymm10,%ymm13

# qhasm:               mem256[work1 - 32] aligned= Q3
# asm 1: vmovapd   <Q3=reg256#14,-32(<work1=int64#5)
# asm 2: vmovapd   <Q3=%ymm13,-32(<work1=%r8)
# bytes: 6 uops: 1
vmovapd   %ymm13,-32(%r8)

# qhasm: 	      4x Q2 = I2 if b<0 else H2
# asm 1: vblendvpd <b=reg256#13,<I2=reg256#5,<H2=reg256#2,>Q2=reg256#14
# asm 2: vblendvpd <b=%ymm12,<I2=%ymm4,<H2=%ymm1,>Q2=%ymm13
# bytes: 10 uops: 2
.byte 0x3e
.byte 0x3e
.byte 0x3e
.byte 0x3e
vblendvpd %ymm12,%ymm4,%ymm1,%ymm13
# block pos: 1056 1088 uops: 6

# qhasm:               mem256[work1 - 64] aligned= Q2
# asm 1: vmovapd   <Q2=reg256#14,-64(<work1=int64#5)
# asm 2: vmovapd   <Q2=%ymm13,-64(<work1=%r8)
# bytes: 6 uops: 1
vmovapd   %ymm13,-64(%r8)

# qhasm: 	      4x Q1 = I1 if b<0 else H1
# asm 1: vblendvpd <b=reg256#13,<I1=reg256#8,<H1=reg256#12,>Q1=reg256#14
# asm 2: vblendvpd <b=%ymm12,<I1=%ymm7,<H1=%ymm11,>Q1=%ymm13
# bytes: 10 uops: 2
.byte 0x3e
.byte 0x3e
.byte 0x3e
.byte 0x3e
vblendvpd %ymm12,%ymm7,%ymm11,%ymm13

# qhasm:               mem256[work1 - 96] aligned= Q1
# asm 1: vmovapd   <Q1=reg256#14,-96(<work1=int64#5)
# asm 2: vmovapd   <Q1=%ymm13,-96(<work1=%r8)
# bytes: 6 uops: 1
vmovapd   %ymm13,-96(%r8)

# qhasm: 	      4x Q0 = I0 if b<0 else H0
# asm 1: vblendvpd <b=reg256#13,<I0=reg256#6,<H0=reg256#3,>Q0=reg256#13
# asm 2: vblendvpd <b=%ymm12,<I0=%ymm5,<H0=%ymm2,>Q0=%ymm12
# bytes: 10 uops: 2
.byte 0x3e
.byte 0x3e
.byte 0x3e
.byte 0x3e
vblendvpd %ymm12,%ymm5,%ymm2,%ymm12
# block pos: 1088 1120 uops: 6

# qhasm:               mem256[work1 - 128] aligned= Q0
# asm 1: vmovapd   <Q0=reg256#13,-128(<work1=int64#5)
# asm 2: vmovapd   <Q0=%ymm12,-128(<work1=%r8)
# bytes: 6 uops: 1
vmovapd   %ymm12,-128(%r8)

# qhasm:                           4x R5 = approx I1 * H4
# asm 1: vmulpd <I1=reg256#8,<H4=reg256#1,>R5=reg256#13
# asm 2: vmulpd <I1=%ymm7,<H4=%ymm0,>R5=%ymm12
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm7,%ymm0,%ymm12

# qhasm:                             4x R4 = approx I1 * H3
# asm 1: vmulpd <I1=reg256#8,<H3=reg256#11,>R4=reg256#14
# asm 2: vmulpd <I1=%ymm7,<H3=%ymm10,>R4=%ymm13
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm7,%ymm10,%ymm13

# qhasm:                               4x R3 = approx I1 * H2
# asm 1: vmulpd <I1=reg256#8,<H2=reg256#2,>R3=reg256#15
# asm 2: vmulpd <I1=%ymm7,<H2=%ymm1,>R3=%ymm14
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm7,%ymm1,%ymm14

# qhasm:                           4x a0b5 = approx I0 * H5
# asm 1: vmulpd <I0=reg256#6,<H5=reg256#10,>a0b5=reg256#16
# asm 2: vmulpd <I0=%ymm5,<H5=%ymm9,>a0b5=%ymm15
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm5,%ymm9,%ymm15

# qhasm:                           4x R5 approx+= a0b5
# asm 1: vaddpd <a0b5=reg256#16,<R5=reg256#13,>R5=reg256#13
# asm 2: vaddpd <a0b5=%ymm15,<R5=%ymm12,>R5=%ymm12
# bytes: 5 uops: 1
vaddpd %ymm15,%ymm12,%ymm12
# block pos: 1120 1152 uops: 6

# qhasm:                             4x a0b4 = approx I0 * H4
# asm 1: vmulpd <I0=reg256#6,<H4=reg256#1,>a0b4=reg256#16
# asm 2: vmulpd <I0=%ymm5,<H4=%ymm0,>a0b4=%ymm15
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm5,%ymm0,%ymm15

# qhasm:                             4x R4 approx+= a0b4
# asm 1: vaddpd <a0b4=reg256#16,<R4=reg256#14,>R4=reg256#14
# asm 2: vaddpd <a0b4=%ymm15,<R4=%ymm13,>R4=%ymm13
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm15,%ymm13,%ymm13

# qhasm:                               4x a0b3 = approx I0 * H3
# asm 1: vmulpd <I0=reg256#6,<H3=reg256#11,>a0b3=reg256#16
# asm 2: vmulpd <I0=%ymm5,<H3=%ymm10,>a0b3=%ymm15
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm5,%ymm10,%ymm15

# qhasm:                               4x R3 approx+= a0b3
# asm 1: vaddpd <a0b3=reg256#16,<R3=reg256#15,>R3=reg256#15
# asm 2: vaddpd <a0b3=%ymm15,<R3=%ymm14,>R3=%ymm14
# bytes: 5 uops: 1
vaddpd %ymm15,%ymm14,%ymm14

# qhasm:                           4x a3b2 = approx I3 * H2
# asm 1: vmulpd <I3=reg256#9,<H2=reg256#2,>a3b2=reg256#16
# asm 2: vmulpd <I3=%ymm8,<H2=%ymm1,>a3b2=%ymm15
# bytes: 5 uops: 1
vmulpd %ymm8,%ymm1,%ymm15

# qhasm:                           4x R5 approx+= a3b2
# asm 1: vaddpd <a3b2=reg256#16,<R5=reg256#13,>R5=reg256#13
# asm 2: vaddpd <a3b2=%ymm15,<R5=%ymm12,>R5=%ymm12
# bytes: 5 uops: 1
vaddpd %ymm15,%ymm12,%ymm12
# block pos: 1152 1184 uops: 6

# qhasm:                             4x a3b1 = approx I3 * H1
# asm 1: vmulpd <I3=reg256#9,<H1=reg256#12,>a3b1=reg256#16
# asm 2: vmulpd <I3=%ymm8,<H1=%ymm11,>a3b1=%ymm15
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm8,%ymm11,%ymm15

# qhasm:                             4x R4 approx+= a3b1
# asm 1: vaddpd <a3b1=reg256#16,<R4=reg256#14,>R4=reg256#14
# asm 2: vaddpd <a3b1=%ymm15,<R4=%ymm13,>R4=%ymm13
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm15,%ymm13,%ymm13

# qhasm: 			      4x a3b0 =approx I3 * H0
# asm 1: vmulpd <I3=reg256#9,<H0=reg256#3,>a3b0=reg256#9
# asm 2: vmulpd <I3=%ymm8,<H0=%ymm2,>a3b0=%ymm8
# bytes: 5 uops: 1
vmulpd %ymm8,%ymm2,%ymm8

# qhasm:                               4x R3 approx+= a3b0
# asm 1: vaddpd <a3b0=reg256#9,<R3=reg256#15,>R3=reg256#9
# asm 2: vaddpd <a3b0=%ymm8,<R3=%ymm14,>R3=%ymm8
# bytes: 5 uops: 1
vaddpd %ymm8,%ymm14,%ymm8

# qhasm:                           4x a2b3 = approx I2 * H3
# asm 1: vmulpd <I2=reg256#5,<H3=reg256#11,>a2b3=reg256#15
# asm 2: vmulpd <I2=%ymm4,<H3=%ymm10,>a2b3=%ymm14
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm4,%ymm10,%ymm14

# qhasm:                           4x R5 approx+= a2b3
# asm 1: vaddpd <a2b3=reg256#15,<R5=reg256#13,>R5=reg256#13
# asm 2: vaddpd <a2b3=%ymm14,<R5=%ymm12,>R5=%ymm12
# bytes: 5 uops: 1
vaddpd %ymm14,%ymm12,%ymm12
# block pos: 1184 1216 uops: 6

# qhasm:                             4x a2b2 = approx I2 * H2
# asm 1: vmulpd <I2=reg256#5,<H2=reg256#2,>a2b2=reg256#15
# asm 2: vmulpd <I2=%ymm4,<H2=%ymm1,>a2b2=%ymm14
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm4,%ymm1,%ymm14

# qhasm:                             4x R4 approx+= a2b2
# asm 1: vaddpd <a2b2=reg256#15,<R4=reg256#14,>R4=reg256#14
# asm 2: vaddpd <a2b2=%ymm14,<R4=%ymm13,>R4=%ymm13
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm14,%ymm13,%ymm13

# qhasm:                               4x a2b1 = approx I2 * H1
# asm 1: vmulpd <I2=reg256#5,<H1=reg256#12,>a2b1=reg256#15
# asm 2: vmulpd <I2=%ymm4,<H1=%ymm11,>a2b1=%ymm14
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm4,%ymm11,%ymm14

# qhasm:                               4x R3 approx+= a2b1
# asm 1: vaddpd <a2b1=reg256#15,<R3=reg256#9,>R3=reg256#9
# asm 2: vaddpd <a2b1=%ymm14,<R3=%ymm8,>R3=%ymm8
# bytes: 5 uops: 1
vaddpd %ymm14,%ymm8,%ymm8

# qhasm: 			  4x a5b0 = approx I5 * H0
# asm 1: vmulpd <I5=reg256#7,<H0=reg256#3,>a5b0=reg256#7
# asm 2: vmulpd <I5=%ymm6,<H0=%ymm2,>a5b0=%ymm6
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm6,%ymm2,%ymm6

# qhasm:                           4x R5 approx+= a5b0
# asm 1: vaddpd <a5b0=reg256#7,<R5=reg256#13,>R5=reg256#7
# asm 2: vaddpd <a5b0=%ymm6,<R5=%ymm12,>R5=%ymm6
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm6,%ymm12,%ymm6
# block pos: 1216 1248 uops: 6

# qhasm:                             4x a5b5 = approx H5 * 127I5_stack
# asm 1: vmulpd <127I5_stack=stack256#1,<H5=reg256#10,>a5b5=reg256#13
# asm 2: vmulpd <127I5_stack=0(%rsp),<H5=%ymm9,>a5b5=%ymm12
# bytes: 5 uops: 1
vmulpd 0(%rsp),%ymm9,%ymm12

# qhasm:                             4x R4 approx+= a5b5
# asm 1: vaddpd <a5b5=reg256#13,<R4=reg256#14,>R4=reg256#13
# asm 2: vaddpd <a5b5=%ymm12,<R4=%ymm13,>R4=%ymm12
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm12,%ymm13,%ymm12

# qhasm:                               4x a5b4 = approx H4 * 127I5_stack
# asm 1: vmulpd <127I5_stack=stack256#1,<H4=reg256#1,>a5b4=reg256#14
# asm 2: vmulpd <127I5_stack=0(%rsp),<H4=%ymm0,>a5b4=%ymm13
# bytes: 5 uops: 1
vmulpd 0(%rsp),%ymm0,%ymm13

# qhasm:                               4x R3 approx+= a5b4
# asm 1: vaddpd <a5b4=reg256#14,<R3=reg256#9,>R3=reg256#9
# asm 2: vaddpd <a5b4=%ymm13,<R3=%ymm8,>R3=%ymm8
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm13,%ymm8,%ymm8

# qhasm:                           4x a4b1 = approx I4 * H1
# asm 1: vmulpd <I4=reg256#4,<H1=reg256#12,>a4b1=reg256#14
# asm 2: vmulpd <I4=%ymm3,<H1=%ymm11,>a4b1=%ymm13
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm3,%ymm11,%ymm13

# qhasm:                           4x R5 approx+= a4b1
# asm 1: vaddpd <a4b1=reg256#14,<R5=reg256#7,>R5=reg256#7
# asm 2: vaddpd <a4b1=%ymm13,<R5=%ymm6,>R5=%ymm6
# bytes: 5 uops: 1
vaddpd %ymm13,%ymm6,%ymm6
# block pos: 1248 1280 uops: 6

# qhasm:                             4x a4b0 = approx I4 * H0
# asm 1: vmulpd <I4=reg256#4,<H0=reg256#3,>a4b0=reg256#4
# asm 2: vmulpd <I4=%ymm3,<H0=%ymm2,>a4b0=%ymm3
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm3,%ymm2,%ymm3

# qhasm: 			    4x R4 approx+= a4b0
# asm 1: vaddpd <a4b0=reg256#4,<R4=reg256#13,>R4=reg256#4
# asm 2: vaddpd <a4b0=%ymm3,<R4=%ymm12,>R4=%ymm3
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm3,%ymm12,%ymm3

# qhasm:                               4x a4b5 = approx H5 * 127I4_stack
# asm 1: vmulpd <127I4_stack=stack256#2,<H5=reg256#10,>a4b5=reg256#13
# asm 2: vmulpd <127I4_stack=32(%rsp),<H5=%ymm9,>a4b5=%ymm12
# bytes: 6 uops: 1
vmulpd 32(%rsp),%ymm9,%ymm12

# qhasm:                               4x R3 approx+= a4b5
# asm 1: vaddpd <a4b5=reg256#13,<R3=reg256#9,>R3=reg256#9
# asm 2: vaddpd <a4b5=%ymm12,<R3=%ymm8,>R3=%ymm8
# bytes: 5 uops: 1
vaddpd %ymm12,%ymm8,%ymm8

# qhasm:                                 4x R2 = approx I1 * H1
# asm 1: vmulpd <I1=reg256#8,<H1=reg256#12,>R2=reg256#13
# asm 2: vmulpd <I1=%ymm7,<H1=%ymm11,>R2=%ymm12
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm7,%ymm11,%ymm12

# qhasm:                                   4x R1 = approx I1 * H0
# asm 1: vmulpd <I1=reg256#8,<H0=reg256#3,>R1=reg256#8
# asm 2: vmulpd <I1=%ymm7,<H0=%ymm2,>R1=%ymm7
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm7,%ymm2,%ymm7
# block pos: 1280 1312 uops: 6

# qhasm:                                     4x R0 = approx H5 * mem256[const1 + 96]
# asm 1: vmulpd 96(<const1=int64#8),<H5=reg256#10,>R0=reg256#14
# asm 2: vmulpd 96(<const1=%r10),<H5=%ymm9,>R0=%ymm13
# bytes: 6 uops: 1
vmulpd 96(%r10),%ymm9,%ymm13

# qhasm:                                 4x a0b2 = approx I0 * H2
# asm 1: vmulpd <I0=reg256#6,<H2=reg256#2,>a0b2=reg256#15
# asm 2: vmulpd <I0=%ymm5,<H2=%ymm1,>a0b2=%ymm14
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm5,%ymm1,%ymm14

# qhasm:                                 4x R2 approx+= a0b2
# asm 1: vaddpd <a0b2=reg256#15,<R2=reg256#13,>R2=reg256#13
# asm 2: vaddpd <a0b2=%ymm14,<R2=%ymm12,>R2=%ymm12
# bytes: 5 uops: 1
vaddpd %ymm14,%ymm12,%ymm12

# qhasm:                                   4x a0b1 = approx I0 * H1
# asm 1: vmulpd <I0=reg256#6,<H1=reg256#12,>a0b1=reg256#15
# asm 2: vmulpd <I0=%ymm5,<H1=%ymm11,>a0b1=%ymm14
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm5,%ymm11,%ymm14

# qhasm:                                   4x R1 approx+= a0b1
# asm 1: vaddpd <a0b1=reg256#15,<R1=reg256#8,>R1=reg256#8
# asm 2: vaddpd <a0b1=%ymm14,<R1=%ymm7,>R1=%ymm7
# bytes: 5 uops: 1
vaddpd %ymm14,%ymm7,%ymm7

# qhasm:                                     4x a0b0 = approx I0 * H0
# asm 1: vmulpd <I0=reg256#6,<H0=reg256#3,>a0b0=reg256#6
# asm 2: vmulpd <I0=%ymm5,<H0=%ymm2,>a0b0=%ymm5
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm5,%ymm2,%ymm5
# block pos: 1312 1344 uops: 6

# qhasm:                                     4x R0 approx+= a0b0
# asm 1: vaddpd <a0b0=reg256#6,<R0=reg256#14,>R0=reg256#6
# asm 2: vaddpd <a0b0=%ymm5,<R0=%ymm13,>R0=%ymm5
# bytes: 4 uops: 1
vaddpd %ymm5,%ymm13,%ymm5

# qhasm:                                 4x a3b5 = approx H5 * 127I3_stack
# asm 1: vmulpd <127I3_stack=stack256#3,<H5=reg256#10,>a3b5=reg256#14
# asm 2: vmulpd <127I3_stack=64(%rsp),<H5=%ymm9,>a3b5=%ymm13
# bytes: 6 uops: 1
vmulpd 64(%rsp),%ymm9,%ymm13

# qhasm:                                 4x R2 approx+= a3b5
# asm 1: vaddpd <a3b5=reg256#14,<R2=reg256#13,>R2=reg256#13
# asm 2: vaddpd <a3b5=%ymm13,<R2=%ymm12,>R2=%ymm12
# bytes: 5 uops: 1
vaddpd %ymm13,%ymm12,%ymm12

# qhasm:                                   4x a3b4 = approx H4 * 127I3_stack
# asm 1: vmulpd <127I3_stack=stack256#3,<H4=reg256#1,>a3b4=reg256#14
# asm 2: vmulpd <127I3_stack=64(%rsp),<H4=%ymm0,>a3b4=%ymm13
# bytes: 6 uops: 1
vmulpd 64(%rsp),%ymm0,%ymm13

# qhasm:                                   4x R1 approx+= a3b4
# asm 1: vaddpd <a3b4=reg256#14,<R1=reg256#8,>R1=reg256#8
# asm 2: vaddpd <a3b4=%ymm13,<R1=%ymm7,>R1=%ymm7
# bytes: 5 uops: 1
vaddpd %ymm13,%ymm7,%ymm7

# qhasm:                                     4x a3b3 = approx H3 * 127I3_stack
# asm 1: vmulpd <127I3_stack=stack256#3,<H3=reg256#11,>a3b3=reg256#14
# asm 2: vmulpd <127I3_stack=64(%rsp),<H3=%ymm10,>a3b3=%ymm13
# bytes: 6 uops: 1
vmulpd 64(%rsp),%ymm10,%ymm13
# block pos: 1344 1376 uops: 6

# qhasm:                                     4x R0 approx+= a3b3
# asm 1: vaddpd <a3b3=reg256#14,<R0=reg256#6,>R0=reg256#6
# asm 2: vaddpd <a3b3=%ymm13,<R0=%ymm5,>R0=%ymm5
# bytes: 5 uops: 1
vaddpd %ymm13,%ymm5,%ymm5

# qhasm: 			        4x a2b0 =approx H0 * I2
# asm 1: vmulpd <H0=reg256#3,<I2=reg256#5,>a2b0=reg256#3
# asm 2: vmulpd <H0=%ymm2,<I2=%ymm4,>a2b0=%ymm2
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm2,%ymm4,%ymm2

# qhasm:                                 4x R2 approx+= a2b0
# asm 1: vaddpd <a2b0=reg256#3,<R2=reg256#13,>R2=reg256#3
# asm 2: vaddpd <a2b0=%ymm2,<R2=%ymm12,>R2=%ymm2
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm2,%ymm12,%ymm2

# qhasm:                                   4x a2b5 = approx H5 * 127I2_stack
# asm 1: vmulpd <127I2_stack=stack256#4,<H5=reg256#10,>a2b5=reg256#5
# asm 2: vmulpd <127I2_stack=96(%rsp),<H5=%ymm9,>a2b5=%ymm4
# bytes: 6 uops: 1
vmulpd 96(%rsp),%ymm9,%ymm4

# qhasm:                                   4x R1 approx+= a2b5
# asm 1: vaddpd <a2b5=reg256#5,<R1=reg256#8,>R1=reg256#5
# asm 2: vaddpd <a2b5=%ymm4,<R1=%ymm7,>R1=%ymm4
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm4,%ymm7,%ymm4

# qhasm:                                     4x a2b4 = approx H4 * 127I2_stack
# asm 1: vmulpd <127I2_stack=stack256#4,<H4=reg256#1,>a2b4=reg256#8
# asm 2: vmulpd <127I2_stack=96(%rsp),<H4=%ymm0,>a2b4=%ymm7
# bytes: 6 uops: 1
vmulpd 96(%rsp),%ymm0,%ymm7
# block pos: 1376 1408 uops: 6

# qhasm:                                     4x R0 approx+= a2b4
# asm 1: vaddpd <a2b4=reg256#8,<R0=reg256#6,>R0=reg256#6
# asm 2: vaddpd <a2b4=%ymm7,<R0=%ymm5,>R0=%ymm5
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddpd %ymm7,%ymm5,%ymm5

# qhasm:                                 4x a5b3 = approx H3 * 127I5_stack
# asm 1: vmulpd <127I5_stack=stack256#1,<H3=reg256#11,>a5b3=reg256#8
# asm 2: vmulpd <127I5_stack=0(%rsp),<H3=%ymm10,>a5b3=%ymm7
# bytes: 5 uops: 1
vmulpd 0(%rsp),%ymm10,%ymm7

# qhasm:                                 4x R2 approx+= a5b3
# asm 1: vaddpd <a5b3=reg256#8,<R2=reg256#3,>R2=reg256#3
# asm 2: vaddpd <a5b3=%ymm7,<R2=%ymm2,>R2=%ymm2
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddpd %ymm7,%ymm2,%ymm2

# qhasm:                                   4x a5b2 = approx H2 * 127I5_stack
# asm 1: vmulpd <127I5_stack=stack256#1,<H2=reg256#2,>a5b2=reg256#8
# asm 2: vmulpd <127I5_stack=0(%rsp),<H2=%ymm1,>a5b2=%ymm7
# bytes: 5 uops: 1
vmulpd 0(%rsp),%ymm1,%ymm7

# qhasm:                                   4x R1 approx+= a5b2
# asm 1: vaddpd <a5b2=reg256#8,<R1=reg256#5,>R1=reg256#5
# asm 2: vaddpd <a5b2=%ymm7,<R1=%ymm4,>R1=%ymm4
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm7,%ymm4,%ymm4

# qhasm:                                     4x a5b1 = approx H1 * 127I5_stack
# asm 1: vmulpd <127I5_stack=stack256#1,<H1=reg256#12,>a5b1=reg256#8
# asm 2: vmulpd <127I5_stack=0(%rsp),<H1=%ymm11,>a5b1=%ymm7
# bytes: 5 uops: 1
vmulpd 0(%rsp),%ymm11,%ymm7
# block pos: 1408 1440 uops: 6

# qhasm:                                     4x R0 approx+= a5b1
# asm 1: vaddpd <a5b1=reg256#8,<R0=reg256#6,>R0=reg256#6
# asm 2: vaddpd <a5b1=%ymm7,<R0=%ymm5,>R0=%ymm5
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm7,%ymm5,%ymm5

# qhasm:                                 4x a4b4 = approx H4 * 127I4_stack
# asm 1: vmulpd <127I4_stack=stack256#2,<H4=reg256#1,>a4b4=reg256#1
# asm 2: vmulpd <127I4_stack=32(%rsp),<H4=%ymm0,>a4b4=%ymm0
# bytes: 6 uops: 1
vmulpd 32(%rsp),%ymm0,%ymm0

# qhasm:                                 4x R2 approx+= a4b4
# asm 1: vaddpd <a4b4=reg256#1,<R2=reg256#3,>R2=reg256#1
# asm 2: vaddpd <a4b4=%ymm0,<R2=%ymm2,>R2=%ymm0
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm0,%ymm2,%ymm0

# qhasm:                                   4x a4b3 = approx H3 * 127I4_stack
# asm 1: vmulpd <127I4_stack=stack256#2,<H3=reg256#11,>a4b3=reg256#3
# asm 2: vmulpd <127I4_stack=32(%rsp),<H3=%ymm10,>a4b3=%ymm2
# bytes: 6 uops: 1
vmulpd 32(%rsp),%ymm10,%ymm2

# qhasm:                                   4x R1 approx+= a4b3
# asm 1: vaddpd <a4b3=reg256#3,<R1=reg256#5,>R1=reg256#3
# asm 2: vaddpd <a4b3=%ymm2,<R1=%ymm4,>R1=%ymm2
# bytes: 4 uops: 1
vaddpd %ymm2,%ymm4,%ymm2

# qhasm:                                     4x a4b2 = approx H2 * 127I4_stack
# asm 1: vmulpd <127I4_stack=stack256#2,<H2=reg256#2,>a4b2=reg256#2
# asm 2: vmulpd <127I4_stack=32(%rsp),<H2=%ymm1,>a4b2=%ymm1
# bytes: 6 uops: 1
vmulpd 32(%rsp),%ymm1,%ymm1
# block pos: 1440 1473 uops: 6

# qhasm:                                     4x R0 approx+= a4b2
# asm 1: vaddpd <a4b2=reg256#2,<R0=reg256#6,>R0=reg256#2
# asm 2: vaddpd <a4b2=%ymm1,<R0=%ymm5,>R0=%ymm1
# bytes: 4 uops: 1
vaddpd %ymm1,%ymm5,%ymm1

# qhasm:                                       4x c5 = approx R5 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#8),<R5=reg256#7,>c5=reg256#5
# asm 2: vmulpd -128(<const1=%r10),<R5=%ymm6,>c5=%ymm4
# bytes: 6 uops: 1
vmulpd -128(%r10),%ymm6,%ymm4

# qhasm:                                       4x c4 = approx R4 * mem256[const1 - 32]
# asm 1: vmulpd -32(<const1=int64#8),<R4=reg256#4,>c4=reg256#6
# asm 2: vmulpd -32(<const1=%r10),<R4=%ymm3,>c4=%ymm5
# bytes: 6 uops: 1
vmulpd -32(%r10),%ymm3,%ymm5

# qhasm:                                       4x c3 = approx R3 * mem256[const1 - 64]
# asm 1: vmulpd -64(<const1=int64#8),<R3=reg256#9,>c3=reg256#8
# asm 2: vmulpd -64(<const1=%r10),<R3=%ymm8,>c3=%ymm7
# bytes: 6 uops: 1
vmulpd -64(%r10),%ymm8,%ymm7

# qhasm:                                       4x c2 = approx R2 * mem256[const1 - 96]
# asm 1: vmulpd -96(<const1=int64#8),<R2=reg256#1,>c2=reg256#10
# asm 2: vmulpd -96(<const1=%r10),<R2=%ymm0,>c2=%ymm9
# bytes: 6 uops: 1
vmulpd -96(%r10),%ymm0,%ymm9

# qhasm:                                       4x c1 = approx R1 * mem256[const0 + 96]
# asm 1: vmulpd 96(<const0=int64#7),<R1=reg256#3,>c1=reg256#11
# asm 2: vmulpd 96(<const0=%rax),<R1=%ymm2,>c1=%ymm10
# bytes: 5 uops: 1
vmulpd 96(%rax),%ymm2,%ymm10
# block pos: 1473 1508 uops: 6

# qhasm:                                       4x c0 = approx R0 * mem256[const0 + 64]
# asm 1: vmulpd 64(<const0=int64#7),<R0=reg256#2,>c0=reg256#12
# asm 2: vmulpd 64(<const0=%rax),<R0=%ymm1,>c0=%ymm11
# bytes: 5 uops: 1
vmulpd 64(%rax),%ymm1,%ymm11

# qhasm:                                       4x c5 = round(c5)
# asm 1: vroundpd $8,<c5=reg256#5,>c5=reg256#5
# asm 2: vroundpd $8,<c5=%ymm4,>c5=%ymm4
# bytes: 6 uops: 1
vroundpd $8,%ymm4,%ymm4

# qhasm:                                       4x c4 = round(c4)
# asm 1: vroundpd $8,<c4=reg256#6,>c4=reg256#6
# asm 2: vroundpd $8,<c4=%ymm5,>c4=%ymm5
# bytes: 6 uops: 1
vroundpd $8,%ymm5,%ymm5

# qhasm:                                       4x c3 = round(c3)
# asm 1: vroundpd $8,<c3=reg256#8,>c3=reg256#8
# asm 2: vroundpd $8,<c3=%ymm7,>c3=%ymm7
# bytes: 6 uops: 1
vroundpd $8,%ymm7,%ymm7

# qhasm:                                       4x c2 = round(c2)
# asm 1: vroundpd $8,<c2=reg256#10,>c2=reg256#10
# asm 2: vroundpd $8,<c2=%ymm9,>c2=%ymm9
# bytes: 6 uops: 1
vroundpd $8,%ymm9,%ymm9

# qhasm:                                       4x c1 = round(c1)
# asm 1: vroundpd $8,<c1=reg256#11,>c1=reg256#11
# asm 2: vroundpd $8,<c1=%ymm10,>c1=%ymm10
# bytes: 6 uops: 1
vroundpd $8,%ymm10,%ymm10
# block pos: 1508 1537 uops: 6

# qhasm:                                       4x c0 = round(c0)
# asm 1: vroundpd $8,<c0=reg256#12,>c0=reg256#12
# asm 2: vroundpd $8,<c0=%ymm11,>c0=%ymm11
# bytes: 6 uops: 1
vroundpd $8,%ymm11,%ymm11

# qhasm:                                         4x R0 approx+= c5
# asm 1: vaddpd <c5=reg256#5,<R0=reg256#2,>R0=reg256#2
# asm 2: vaddpd <c5=%ymm4,<R0=%ymm1,>R0=%ymm1
# bytes: 4 uops: 1
vaddpd %ymm4,%ymm1,%ymm1

# qhasm:                                       4x c4 approx*= mem256[const0 + 0]
# asm 1: vmulpd 0(<const0=int64#7),<c4=reg256#6,>c4=reg256#6
# asm 2: vmulpd 0(<const0=%rax),<c4=%ymm5,>c4=%ymm5
# bytes: 4 uops: 1
vmulpd 0(%rax),%ymm5,%ymm5

# qhasm:                                       4x c3 approx*= mem256[const0 - 32]
# asm 1: vmulpd -32(<const0=int64#7),<c3=reg256#8,>c3=reg256#8
# asm 2: vmulpd -32(<const0=%rax),<c3=%ymm7,>c3=%ymm7
# bytes: 5 uops: 1
vmulpd -32(%rax),%ymm7,%ymm7

# qhasm:                                       4x c2 approx*= mem256[const0 - 64]
# asm 1: vmulpd -64(<const0=int64#7),<c2=reg256#10,>c2=reg256#10
# asm 2: vmulpd -64(<const0=%rax),<c2=%ymm9,>c2=%ymm9
# bytes: 5 uops: 1
vmulpd -64(%rax),%ymm9,%ymm9

# qhasm:                                       4x c1 approx*= mem256[const0 - 96]
# asm 1: vmulpd -96(<const0=int64#7),<c1=reg256#11,>c1=reg256#11
# asm 2: vmulpd -96(<const0=%rax),<c1=%ymm10,>c1=%ymm10
# bytes: 5 uops: 1
vmulpd -96(%rax),%ymm10,%ymm10
# block pos: 1537 1568 uops: 6

# qhasm:                                       4x c0 approx*= mem256[const0 - 128]
# asm 1: vmulpd -128(<const0=int64#7),<c0=reg256#12,>c0=reg256#12
# asm 2: vmulpd -128(<const0=%rax),<c0=%ymm11,>c0=%ymm11
# bytes: 5 uops: 1
vmulpd -128(%rax),%ymm11,%ymm11

# qhasm:                                         4x c5 approx*= mem256[const0 + 32]
# asm 1: vmulpd 32(<const0=int64#7),<c5=reg256#5,>c5=reg256#5
# asm 2: vmulpd 32(<const0=%rax),<c5=%ymm4,>c5=%ymm4
# bytes: 5 uops: 1
vmulpd 32(%rax),%ymm4,%ymm4

# qhasm:                                         4x R5 approx-= c5
# asm 1: vsubpd <c5=reg256#5,<R5=reg256#7,>R5=reg256#5
# asm 2: vsubpd <c5=%ymm4,<R5=%ymm6,>R5=%ymm4
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vsubpd %ymm4,%ymm6,%ymm4

# qhasm:                                         4x R5 approx+= c4
# asm 1: vaddpd <c4=reg256#6,<R5=reg256#5,>R5=reg256#5
# asm 2: vaddpd <c4=%ymm5,<R5=%ymm4,>R5=%ymm4
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm5,%ymm4,%ymm4

# qhasm:                                         4x R4 approx-= c4
# asm 1: vsubpd <c4=reg256#6,<R4=reg256#4,>R4=reg256#4
# asm 2: vsubpd <c4=%ymm5,<R4=%ymm3,>R4=%ymm3
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm5,%ymm3,%ymm3

# qhasm:                                         4x R4 approx+= c3
# asm 1: vaddpd <c3=reg256#8,<R4=reg256#4,>R4=reg256#4
# asm 2: vaddpd <c3=%ymm7,<R4=%ymm3,>R4=%ymm3
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm7,%ymm3,%ymm3
# block pos: 1568 1600 uops: 6

# qhasm:                                         4x R3 approx-= c3
# asm 1: vsubpd <c3=reg256#8,<R3=reg256#9,>R3=reg256#6
# asm 2: vsubpd <c3=%ymm7,<R3=%ymm8,>R3=%ymm5
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vsubpd %ymm7,%ymm8,%ymm5

# qhasm:                                         4x R3 approx+= c2
# asm 1: vaddpd <c2=reg256#10,<R3=reg256#6,>R3=reg256#6
# asm 2: vaddpd <c2=%ymm9,<R3=%ymm5,>R3=%ymm5
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm9,%ymm5,%ymm5

# qhasm:                                         4x R2 approx-= c2
# asm 1: vsubpd <c2=reg256#10,<R2=reg256#1,>R2=reg256#1
# asm 2: vsubpd <c2=%ymm9,<R2=%ymm0,>R2=%ymm0
# bytes: 5 uops: 1
vsubpd %ymm9,%ymm0,%ymm0

# qhasm:                                         4x R2 approx+= c1
# asm 1: vaddpd <c1=reg256#11,<R2=reg256#1,>R2=reg256#1
# asm 2: vaddpd <c1=%ymm10,<R2=%ymm0,>R2=%ymm0
# bytes: 5 uops: 1
vaddpd %ymm10,%ymm0,%ymm0

# qhasm:                                         4x R1 approx-= c1
# asm 1: vsubpd <c1=reg256#11,<R1=reg256#3,>R1=reg256#3
# asm 2: vsubpd <c1=%ymm10,<R1=%ymm2,>R1=%ymm2
# bytes: 5 uops: 1
vsubpd %ymm10,%ymm2,%ymm2

# qhasm:                                         4x R1 approx+= c0
# asm 1: vaddpd <c0=reg256#12,<R1=reg256#3,>R1=reg256#3
# asm 2: vaddpd <c0=%ymm11,<R1=%ymm2,>R1=%ymm2
# bytes: 5 uops: 1
vaddpd %ymm11,%ymm2,%ymm2
# block pos: 1600 1632 uops: 6

# qhasm:                                         4x R0 approx-= c0
# asm 1: vsubpd <c0=reg256#12,<R0=reg256#2,>R0=reg256#2
# asm 2: vsubpd <c0=%ymm11,<R0=%ymm1,>R0=%ymm1
# bytes: 5 uops: 1
vsubpd %ymm11,%ymm1,%ymm1

# qhasm:   Q0 aligned= mem256[work1 - 128]
# asm 1: vmovapd   -128(<work1=int64#5),>Q0=reg256#7
# asm 2: vmovapd   -128(<work1=%r8),>Q0=%ymm6
# bytes: 6 uops: 1
vmovapd   -128(%r8),%ymm6

# qhasm:     4x 2Q0 = approx Q0 + Q0
# asm 1: vaddpd <Q0=reg256#7,<Q0=reg256#7,>2Q0=reg256#8
# asm 2: vaddpd <Q0=%ymm6,<Q0=%ymm6,>2Q0=%ymm7
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm6,%ymm6,%ymm7

# qhasm:       4x S0 =approx Q0 * Q0
# asm 1: vmulpd <Q0=reg256#7,<Q0=reg256#7,>S0=reg256#7
# asm 2: vmulpd <Q0=%ymm6,<Q0=%ymm6,>S0=%ymm6
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm6,%ymm6,%ymm6

# qhasm:                           abcd aligned= mem256[const2 + 96]
# asm 1: vmovapd   96(<const2=int64#9),>abcd=reg256#9
# asm 2: vmovapd   96(<const2=%r11),>abcd=%ymm8
# bytes: 6 uops: 1
vmovapd   96(%r11),%ymm8

# qhasm:                           4x R5 = approx R5 * abcd
# asm 1: vmulpd <R5=reg256#5,<abcd=reg256#9,>R5=reg256#5
# asm 2: vmulpd <R5=%ymm4,<abcd=%ymm8,>R5=%ymm4
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm4,%ymm8,%ymm4
# block pos: 1632 1664 uops: 6

# qhasm:                           4x R4 = approx R4 * abcd
# asm 1: vmulpd <R4=reg256#4,<abcd=reg256#9,>R4=reg256#4
# asm 2: vmulpd <R4=%ymm3,<abcd=%ymm8,>R4=%ymm3
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm3,%ymm8,%ymm3

# qhasm:                           4x R3 = approx R3 * abcd
# asm 1: vmulpd <R3=reg256#6,<abcd=reg256#9,>R3=reg256#6
# asm 2: vmulpd <R3=%ymm5,<abcd=%ymm8,>R3=%ymm5
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm5,%ymm8,%ymm5

# qhasm:                           4x R2 = approx R2 * abcd
# asm 1: vmulpd <R2=reg256#1,<abcd=reg256#9,>R2=reg256#1
# asm 2: vmulpd <R2=%ymm0,<abcd=%ymm8,>R2=%ymm0
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm0,%ymm8,%ymm0

# qhasm:                           4x R1 = approx R1 * abcd
# asm 1: vmulpd <R1=reg256#3,<abcd=reg256#9,>R1=reg256#3
# asm 2: vmulpd <R1=%ymm2,<abcd=%ymm8,>R1=%ymm2
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm2,%ymm8,%ymm2

# qhasm:                           4x R0 = approx R0 * abcd
# asm 1: vmulpd <R0=reg256#2,<abcd=reg256#9,>R0=reg256#2
# asm 2: vmulpd <R0=%ymm1,<abcd=%ymm8,>R0=%ymm1
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm1,%ymm8,%ymm1

# qhasm:   Q1 aligned= mem256[work1 - 96]
# asm 1: vmovapd   -96(<work1=int64#5),>Q1=reg256#9
# asm 2: vmovapd   -96(<work1=%r8),>Q1=%ymm8
# bytes: 6 uops: 1
vmovapd   -96(%r8),%ymm8
# block pos: 1664 1696 uops: 6

# qhasm:     4x 2Q1 = approx Q1 + Q1
# asm 1: vaddpd <Q1=reg256#9,<Q1=reg256#9,>2Q1=reg256#10
# asm 2: vaddpd <Q1=%ymm8,<Q1=%ymm8,>2Q1=%ymm9
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm8,%ymm8,%ymm9

# qhasm:       4x S2 =approx Q1 * Q1
# asm 1: vmulpd <Q1=reg256#9,<Q1=reg256#9,>S2=reg256#11
# asm 2: vmulpd <Q1=%ymm8,<Q1=%ymm8,>S2=%ymm10
# bytes: 5 uops: 1
vmulpd %ymm8,%ymm8,%ymm10

# qhasm:       4x S1 =approx 2Q0 * Q1
# asm 1: vmulpd <2Q0=reg256#8,<Q1=reg256#9,>S1=reg256#9
# asm 2: vmulpd <2Q0=%ymm7,<Q1=%ymm8,>S1=%ymm8
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm7,%ymm8,%ymm8

# qhasm:                           a127 aligned= mem256[const2 + 32]
# asm 1: vmovapd   32(<const2=int64#9),>a127=reg256#12
# asm 2: vmovapd   32(<const2=%r11),>a127=%ymm11
# bytes: 6 uops: 1
vmovapd   32(%r11),%ymm11

# qhasm:                           4x c5 = approx R5 + a127
# asm 1: vaddpd <R5=reg256#5,<a127=reg256#12,>c5=reg256#13
# asm 2: vaddpd <R5=%ymm4,<a127=%ymm11,>c5=%ymm12
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm4,%ymm11,%ymm12

# qhasm:                           4x c5 approx-= a127
# asm 1: vsubpd <a127=reg256#12,<c5=reg256#13,>c5=reg256#12
# asm 2: vsubpd <a127=%ymm11,<c5=%ymm12,>c5=%ymm11
# bytes: 5 uops: 1
vsubpd %ymm11,%ymm12,%ymm11
# block pos: 1696 1728 uops: 6

# qhasm:                           4x R5 approx-= c5
# asm 1: vsubpd <c5=reg256#12,<R5=reg256#5,>R5=reg256#5
# asm 2: vsubpd <c5=%ymm11,<R5=%ymm4,>R5=%ymm4
# bytes: 5 uops: 1
vsubpd %ymm11,%ymm4,%ymm4

# qhasm: 	                  4x c5 approx*= mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#8),<c5=reg256#12,>c5=reg256#12
# asm 2: vmulpd -128(<const1=%r10),<c5=%ymm11,>c5=%ymm11
# bytes: 6 uops: 1
vmulpd -128(%r10),%ymm11,%ymm11

# qhasm:                           4x R0 approx+= c5
# asm 1: vaddpd <c5=reg256#12,<R0=reg256#2,>R0=reg256#2
# asm 2: vaddpd <c5=%ymm11,<R0=%ymm1,>R0=%ymm1
# bytes: 5 uops: 1
vaddpd %ymm11,%ymm1,%ymm1

# qhasm:                           4x R4 approx+= R5
# asm 1: vaddpd <R5=reg256#5,<R4=reg256#4,>R4=reg256#4
# asm 2: vaddpd <R5=%ymm4,<R4=%ymm3,>R4=%ymm3
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm4,%ymm3,%ymm3

# qhasm:   Q2 aligned= mem256[work1 - 64]
# asm 1: vmovapd   -64(<work1=int64#5),>Q2=reg256#5
# asm 2: vmovapd   -64(<work1=%r8),>Q2=%ymm4
# bytes: 6 uops: 1
vmovapd   -64(%r8),%ymm4

# qhasm:       4x S4 =approx Q2 * Q2
# asm 1: vmulpd <Q2=reg256#5,<Q2=reg256#5,>S4=reg256#12
# asm 2: vmulpd <Q2=%ymm4,<Q2=%ymm4,>S4=%ymm11
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm4,%ymm4,%ymm11
# block pos: 1728 1760 uops: 6

# qhasm:       4x S3 =approx 2Q1 * Q2
# asm 1: vmulpd <2Q1=reg256#10,<Q2=reg256#5,>S3=reg256#13
# asm 2: vmulpd <2Q1=%ymm9,<Q2=%ymm4,>S3=%ymm12
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm9,%ymm4,%ymm12

# qhasm:       4x 2Q0Q2 = approx 2Q0 * Q2
# asm 1: vmulpd <2Q0=reg256#8,<Q2=reg256#5,>2Q0Q2=reg256#14
# asm 2: vmulpd <2Q0=%ymm7,<Q2=%ymm4,>2Q0Q2=%ymm13
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm7,%ymm4,%ymm13

# qhasm:       4x S2 approx+= 2Q0Q2
# asm 1: vaddpd <2Q0Q2=reg256#14,<S2=reg256#11,>S2=reg256#11
# asm 2: vaddpd <2Q0Q2=%ymm13,<S2=%ymm10,>S2=%ymm10
# bytes: 5 uops: 1
vaddpd %ymm13,%ymm10,%ymm10

# qhasm:     4x 2Q2 = approx Q2 * mem256[const1 + 0]
# asm 1: vmulpd 0(<const1=int64#8),<Q2=reg256#5,>2Q2=reg256#5
# asm 2: vmulpd 0(<const1=%r10),<Q2=%ymm4,>2Q2=%ymm4
# bytes: 5 uops: 1
vmulpd 0(%r10),%ymm4,%ymm4

# qhasm:                           a85 aligned= mem256[const2 - 32]
# asm 1: vmovapd   -32(<const2=int64#9),>a85=reg256#14
# asm 2: vmovapd   -32(<const2=%r11),>a85=%ymm13
# bytes: 6 uops: 1
vmovapd   -32(%r11),%ymm13

# qhasm:                           4x c3 = approx R3 + a85
# asm 1: vaddpd <R3=reg256#6,<a85=reg256#14,>c3=reg256#15
# asm 2: vaddpd <R3=%ymm5,<a85=%ymm13,>c3=%ymm14
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm5,%ymm13,%ymm14
# block pos: 1760 1792 uops: 6

# qhasm:                           4x c3 approx-= a85
# asm 1: vsubpd <a85=reg256#14,<c3=reg256#15,>c3=reg256#14
# asm 2: vsubpd <a85=%ymm13,<c3=%ymm14,>c3=%ymm13
# bytes: 6 uops: 1
.byte 0x3e
vsubpd %ymm13,%ymm14,%ymm13

# qhasm:                           4x R4 approx+= c3
# asm 1: vaddpd <c3=reg256#14,<R4=reg256#4,>R4=reg256#4
# asm 2: vaddpd <c3=%ymm13,<R4=%ymm3,>R4=%ymm3
# bytes: 5 uops: 1
vaddpd %ymm13,%ymm3,%ymm3

# qhasm: 			  4x R3 approx-= c3
# asm 1: vsubpd <c3=reg256#14,<R3=reg256#6,>R3=reg256#6
# asm 2: vsubpd <c3=%ymm13,<R3=%ymm5,>R3=%ymm5
# bytes: 5 uops: 1
vsubpd %ymm13,%ymm5,%ymm5

# qhasm:                           4x R2 approx+= R3
# asm 1: vaddpd <R3=reg256#6,<R2=reg256#1,>R2=reg256#1
# asm 2: vaddpd <R3=%ymm5,<R2=%ymm0,>R2=%ymm0
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm5,%ymm0,%ymm0

# qhasm:                           a43 aligned= mem256[const2 - 96]
# asm 1: vmovapd   -96(<const2=int64#9),>a43=reg256#6
# asm 2: vmovapd   -96(<const2=%r11),>a43=%ymm5
# bytes: 6 uops: 1
vmovapd   -96(%r11),%ymm5

# qhasm:                           4x c1 = approx R1 + a43
# asm 1: vaddpd <R1=reg256#3,<a43=reg256#6,>c1=reg256#14
# asm 2: vaddpd <R1=%ymm2,<a43=%ymm5,>c1=%ymm13
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm2,%ymm5,%ymm13
# block pos: 1792 1824 uops: 6

# qhasm:                           4x c1 approx-= a43
# asm 1: vsubpd <a43=reg256#6,<c1=reg256#14,>c1=reg256#6
# asm 2: vsubpd <a43=%ymm5,<c1=%ymm13,>c1=%ymm5
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vsubpd %ymm5,%ymm13,%ymm5

# qhasm:                           4x R2 approx+= c1
# asm 1: vaddpd <c1=reg256#6,<R2=reg256#1,>R2=reg256#1
# asm 2: vaddpd <c1=%ymm5,<R2=%ymm0,>R2=%ymm0
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm5,%ymm0,%ymm0

# qhasm: 			  4x R1 approx-= c1
# asm 1: vsubpd <c1=reg256#6,<R1=reg256#3,>R1=reg256#3
# asm 2: vsubpd <c1=%ymm5,<R1=%ymm2,>R1=%ymm2
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm5,%ymm2,%ymm2

# qhasm:                           4x R0 approx+= R1
# asm 1: vaddpd <R1=reg256#3,<R0=reg256#2,>R0=reg256#2
# asm 2: vaddpd <R1=%ymm2,<R0=%ymm1,>R0=%ymm1
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm2,%ymm1,%ymm1

# qhasm:   Q3 aligned= mem256[work1 - 32]
# asm 1: vmovapd   -32(<work1=int64#5),>Q3=reg256#3
# asm 2: vmovapd   -32(<work1=%r8),>Q3=%ymm2
# bytes: 6 uops: 1
vmovapd   -32(%r8),%ymm2

# qhasm:       4x S5 = approx 2Q2 * Q3
# asm 1: vmulpd <2Q2=reg256#5,<Q3=reg256#3,>S5=reg256#6
# asm 2: vmulpd <2Q2=%ymm4,<Q3=%ymm2,>S5=%ymm5
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm4,%ymm2,%ymm5
# block pos: 1824 1856 uops: 6

# qhasm:       4x 2Q1Q3 = approx 2Q1 * Q3
# asm 1: vmulpd <2Q1=reg256#10,<Q3=reg256#3,>2Q1Q3=reg256#14
# asm 2: vmulpd <2Q1=%ymm9,<Q3=%ymm2,>2Q1Q3=%ymm13
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm9,%ymm2,%ymm13

# qhasm:       4x S4 approx+= 2Q1Q3
# asm 1: vaddpd <2Q1Q3=reg256#14,<S4=reg256#12,>S4=reg256#12
# asm 2: vaddpd <2Q1Q3=%ymm13,<S4=%ymm11,>S4=%ymm11
# bytes: 5 uops: 1
vaddpd %ymm13,%ymm11,%ymm11

# qhasm:       4x 2Q0Q3 = approx 2Q0 * Q3
# asm 1: vmulpd <2Q0=reg256#8,<Q3=reg256#3,>2Q0Q3=reg256#14
# asm 2: vmulpd <2Q0=%ymm7,<Q3=%ymm2,>2Q0Q3=%ymm13
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm7,%ymm2,%ymm13

# qhasm:       4x S3 approx+= 2Q0Q3
# asm 1: vaddpd <2Q0Q3=reg256#14,<S3=reg256#13,>S3=reg256#13
# asm 2: vaddpd <2Q0Q3=%ymm13,<S3=%ymm12,>S3=%ymm12
# bytes: 5 uops: 1
vaddpd %ymm13,%ymm12,%ymm12

# qhasm:       4x Q3Q3 = approx Q3 * Q3
# asm 1: vmulpd <Q3=reg256#3,<Q3=reg256#3,>Q3Q3=reg256#14
# asm 2: vmulpd <Q3=%ymm2,<Q3=%ymm2,>Q3Q3=%ymm13
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm2,%ymm2,%ymm13

# qhasm:       4x Q3Q3 approx*= mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#8),<Q3Q3=reg256#14,>Q3Q3=reg256#14
# asm 2: vmulpd -128(<const1=%r10),<Q3Q3=%ymm13,>Q3Q3=%ymm13
# bytes: 6 uops: 1
vmulpd -128(%r10),%ymm13,%ymm13
# block pos: 1856 1888 uops: 6

# qhasm:       4x S0 approx+= Q3Q3
# asm 1: vaddpd <Q3Q3=reg256#14,<S0=reg256#7,>S0=reg256#7
# asm 2: vaddpd <Q3Q3=%ymm13,<S0=%ymm6,>S0=%ymm6
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm13,%ymm6,%ymm6

# qhasm:     4x 2Q3 = approx Q3 * mem256[const1 + 0]
# asm 1: vmulpd 0(<const1=int64#8),<Q3=reg256#3,>2Q3=reg256#3
# asm 2: vmulpd 0(<const1=%r10),<Q3=%ymm2,>2Q3=%ymm2
# bytes: 5 uops: 1
vmulpd 0(%r10),%ymm2,%ymm2

# qhasm:   Q4 aligned= mem256[work1 + 0]
# asm 1: vmovapd   0(<work1=int64#5),>Q4=reg256#14
# asm 2: vmovapd   0(<work1=%r8),>Q4=%ymm13
# bytes: 5 uops: 1
vmovapd   0(%r8),%ymm13

# qhasm:       4x 2Q1Q4 = approx 2Q1 * Q4
# asm 1: vmulpd <2Q1=reg256#10,<Q4=reg256#14,>2Q1Q4=reg256#15
# asm 2: vmulpd <2Q1=%ymm9,<Q4=%ymm13,>2Q1Q4=%ymm14
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm9,%ymm13,%ymm14

# qhasm:       4x S5 approx+= 2Q1Q4
# asm 1: vaddpd <2Q1Q4=reg256#15,<S5=reg256#6,>S5=reg256#6
# asm 2: vaddpd <2Q1Q4=%ymm14,<S5=%ymm5,>S5=%ymm5
# bytes: 5 uops: 1
vaddpd %ymm14,%ymm5,%ymm5

# qhasm:       4x 2Q0Q4 = approx 2Q0 * Q4
# asm 1: vmulpd <2Q0=reg256#8,<Q4=reg256#14,>2Q0Q4=reg256#15
# asm 2: vmulpd <2Q0=%ymm7,<Q4=%ymm13,>2Q0Q4=%ymm14
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm7,%ymm13,%ymm14
# block pos: 1888 1920 uops: 6

# qhasm:       4x S4 approx+= 2Q0Q4
# asm 1: vaddpd <2Q0Q4=reg256#15,<S4=reg256#12,>S4=reg256#12
# asm 2: vaddpd <2Q0Q4=%ymm14,<S4=%ymm11,>S4=%ymm11
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm14,%ymm11,%ymm11

# qhasm:     4x 127Q4 = approx Q4 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#8),<Q4=reg256#14,>127Q4=reg256#15
# asm 2: vmulpd -128(<const1=%r10),<Q4=%ymm13,>127Q4=%ymm14
# bytes: 6 uops: 1
vmulpd -128(%r10),%ymm13,%ymm14

# qhasm:       4x Q4Q4 = approx Q4 * 127Q4
# asm 1: vmulpd <Q4=reg256#14,<127Q4=reg256#15,>Q4Q4=reg256#16
# asm 2: vmulpd <Q4=%ymm13,<127Q4=%ymm14,>Q4Q4=%ymm15
# bytes: 5 uops: 1
vmulpd %ymm13,%ymm14,%ymm15

# qhasm:       4x S2 approx+= Q4Q4
# asm 1: vaddpd <Q4Q4=reg256#16,<S2=reg256#11,>S2=reg256#11
# asm 2: vaddpd <Q4Q4=%ymm15,<S2=%ymm10,>S2=%ymm10
# bytes: 5 uops: 1
vaddpd %ymm15,%ymm10,%ymm10

# qhasm:       4x 2Q3Q4 = approx 2Q3 * 127Q4
# asm 1: vmulpd <2Q3=reg256#3,<127Q4=reg256#15,>2Q3Q4=reg256#16
# asm 2: vmulpd <2Q3=%ymm2,<127Q4=%ymm14,>2Q3Q4=%ymm15
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm2,%ymm14,%ymm15

# qhasm:       4x S1 approx+= 2Q3Q4
# asm 1: vaddpd <2Q3Q4=reg256#16,<S1=reg256#9,>S1=reg256#9
# asm 2: vaddpd <2Q3Q4=%ymm15,<S1=%ymm8,>S1=%ymm8
# bytes: 5 uops: 1
vaddpd %ymm15,%ymm8,%ymm8
# block pos: 1920 1952 uops: 6

# qhasm:       4x 2Q2Q4 = approx 2Q2 * 127Q4
# asm 1: vmulpd <2Q2=reg256#5,<127Q4=reg256#15,>2Q2Q4=reg256#15
# asm 2: vmulpd <2Q2=%ymm4,<127Q4=%ymm14,>2Q2Q4=%ymm14
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm4,%ymm14,%ymm14

# qhasm:       4x S0 approx+= 2Q2Q4
# asm 1: vaddpd <2Q2Q4=reg256#15,<S0=reg256#7,>S0=reg256#7
# asm 2: vaddpd <2Q2Q4=%ymm14,<S0=%ymm6,>S0=%ymm6
# bytes: 5 uops: 1
vaddpd %ymm14,%ymm6,%ymm6

# qhasm:     4x 2Q4 = approx Q4 * mem256[const1 + 0]
# asm 1: vmulpd 0(<const1=int64#8),<Q4=reg256#14,>2Q4=reg256#14
# asm 2: vmulpd 0(<const1=%r10),<Q4=%ymm13,>2Q4=%ymm13
# bytes: 5 uops: 1
vmulpd 0(%r10),%ymm13,%ymm13

# qhasm:   Q5 aligned= mem256[work1 + 32]
# asm 1: vmovapd   32(<work1=int64#5),>Q5=reg256#15
# asm 2: vmovapd   32(<work1=%r8),>Q5=%ymm14
# bytes: 6 uops: 1
vmovapd   32(%r8),%ymm14

# qhasm:       4x 2Q0Q5 =approx 2Q0 * Q5
# asm 1: vmulpd <2Q0=reg256#8,<Q5=reg256#15,>2Q0Q5=reg256#8
# asm 2: vmulpd <2Q0=%ymm7,<Q5=%ymm14,>2Q0Q5=%ymm7
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm7,%ymm14,%ymm7

# qhasm:       4x S5 approx+= 2Q0Q5
# asm 1: vaddpd <2Q0Q5=reg256#8,<S5=reg256#6,>S5=reg256#6
# asm 2: vaddpd <2Q0Q5=%ymm7,<S5=%ymm5,>S5=%ymm5
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm7,%ymm5,%ymm5
# block pos: 1952 1984 uops: 6

# qhasm:     4x 127Q5 = approx Q5 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#8),<Q5=reg256#15,>127Q5=reg256#8
# asm 2: vmulpd -128(<const1=%r10),<Q5=%ymm14,>127Q5=%ymm7
# bytes: 6 uops: 1
vmulpd -128(%r10),%ymm14,%ymm7

# qhasm:       4x Q5Q5 = approx Q5 * 127Q5
# asm 1: vmulpd <Q5=reg256#15,<127Q5=reg256#8,>Q5Q5=reg256#15
# asm 2: vmulpd <Q5=%ymm14,<127Q5=%ymm7,>Q5Q5=%ymm14
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm14,%ymm7,%ymm14

# qhasm:       4x S4 approx+= Q5Q5
# asm 1: vaddpd <Q5Q5=reg256#15,<S4=reg256#12,>S4=reg256#12
# asm 2: vaddpd <Q5Q5=%ymm14,<S4=%ymm11,>S4=%ymm11
# bytes: 5 uops: 1
vaddpd %ymm14,%ymm11,%ymm11

# qhasm:       4x 2Q4Q5 = approx 2Q4 * 127Q5
# asm 1: vmulpd <2Q4=reg256#14,<127Q5=reg256#8,>2Q4Q5=reg256#14
# asm 2: vmulpd <2Q4=%ymm13,<127Q5=%ymm7,>2Q4Q5=%ymm13
# bytes: 5 uops: 1
vmulpd %ymm13,%ymm7,%ymm13

# qhasm:       4x S3 approx+= 2Q4Q5
# asm 1: vaddpd <2Q4Q5=reg256#14,<S3=reg256#13,>S3=reg256#13
# asm 2: vaddpd <2Q4Q5=%ymm13,<S3=%ymm12,>S3=%ymm12
# bytes: 5 uops: 1
vaddpd %ymm13,%ymm12,%ymm12

# qhasm:       4x 2Q3Q5 = approx 2Q3 * 127Q5
# asm 1: vmulpd <2Q3=reg256#3,<127Q5=reg256#8,>2Q3Q5=reg256#3
# asm 2: vmulpd <2Q3=%ymm2,<127Q5=%ymm7,>2Q3Q5=%ymm2
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm2,%ymm7,%ymm2
# block pos: 1984 2016 uops: 6

# qhasm:       4x S2 approx+= 2Q3Q5
# asm 1: vaddpd <2Q3Q5=reg256#3,<S2=reg256#11,>S2=reg256#3
# asm 2: vaddpd <2Q3Q5=%ymm2,<S2=%ymm10,>S2=%ymm2
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddpd %ymm2,%ymm10,%ymm2

# qhasm:       4x 2Q2Q5 = approx 2Q2 * 127Q5
# asm 1: vmulpd <2Q2=reg256#5,<127Q5=reg256#8,>2Q2Q5=reg256#5
# asm 2: vmulpd <2Q2=%ymm4,<127Q5=%ymm7,>2Q2Q5=%ymm4
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm4,%ymm7,%ymm4

# qhasm:       4x S1 approx+= 2Q2Q5
# asm 1: vaddpd <2Q2Q5=reg256#5,<S1=reg256#9,>S1=reg256#5
# asm 2: vaddpd <2Q2Q5=%ymm4,<S1=%ymm8,>S1=%ymm4
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm4,%ymm8,%ymm4

# qhasm:       4x 2Q1Q5 = approx 2Q1 * 127Q5
# asm 1: vmulpd <2Q1=reg256#10,<127Q5=reg256#8,>2Q1Q5=reg256#8
# asm 2: vmulpd <2Q1=%ymm9,<127Q5=%ymm7,>2Q1Q5=%ymm7
# bytes: 5 uops: 1
vmulpd %ymm9,%ymm7,%ymm7

# qhasm:       4x S0 approx+= 2Q1Q5
# asm 1: vaddpd <2Q1Q5=reg256#8,<S0=reg256#7,>S0=reg256#7
# asm 2: vaddpd <2Q1Q5=%ymm7,<S0=%ymm6,>S0=%ymm6
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm7,%ymm6,%ymm6

# qhasm:                           yxtz4[0,1,2,3] = R4[1,0,3,2]
# asm 1: vpermilpd $0x5,<R4=reg256#4,>yxtz4=reg256#8
# asm 2: vpermilpd $0x5,<R4=%ymm3,>yxtz4=%ymm7
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm3,%ymm7
# block pos: 2016 2048 uops: 6

# qhasm:                           abcd4[0,1,2,3] approx= R4[0]-yxtz4[0],R4[1]+yxtz4[1],R4[2]-yxtz4[2],R4[3]+yxtz4[3]
# asm 1: vaddsubpd <yxtz4=reg256#8,<R4=reg256#4,>abcd4=reg256#4
# asm 2: vaddsubpd <yxtz4=%ymm7,<R4=%ymm3,>abcd4=%ymm3
# bytes: 7 uops: 1
.byte 0x3e
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm7,%ymm3,%ymm3

# qhasm:                           cdab4[0,1,2,3] = abcd4[2,3],abcd4[0,1]
# asm 1: vperm2f128 $0x21,<abcd4=reg256#4,<abcd4=reg256#4,>cdab4=reg256#8
# asm 2: vperm2f128 $0x21,<abcd4=%ymm3,<abcd4=%ymm3,>cdab4=%ymm7
# bytes: 7 uops: 2
.byte 0x3e
vperm2f128 $0x21,%ymm3,%ymm3,%ymm7

# qhasm:                           badc4[0,1,2,3] = abcd4[1,0,3,2]
# asm 1: vpermilpd $0x5,<abcd4=reg256#4,>badc4=reg256#4
# asm 2: vpermilpd $0x5,<abcd4=%ymm3,>badc4=%ymm3
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm3,%ymm3

# qhasm:                           A4[0,1,2,3] approx= badc4[0]-cdab4[0],badc4[1]+cdab4[1],badc4[2]-cdab4[2],badc4[3]+cdab4[3]
# asm 1: vaddsubpd <cdab4=reg256#8,<badc4=reg256#4,>A4=reg256#4
# asm 2: vaddsubpd <cdab4=%ymm7,<badc4=%ymm3,>A4=%ymm3
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm7,%ymm3,%ymm3

# qhasm:   4x c5 = approx S5 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#8),<S5=reg256#6,>c5=reg256#8
# asm 2: vmulpd -128(<const1=%r10),<S5=%ymm5,>c5=%ymm7
# bytes: 6 uops: 1
vmulpd -128(%r10),%ymm5,%ymm7
# block pos: 2048 2082 uops: 6

# qhasm:   4x c4 = approx S4 * mem256[const1 - 32]
# asm 1: vmulpd -32(<const1=int64#8),<S4=reg256#12,>c4=reg256#9
# asm 2: vmulpd -32(<const1=%r10),<S4=%ymm11,>c4=%ymm8
# bytes: 6 uops: 1
vmulpd -32(%r10),%ymm11,%ymm8

# qhasm:   4x c3 = approx S3 * mem256[const1 - 64]
# asm 1: vmulpd -64(<const1=int64#8),<S3=reg256#13,>c3=reg256#10
# asm 2: vmulpd -64(<const1=%r10),<S3=%ymm12,>c3=%ymm9
# bytes: 6 uops: 1
vmulpd -64(%r10),%ymm12,%ymm9

# qhasm:   4x c2 = approx S2 * mem256[const1 - 96]
# asm 1: vmulpd -96(<const1=int64#8),<S2=reg256#3,>c2=reg256#11
# asm 2: vmulpd -96(<const1=%r10),<S2=%ymm2,>c2=%ymm10
# bytes: 6 uops: 1
vmulpd -96(%r10),%ymm2,%ymm10

# qhasm:   4x c1 = approx S1 * mem256[const0 + 96]
# asm 1: vmulpd 96(<const0=int64#7),<S1=reg256#5,>c1=reg256#14
# asm 2: vmulpd 96(<const0=%rax),<S1=%ymm4,>c1=%ymm13
# bytes: 5 uops: 1
vmulpd 96(%rax),%ymm4,%ymm13

# qhasm:   4x c0 = approx S0 * mem256[const0 + 64]
# asm 1: vmulpd 64(<const0=int64#7),<S0=reg256#7,>c0=reg256#15
# asm 2: vmulpd 64(<const0=%rax),<S0=%ymm6,>c0=%ymm14
# bytes: 5 uops: 1
vmulpd 64(%rax),%ymm6,%ymm14

# qhasm:   4x c5 = round(c5)
# asm 1: vroundpd $8,<c5=reg256#8,>c5=reg256#8
# asm 2: vroundpd $8,<c5=%ymm7,>c5=%ymm7
# bytes: 6 uops: 1
vroundpd $8,%ymm7,%ymm7
# block pos: 2082 2112 uops: 5

# qhasm:   4x c4 = round(c4)
# asm 1: vroundpd $8,<c4=reg256#9,>c4=reg256#9
# asm 2: vroundpd $8,<c4=%ymm8,>c4=%ymm8
# bytes: 6 uops: 1
vroundpd $8,%ymm8,%ymm8

# qhasm:   4x c3 = round(c3)
# asm 1: vroundpd $8,<c3=reg256#10,>c3=reg256#10
# asm 2: vroundpd $8,<c3=%ymm9,>c3=%ymm9
# bytes: 6 uops: 1
vroundpd $8,%ymm9,%ymm9

# qhasm:   4x c2 = round(c2)
# asm 1: vroundpd $8,<c2=reg256#11,>c2=reg256#11
# asm 2: vroundpd $8,<c2=%ymm10,>c2=%ymm10
# bytes: 6 uops: 1
vroundpd $8,%ymm10,%ymm10

# qhasm:   4x c1 = round(c1)
# asm 1: vroundpd $8,<c1=reg256#14,>c1=reg256#14
# asm 2: vroundpd $8,<c1=%ymm13,>c1=%ymm13
# bytes: 6 uops: 1
vroundpd $8,%ymm13,%ymm13

# qhasm:   4x c0 = round(c0)
# asm 1: vroundpd $8,<c0=reg256#15,>c0=reg256#15
# asm 2: vroundpd $8,<c0=%ymm14,>c0=%ymm14
# bytes: 6 uops: 1
vroundpd $8,%ymm14,%ymm14
# block pos: 2112 2144 uops: 6

# qhasm:   4x S0 approx+= c5
# asm 1: vaddpd <c5=reg256#8,<S0=reg256#7,>S0=reg256#7
# asm 2: vaddpd <c5=%ymm7,<S0=%ymm6,>S0=%ymm6
# bytes: 8 uops: 1
.byte 0x3e
.byte 0x3e
.byte 0x3e
.byte 0x3e
vaddpd %ymm7,%ymm6,%ymm6

# qhasm:   4x c4 approx*= mem256[const0 + 0]
# asm 1: vmulpd 0(<const0=int64#7),<c4=reg256#9,>c4=reg256#9
# asm 2: vmulpd 0(<const0=%rax),<c4=%ymm8,>c4=%ymm8
# bytes: 4 uops: 1
vmulpd 0(%rax),%ymm8,%ymm8

# qhasm:   4x c3 approx*= mem256[const0 - 32]
# asm 1: vmulpd -32(<const0=int64#7),<c3=reg256#10,>c3=reg256#10
# asm 2: vmulpd -32(<const0=%rax),<c3=%ymm9,>c3=%ymm9
# bytes: 5 uops: 1
vmulpd -32(%rax),%ymm9,%ymm9

# qhasm:   4x c2 approx*= mem256[const0 - 64]
# asm 1: vmulpd -64(<const0=int64#7),<c2=reg256#11,>c2=reg256#11
# asm 2: vmulpd -64(<const0=%rax),<c2=%ymm10,>c2=%ymm10
# bytes: 5 uops: 1
vmulpd -64(%rax),%ymm10,%ymm10

# qhasm:   4x c1 approx*= mem256[const0 - 96]
# asm 1: vmulpd -96(<const0=int64#7),<c1=reg256#14,>c1=reg256#14
# asm 2: vmulpd -96(<const0=%rax),<c1=%ymm13,>c1=%ymm13
# bytes: 5 uops: 1
vmulpd -96(%rax),%ymm13,%ymm13

# qhasm:   4x c0 approx*= mem256[const0 - 128]
# asm 1: vmulpd -128(<const0=int64#7),<c0=reg256#15,>c0=reg256#15
# asm 2: vmulpd -128(<const0=%rax),<c0=%ymm14,>c0=%ymm14
# bytes: 5 uops: 1
vmulpd -128(%rax),%ymm14,%ymm14
# block pos: 2144 2176 uops: 6

# qhasm:                           yxtz2[0,1,2,3] = R2[1,0,3,2]
# asm 1: vpermilpd $0x5,<R2=reg256#1,>yxtz2=reg256#16
# asm 2: vpermilpd $0x5,<R2=%ymm0,>yxtz2=%ymm15
# bytes: 7 uops: 1
.byte 0x3e
vpermilpd $0x5,%ymm0,%ymm15

# qhasm:                           abcd2[0,1,2,3] approx= R2[0]-yxtz2[0],R2[1]+yxtz2[1],R2[2]-yxtz2[2],R2[3]+yxtz2[3]
# asm 1: vaddsubpd <yxtz2=reg256#16,<R2=reg256#1,>abcd2=reg256#1
# asm 2: vaddsubpd <yxtz2=%ymm15,<R2=%ymm0,>abcd2=%ymm0
# bytes: 7 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm15,%ymm0,%ymm0

# qhasm:                           cdab2[0,1,2,3] = abcd2[2,3],abcd2[0,1]
# asm 1: vperm2f128 $0x21,<abcd2=reg256#1,<abcd2=reg256#1,>cdab2=reg256#16
# asm 2: vperm2f128 $0x21,<abcd2=%ymm0,<abcd2=%ymm0,>cdab2=%ymm15
# bytes: 6 uops: 2
vperm2f128 $0x21,%ymm0,%ymm0,%ymm15

# qhasm:                           badc2[0,1,2,3] = abcd2[1,0,3,2]
# asm 1: vpermilpd $0x5,<abcd2=reg256#1,>badc2=reg256#1
# asm 2: vpermilpd $0x5,<abcd2=%ymm0,>badc2=%ymm0
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm0,%ymm0

# qhasm:                           A2[0,1,2,3] approx= badc2[0]-cdab2[0],badc2[1]+cdab2[1],badc2[2]-cdab2[2],badc2[3]+cdab2[3]
# asm 1: vaddsubpd <cdab2=reg256#16,<badc2=reg256#1,>A2=reg256#1
# asm 2: vaddsubpd <cdab2=%ymm15,<badc2=%ymm0,>A2=%ymm0
# bytes: 6 uops: 1
.byte 0x3e
vaddsubpd %ymm15,%ymm0,%ymm0
# block pos: 2176 2208 uops: 6

# qhasm:   4x c5 approx*= mem256[const0 + 32]
# asm 1: vmulpd 32(<const0=int64#7),<c5=reg256#8,>c5=reg256#8
# asm 2: vmulpd 32(<const0=%rax),<c5=%ymm7,>c5=%ymm7
# bytes: 5 uops: 1
vmulpd 32(%rax),%ymm7,%ymm7

# qhasm:   4x S5 approx+= c4
# asm 1: vaddpd <c4=reg256#9,<S5=reg256#6,>S5=reg256#6
# asm 2: vaddpd <c4=%ymm8,<S5=%ymm5,>S5=%ymm5
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm8,%ymm5,%ymm5

# qhasm:   4x S4 approx+= c3
# asm 1: vaddpd <c3=reg256#10,<S4=reg256#12,>S4=reg256#12
# asm 2: vaddpd <c3=%ymm9,<S4=%ymm11,>S4=%ymm11
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm9,%ymm11,%ymm11

# qhasm:   4x S3 approx+= c2
# asm 1: vaddpd <c2=reg256#11,<S3=reg256#13,>S3=reg256#13
# asm 2: vaddpd <c2=%ymm10,<S3=%ymm12,>S3=%ymm12
# bytes: 5 uops: 1
vaddpd %ymm10,%ymm12,%ymm12

# qhasm:   4x S2 approx+= c1
# asm 1: vaddpd <c1=reg256#14,<S2=reg256#3,>S2=reg256#3
# asm 2: vaddpd <c1=%ymm13,<S2=%ymm2,>S2=%ymm2
# bytes: 5 uops: 1
vaddpd %ymm13,%ymm2,%ymm2

# qhasm:   4x S1 approx+= c0
# asm 1: vaddpd <c0=reg256#15,<S1=reg256#5,>S1=reg256#5
# asm 2: vaddpd <c0=%ymm14,<S1=%ymm4,>S1=%ymm4
# bytes: 5 uops: 1
vaddpd %ymm14,%ymm4,%ymm4
# block pos: 2208 2240 uops: 6

# qhasm:   4x S5 approx-= c5
# asm 1: vsubpd <c5=reg256#8,<S5=reg256#6,>S5=reg256#6
# asm 2: vsubpd <c5=%ymm7,<S5=%ymm5,>S5=%ymm5
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vsubpd %ymm7,%ymm5,%ymm5

# qhasm:   4x S4 approx-= c4
# asm 1: vsubpd <c4=reg256#9,<S4=reg256#12,>S4=reg256#8
# asm 2: vsubpd <c4=%ymm8,<S4=%ymm11,>S4=%ymm7
# bytes: 6 uops: 1
.byte 0x3e
vsubpd %ymm8,%ymm11,%ymm7

# qhasm:   4x S3 approx-= c3
# asm 1: vsubpd <c3=reg256#10,<S3=reg256#13,>S3=reg256#9
# asm 2: vsubpd <c3=%ymm9,<S3=%ymm12,>S3=%ymm8
# bytes: 5 uops: 1
vsubpd %ymm9,%ymm12,%ymm8

# qhasm:   4x S2 approx-= c2
# asm 1: vsubpd <c2=reg256#11,<S2=reg256#3,>S2=reg256#3
# asm 2: vsubpd <c2=%ymm10,<S2=%ymm2,>S2=%ymm2
# bytes: 5 uops: 1
vsubpd %ymm10,%ymm2,%ymm2

# qhasm:   4x S1 approx-= c1
# asm 1: vsubpd <c1=reg256#14,<S1=reg256#5,>S1=reg256#5
# asm 2: vsubpd <c1=%ymm13,<S1=%ymm4,>S1=%ymm4
# bytes: 5 uops: 1
vsubpd %ymm13,%ymm4,%ymm4

# qhasm:   4x S0 approx-= c0
# asm 1: vsubpd <c0=reg256#15,<S0=reg256#7,>S0=reg256#7
# asm 2: vsubpd <c0=%ymm14,<S0=%ymm6,>S0=%ymm6
# bytes: 5 uops: 1
vsubpd %ymm14,%ymm6,%ymm6
# block pos: 2240 2272 uops: 6

# qhasm:                           yxtz0[0,1,2,3] = R0[1,0,3,2]
# asm 1: vpermilpd $0x5,<R0=reg256#2,>yxtz0=reg256#10
# asm 2: vpermilpd $0x5,<R0=%ymm1,>yxtz0=%ymm9
# bytes: 7 uops: 1
.byte 0x3e
vpermilpd $0x5,%ymm1,%ymm9

# qhasm:                           abcd0[0,1,2,3] approx= R0[0]-yxtz0[0],R0[1]+yxtz0[1],R0[2]-yxtz0[2],R0[3]+yxtz0[3]
# asm 1: vaddsubpd <yxtz0=reg256#10,<R0=reg256#2,>abcd0=reg256#2
# asm 2: vaddsubpd <yxtz0=%ymm9,<R0=%ymm1,>abcd0=%ymm1
# bytes: 7 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm9,%ymm1,%ymm1

# qhasm:                           cdab0[0,1,2,3] = abcd0[2,3],abcd0[0,1]
# asm 1: vperm2f128 $0x21,<abcd0=reg256#2,<abcd0=reg256#2,>cdab0=reg256#10
# asm 2: vperm2f128 $0x21,<abcd0=%ymm1,<abcd0=%ymm1,>cdab0=%ymm9
# bytes: 6 uops: 2
vperm2f128 $0x21,%ymm1,%ymm1,%ymm9

# qhasm:                           badc0[0,1,2,3] = abcd0[1,0,3,2]
# asm 1: vpermilpd $0x5,<abcd0=reg256#2,>badc0=reg256#2
# asm 2: vpermilpd $0x5,<abcd0=%ymm1,>badc0=%ymm1
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm1,%ymm1

# qhasm:                           A0[0,1,2,3] approx= badc0[0]-cdab0[0],badc0[1]+cdab0[1],badc0[2]-cdab0[2],badc0[3]+cdab0[3]
# asm 1: vaddsubpd <cdab0=reg256#10,<badc0=reg256#2,>A0=reg256#2
# asm 2: vaddsubpd <cdab0=%ymm9,<badc0=%ymm1,>A0=%ymm1
# bytes: 6 uops: 1
.byte 0x3e
vaddsubpd %ymm9,%ymm1,%ymm1
# block pos: 2272 2304 uops: 6

# qhasm:                           a106 aligned= mem256[const2 + 0]
# asm 1: vmovapd   0(<const2=int64#9),>a106=reg256#10
# asm 2: vmovapd   0(<const2=%r11),>a106=%ymm9
# bytes: 5 uops: 1
vmovapd   0(%r11),%ymm9

# qhasm:                           4x A5 = approx A4 + a106
# asm 1: vaddpd <A4=reg256#4,<a106=reg256#10,>A5=reg256#11
# asm 2: vaddpd <A4=%ymm3,<a106=%ymm9,>A5=%ymm10
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddpd %ymm3,%ymm9,%ymm10

# qhasm:                           4x A5 approx-= a106
# asm 1: vsubpd <a106=reg256#10,<A5=reg256#11,>A5=reg256#10
# asm 2: vsubpd <a106=%ymm9,<A5=%ymm10,>A5=%ymm9
# bytes: 5 uops: 1
vsubpd %ymm9,%ymm10,%ymm9

# qhasm:                           4x A4 approx-= A5
# asm 1: vsubpd <A5=reg256#10,<A4=reg256#4,>A4=reg256#4
# asm 2: vsubpd <A5=%ymm9,<A4=%ymm3,>A4=%ymm3
# bytes: 5 uops: 1
vsubpd %ymm9,%ymm3,%ymm3

# qhasm:                           a64 aligned= mem256[const2 - 64]
# asm 1: vmovapd   -64(<const2=int64#9),>a64=reg256#11
# asm 2: vmovapd   -64(<const2=%r11),>a64=%ymm10
# bytes: 6 uops: 1
vmovapd   -64(%r11),%ymm10

# qhasm:                           4x A3 = approx A2 + a64
# asm 1: vaddpd <A2=reg256#1,<a64=reg256#11,>A3=reg256#12
# asm 2: vaddpd <A2=%ymm0,<a64=%ymm10,>A3=%ymm11
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm0,%ymm10,%ymm11
# block pos: 2304 2336 uops: 6

# qhasm:                           4x A3 approx-= a64
# asm 1: vsubpd <a64=reg256#11,<A3=reg256#12,>A3=reg256#11
# asm 2: vsubpd <a64=%ymm10,<A3=%ymm11,>A3=%ymm10
# bytes: 6 uops: 1
.byte 0x3e
vsubpd %ymm10,%ymm11,%ymm10

# qhasm:                           4x A2 approx-= A3
# asm 1: vsubpd <A3=reg256#11,<A2=reg256#1,>A2=reg256#1
# asm 2: vsubpd <A3=%ymm10,<A2=%ymm0,>A2=%ymm0
# bytes: 5 uops: 1
vsubpd %ymm10,%ymm0,%ymm0

# qhasm:                           a22 aligned= mem256[const2 - 128]
# asm 1: vmovapd   -128(<const2=int64#9),>a22=reg256#12
# asm 2: vmovapd   -128(<const2=%r11),>a22=%ymm11
# bytes: 6 uops: 1
vmovapd   -128(%r11),%ymm11

# qhasm:                           4x A1 = approx A0 + a22
# asm 1: vaddpd <A0=reg256#2,<a22=reg256#12,>A1=reg256#13
# asm 2: vaddpd <A0=%ymm1,<a22=%ymm11,>A1=%ymm12
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm1,%ymm11,%ymm12

# qhasm:                           4x A1 approx-= a22
# asm 1: vsubpd <a22=reg256#12,<A1=reg256#13,>A1=reg256#12
# asm 2: vsubpd <a22=%ymm11,<A1=%ymm12,>A1=%ymm11
# bytes: 5 uops: 1
vsubpd %ymm11,%ymm12,%ymm11

# qhasm:                           4x A0 approx-= A1
# asm 1: vsubpd <A1=reg256#12,<A0=reg256#2,>A0=reg256#2
# asm 2: vsubpd <A1=%ymm11,<A0=%ymm1,>A0=%ymm1
# bytes: 5 uops: 1
vsubpd %ymm11,%ymm1,%ymm1
# block pos: 2336 2368 uops: 6

# qhasm:                           abcd aligned= mem256[const2 + 96]
# asm 1: vmovapd   96(<const2=int64#9),>abcd=reg256#13
# asm 2: vmovapd   96(<const2=%r11),>abcd=%ymm12
# bytes: 6 uops: 1
vmovapd   96(%r11),%ymm12

# qhasm:   4x S5 = approx S5 * abcd
# asm 1: vmulpd <S5=reg256#6,<abcd=reg256#13,>S5=reg256#6
# asm 2: vmulpd <S5=%ymm5,<abcd=%ymm12,>S5=%ymm5
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm5,%ymm12,%ymm5

# qhasm:   4x S4 = approx S4 * abcd
# asm 1: vmulpd <S4=reg256#8,<abcd=reg256#13,>S4=reg256#8
# asm 2: vmulpd <S4=%ymm7,<abcd=%ymm12,>S4=%ymm7
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm7,%ymm12,%ymm7

# qhasm:   4x S3 = approx S3 * abcd
# asm 1: vmulpd <S3=reg256#9,<abcd=reg256#13,>S3=reg256#9
# asm 2: vmulpd <S3=%ymm8,<abcd=%ymm12,>S3=%ymm8
# bytes: 5 uops: 1
vmulpd %ymm8,%ymm12,%ymm8

# qhasm:   4x S2 = approx S2 * abcd
# asm 1: vmulpd <S2=reg256#3,<abcd=reg256#13,>S2=reg256#3
# asm 2: vmulpd <S2=%ymm2,<abcd=%ymm12,>S2=%ymm2
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm2,%ymm12,%ymm2

# qhasm:   4x S1 = approx S1 * abcd
# asm 1: vmulpd <S1=reg256#5,<abcd=reg256#13,>S1=reg256#5
# asm 2: vmulpd <S1=%ymm4,<abcd=%ymm12,>S1=%ymm4
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm4,%ymm12,%ymm4
# block pos: 2368 2401 uops: 6

# qhasm:   4x S0 = approx S0 * abcd
# asm 1: vmulpd <S0=reg256#7,<abcd=reg256#13,>S0=reg256#7
# asm 2: vmulpd <S0=%ymm6,<abcd=%ymm12,>S0=%ymm6
# bytes: 4 uops: 1
vmulpd %ymm6,%ymm12,%ymm6

# qhasm:   4x c5 = approx S5 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#8),<S5=reg256#6,>c5=reg256#13
# asm 2: vmulpd -128(<const1=%r10),<S5=%ymm5,>c5=%ymm12
# bytes: 6 uops: 1
vmulpd -128(%r10),%ymm5,%ymm12

# qhasm:   4x c5 = round(c5)
# asm 1: vroundpd $8,<c5=reg256#13,>c5=reg256#13
# asm 2: vroundpd $8,<c5=%ymm12,>c5=%ymm12
# bytes: 6 uops: 1
vroundpd $8,%ymm12,%ymm12

# qhasm:   4x S0 approx+= c5
# asm 1: vaddpd <c5=reg256#13,<S0=reg256#7,>S0=reg256#7
# asm 2: vaddpd <c5=%ymm12,<S0=%ymm6,>S0=%ymm6
# bytes: 5 uops: 1
vaddpd %ymm12,%ymm6,%ymm6

# qhasm:   4x c3 = approx S3 * mem256[const1 - 64]
# asm 1: vmulpd -64(<const1=int64#8),<S3=reg256#9,>c3=reg256#14
# asm 2: vmulpd -64(<const1=%r10),<S3=%ymm8,>c3=%ymm13
# bytes: 6 uops: 1
vmulpd -64(%r10),%ymm8,%ymm13

# qhasm:   4x c3 = round(c3)
# asm 1: vroundpd $8,<c3=reg256#14,>c3=reg256#14
# asm 2: vroundpd $8,<c3=%ymm13,>c3=%ymm13
# bytes: 6 uops: 1
vroundpd $8,%ymm13,%ymm13
# block pos: 2401 2432 uops: 6

# qhasm:   4x c3 approx*= mem256[const0 - 32]
# asm 1: vmulpd -32(<const0=int64#7),<c3=reg256#14,>c3=reg256#14
# asm 2: vmulpd -32(<const0=%rax),<c3=%ymm13,>c3=%ymm13
# bytes: 5 uops: 1
vmulpd -32(%rax),%ymm13,%ymm13

# qhasm:   4x c1 = approx S1 * mem256[const0 + 96]
# asm 1: vmulpd 96(<const0=int64#7),<S1=reg256#5,>c1=reg256#15
# asm 2: vmulpd 96(<const0=%rax),<S1=%ymm4,>c1=%ymm14
# bytes: 5 uops: 1
vmulpd 96(%rax),%ymm4,%ymm14

# qhasm:   4x c1 = round(c1)
# asm 1: vroundpd $8,<c1=reg256#15,>c1=reg256#15
# asm 2: vroundpd $8,<c1=%ymm14,>c1=%ymm14
# bytes: 6 uops: 1
vroundpd $8,%ymm14,%ymm14

# qhasm:   4x c1 approx*= mem256[const0 - 96]
# asm 1: vmulpd -96(<const0=int64#7),<c1=reg256#15,>c1=reg256#15
# asm 2: vmulpd -96(<const0=%rax),<c1=%ymm14,>c1=%ymm14
# bytes: 5 uops: 1
vmulpd -96(%rax),%ymm14,%ymm14

# qhasm:   4x c5 approx*= mem256[const0 + 32]
# asm 1: vmulpd 32(<const0=int64#7),<c5=reg256#13,>c5=reg256#13
# asm 2: vmulpd 32(<const0=%rax),<c5=%ymm12,>c5=%ymm12
# bytes: 5 uops: 1
vmulpd 32(%rax),%ymm12,%ymm12

# qhasm:   4x S4 approx+= c3
# asm 1: vaddpd <c3=reg256#14,<S4=reg256#8,>S4=reg256#8
# asm 2: vaddpd <c3=%ymm13,<S4=%ymm7,>S4=%ymm7
# bytes: 5 uops: 1
vaddpd %ymm13,%ymm7,%ymm7
# block pos: 2432 2464 uops: 6

# qhasm:   4x S2 approx+= c1
# asm 1: vaddpd <c1=reg256#15,<S2=reg256#3,>S2=reg256#3
# asm 2: vaddpd <c1=%ymm14,<S2=%ymm2,>S2=%ymm2
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm14,%ymm2,%ymm2

# qhasm:   4x S5 approx-= c5
# asm 1: vsubpd <c5=reg256#13,<S5=reg256#6,>S5=reg256#6
# asm 2: vsubpd <c5=%ymm12,<S5=%ymm5,>S5=%ymm5
# bytes: 6 uops: 1
.byte 0x3e
vsubpd %ymm12,%ymm5,%ymm5

# qhasm:   4x S4 approx+= S5
# asm 1: vaddpd <S5=reg256#6,<S4=reg256#8,>S4=reg256#6
# asm 2: vaddpd <S5=%ymm5,<S4=%ymm7,>S4=%ymm5
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm5,%ymm7,%ymm5

# qhasm:   4x S3 approx-= c3
# asm 1: vsubpd <c3=reg256#14,<S3=reg256#9,>S3=reg256#8
# asm 2: vsubpd <c3=%ymm13,<S3=%ymm8,>S3=%ymm7
# bytes: 5 uops: 1
vsubpd %ymm13,%ymm8,%ymm7

# qhasm:   4x S2 approx+= S3
# asm 1: vaddpd <S3=reg256#8,<S2=reg256#3,>S2=reg256#3
# asm 2: vaddpd <S3=%ymm7,<S2=%ymm2,>S2=%ymm2
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm7,%ymm2,%ymm2

# qhasm:   4x S1 approx-= c1
# asm 1: vsubpd <c1=reg256#15,<S1=reg256#5,>S1=reg256#5
# asm 2: vsubpd <c1=%ymm14,<S1=%ymm4,>S1=%ymm4
# bytes: 5 uops: 1
vsubpd %ymm14,%ymm4,%ymm4
# block pos: 2464 2499 uops: 10

# qhasm:   4x S0 approx+= S1
# asm 1: vaddpd <S1=reg256#5,<S0=reg256#7,>S0=reg256#5
# asm 2: vaddpd <S1=%ymm4,<S0=%ymm6,>S0=%ymm4
# bytes: 4 uops: 1
vaddpd %ymm4,%ymm6,%ymm4

# qhasm:                signed<? pos -= 1
# asm 1: sub  $1,<pos=int64#10
# asm 2: sub  $1,<pos=%r12
# bytes: 4 uops: 1
sub  $1,%r12
# comment:fp stack unchanged by jump

# qhasm: goto noload if signed<
# bytes: 2 uops: 1
jl ._noload

# qhasm:   i = pos
# asm 1: mov  <pos=int64#10,>i=int64#4
# asm 2: mov  <pos=%r12,>i=%rcx
# bytes: 3 uops: 1
mov  %r12,%rcx

# qhasm:   (uint64) i >>= 3
# asm 1: shr  $3,<i=int64#4
# asm 2: shr  $3,<i=%rcx
# bytes: 4 uops: 1
shr  $3,%rcx

# qhasm:   bit = *(uint8 *) (input_1 + i)
# asm 1: movzbq (<input_1=int64#2,<i=int64#4),>bit=int64#12
# asm 2: movzbq (<input_1=%rsi,<i=%rcx),>bit=%r14
# bytes: 5 uops: 1
movzbq (%rsi,%rcx),%r14

# qhasm:   j = pos
# asm 1: mov  <pos=int64#10,>j=int64#4
# asm 2: mov  <pos=%r12,>j=%rcx
# bytes: 3 uops: 1
mov  %r12,%rcx

# qhasm:   (uint32) j &= 7
# asm 1: and  $7,<j=int64#4d
# asm 2: and  $7,<j=%ecx
# bytes: 3 uops: 1
and  $7,%ecx

# qhasm:   (uint64) bit >>= j
# asm 1: shr  %cl,<bit=int64#12
# asm 2: shr  %cl,<bit=%r14
# bytes: 3 uops: 1
shr  %cl,%r14

# qhasm:   (uint32) bit &= 1
# asm 1: and  $1,<bit=int64#12d
# asm 2: and  $1,<bit=%r14d
# bytes: 4 uops: 1
and  $1,%r14d
# block pos: 2499 2528 uops: 6

# qhasm:   bit ^= prevbit
# asm 1: xor  <prevbit=int64#11,<bit=int64#12
# asm 2: xor  <prevbit=%r13,<bit=%r14
# bytes: 5 uops: 1
.byte 0x3e
.byte 0x3e
xor  %r13,%r14

# qhasm:   prevbit ^= bit
# asm 1: xor  <bit=int64#12,<prevbit=int64#11
# asm 2: xor  <bit=%r14,<prevbit=%r13
# bytes: 5 uops: 1
.byte 0x3e
.byte 0x3e
xor  %r14,%r13

# qhasm:   bit -= 1
# asm 1: sub  $1,<bit=int64#12
# asm 2: sub  $1,<bit=%r14
# bytes: 5 uops: 1
.byte 0x3e
sub  $1,%r14

# qhasm:   mem64[work3 + 32] = bit
# asm 1: movq   <bit=int64#12,32(<work3=int64#1)
# asm 2: movq   <bit=%r14,32(<work3=%rdi)
# bytes: 4 uops: 1
movq   %r14,32(%rdi)
# comment:fp stack unchanged by fallthrough

# qhasm: noload:
._noload:

# qhasm:   yxtz4[0,1,2,3] = S4[1,0,3,2]
# asm 1: vpermilpd $0x5,<S4=reg256#6,>yxtz4=reg256#7
# asm 2: vpermilpd $0x5,<S4=%ymm5,>yxtz4=%ymm6
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm5,%ymm6

# qhasm:   abcd4[0,1,2,3] approx= S4[0]-yxtz4[0],S4[1]+yxtz4[1],S4[2]-yxtz4[2],S4[3]+yxtz4[3]
# asm 1: vaddsubpd <yxtz4=reg256#7,<S4=reg256#6,>abcd4=reg256#6
# asm 2: vaddsubpd <yxtz4=%ymm6,<S4=%ymm5,>abcd4=%ymm5
# bytes: 4 uops: 1
vaddsubpd %ymm6,%ymm5,%ymm5
# block pos: 2528 2560 uops: 6

# qhasm:   cdab4[0,1,2,3] = abcd4[2,3],abcd4[0,1]
# asm 1: vperm2f128 $0x21,<abcd4=reg256#6,<abcd4=reg256#6,>cdab4=reg256#7
# asm 2: vperm2f128 $0x21,<abcd4=%ymm5,<abcd4=%ymm5,>cdab4=%ymm6
# bytes: 7 uops: 2
.byte 0x3e
vperm2f128 $0x21,%ymm5,%ymm5,%ymm6

# qhasm:   badc4[0,1,2,3] = abcd4[1,0,3,2]
# asm 1: vpermilpd $0x5,<abcd4=reg256#6,>badc4=reg256#6
# asm 2: vpermilpd $0x5,<abcd4=%ymm5,>badc4=%ymm5
# bytes: 7 uops: 1
.byte 0x3e
vpermilpd $0x5,%ymm5,%ymm5

# qhasm:   B4[0,1,2,3] approx= badc4[0]-cdab4[0],badc4[1]+cdab4[1],badc4[2]-cdab4[2],badc4[3]+cdab4[3]
# asm 1: vaddsubpd <cdab4=reg256#7,<badc4=reg256#6,>B4=reg256#6
# asm 2: vaddsubpd <cdab4=%ymm6,<badc4=%ymm5,>B4=%ymm5
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm6,%ymm5,%ymm5

# qhasm:   yxtz2[0,1,2,3] = S2[1,0,3,2]
# asm 1: vpermilpd $0x5,<S2=reg256#3,>yxtz2=reg256#7
# asm 2: vpermilpd $0x5,<S2=%ymm2,>yxtz2=%ymm6
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm2,%ymm6

# qhasm:   abcd2[0,1,2,3] approx= S2[0]-yxtz2[0],S2[1]+yxtz2[1],S2[2]-yxtz2[2],S2[3]+yxtz2[3]
# asm 1: vaddsubpd <yxtz2=reg256#7,<S2=reg256#3,>abcd2=reg256#3
# asm 2: vaddsubpd <yxtz2=%ymm6,<S2=%ymm2,>abcd2=%ymm2
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm6,%ymm2,%ymm2
# block pos: 2560 2592 uops: 6

# qhasm:   cdab2[0,1,2,3] = abcd2[2,3],abcd2[0,1]
# asm 1: vperm2f128 $0x21,<abcd2=reg256#3,<abcd2=reg256#3,>cdab2=reg256#7
# asm 2: vperm2f128 $0x21,<abcd2=%ymm2,<abcd2=%ymm2,>cdab2=%ymm6
# bytes: 7 uops: 2
.byte 0x3e
vperm2f128 $0x21,%ymm2,%ymm2,%ymm6

# qhasm:   badc2[0,1,2,3] = abcd2[1,0,3,2]
# asm 1: vpermilpd $0x5,<abcd2=reg256#3,>badc2=reg256#3
# asm 2: vpermilpd $0x5,<abcd2=%ymm2,>badc2=%ymm2
# bytes: 7 uops: 1
.byte 0x3e
vpermilpd $0x5,%ymm2,%ymm2

# qhasm:   B2[0,1,2,3] approx= badc2[0]-cdab2[0],badc2[1]+cdab2[1],badc2[2]-cdab2[2],badc2[3]+cdab2[3]
# asm 1: vaddsubpd <cdab2=reg256#7,<badc2=reg256#3,>B2=reg256#3
# asm 2: vaddsubpd <cdab2=%ymm6,<badc2=%ymm2,>B2=%ymm2
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm6,%ymm2,%ymm2

# qhasm:   yxtz0[0,1,2,3] = S0[1,0,3,2]
# asm 1: vpermilpd $0x5,<S0=reg256#5,>yxtz0=reg256#7
# asm 2: vpermilpd $0x5,<S0=%ymm4,>yxtz0=%ymm6
# bytes: 6 uops: 1
vpermilpd $0x5,%ymm4,%ymm6

# qhasm:   abcd0[0,1,2,3] approx= S0[0]-yxtz0[0],S0[1]+yxtz0[1],S0[2]-yxtz0[2],S0[3]+yxtz0[3]
# asm 1: vaddsubpd <yxtz0=reg256#7,<S0=reg256#5,>abcd0=reg256#5
# asm 2: vaddsubpd <yxtz0=%ymm6,<S0=%ymm4,>abcd0=%ymm4
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm6,%ymm4,%ymm4
# block pos: 2592 2624 uops: 6

# qhasm:   cdab0[0,1,2,3] = abcd0[2,3],abcd0[0,1]
# asm 1: vperm2f128 $0x21,<abcd0=reg256#5,<abcd0=reg256#5,>cdab0=reg256#7
# asm 2: vperm2f128 $0x21,<abcd0=%ymm4,<abcd0=%ymm4,>cdab0=%ymm6
# bytes: 7 uops: 2
.byte 0x3e
vperm2f128 $0x21,%ymm4,%ymm4,%ymm6

# qhasm:   badc0[0,1,2,3] = abcd0[1,0,3,2]
# asm 1: vpermilpd $0x5,<abcd0=reg256#5,>badc0=reg256#5
# asm 2: vpermilpd $0x5,<abcd0=%ymm4,>badc0=%ymm4
# bytes: 7 uops: 1
.byte 0x3e
vpermilpd $0x5,%ymm4,%ymm4

# qhasm:   B0[0,1,2,3] approx= badc0[0]-cdab0[0],badc0[1]+cdab0[1],badc0[2]-cdab0[2],badc0[3]+cdab0[3]
# asm 1: vaddsubpd <cdab0=reg256#7,<badc0=reg256#5,>B0=reg256#5
# asm 2: vaddsubpd <cdab0=%ymm6,<badc0=%ymm4,>B0=%ymm4
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddsubpd %ymm6,%ymm4,%ymm4

# qhasm:                             4x 2A5 = approx A5 + A5
# asm 1: vaddpd <A5=reg256#10,<A5=reg256#10,>2A5=reg256#7
# asm 2: vaddpd <A5=%ymm9,<A5=%ymm9,>2A5=%ymm6
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm9,%ymm9,%ymm6

# qhasm:                               4x C5 = approx A0 * 2A5
# asm 1: vmulpd <A0=reg256#2,<2A5=reg256#7,>C5=reg256#7
# asm 2: vmulpd <A0=%ymm1,<2A5=%ymm6,>C5=%ymm6
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm1,%ymm6,%ymm6
# block pos: 2624 2656 uops: 6

# qhasm:                             4x 2A4 = approx A4 + A4
# asm 1: vaddpd <A4=reg256#4,<A4=reg256#4,>2A4=reg256#8
# asm 2: vaddpd <A4=%ymm3,<A4=%ymm3,>2A4=%ymm7
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddpd %ymm3,%ymm3,%ymm7

# qhasm:                               4x 2a1a4 = approx A1 * 2A4
# asm 1: vmulpd <A1=reg256#12,<2A4=reg256#8,>2a1a4=reg256#9
# asm 2: vmulpd <A1=%ymm11,<2A4=%ymm7,>2a1a4=%ymm8
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm11,%ymm7,%ymm8

# qhasm:                               4x C5 approx+= 2a1a4
# asm 1: vaddpd <2a1a4=reg256#9,<C5=reg256#7,>C5=reg256#7
# asm 2: vaddpd <2a1a4=%ymm8,<C5=%ymm6,>C5=%ymm6
# bytes: 5 uops: 1
vaddpd %ymm8,%ymm6,%ymm6

# qhasm:                             4x 2A3 = approx A3 + A3
# asm 1: vaddpd <A3=reg256#11,<A3=reg256#11,>2A3=reg256#9
# asm 2: vaddpd <A3=%ymm10,<A3=%ymm10,>2A3=%ymm8
# bytes: 5 uops: 1
vaddpd %ymm10,%ymm10,%ymm8

# qhasm:                               4x 2a2a3 = approx A2 * 2A3
# asm 1: vmulpd <A2=reg256#1,<2A3=reg256#9,>2a2a3=reg256#13
# asm 2: vmulpd <A2=%ymm0,<2A3=%ymm8,>2a2a3=%ymm12
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm0,%ymm8,%ymm12

# qhasm:                               4x C5 approx+= 2a2a3
# asm 1: vaddpd <2a2a3=reg256#13,<C5=reg256#7,>C5=reg256#7
# asm 2: vaddpd <2a2a3=%ymm12,<C5=%ymm6,>C5=%ymm6
# bytes: 5 uops: 1
vaddpd %ymm12,%ymm6,%ymm6
# block pos: 2656 2688 uops: 6

# qhasm:                             4x 127a5 = approx A5 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#8),<A5=reg256#10,>127a5=reg256#13
# asm 2: vmulpd -128(<const1=%r10),<A5=%ymm9,>127a5=%ymm12
# bytes: 6 uops: 1
vmulpd -128(%r10),%ymm9,%ymm12

# qhasm:                               4x C4 = approx A5 * 127a5
# asm 1: vmulpd <A5=reg256#10,<127a5=reg256#13,>C4=reg256#10
# asm 2: vmulpd <A5=%ymm9,<127a5=%ymm12,>C4=%ymm9
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm9,%ymm12,%ymm9

# qhasm:                               4x 2a0a4 = approx A0 * 2A4
# asm 1: vmulpd <A0=reg256#2,<2A4=reg256#8,>2a0a4=reg256#14
# asm 2: vmulpd <A0=%ymm1,<2A4=%ymm7,>2a0a4=%ymm13
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm1,%ymm7,%ymm13

# qhasm:                               4x C4 approx+= 2a0a4
# asm 1: vaddpd <2a0a4=reg256#14,<C4=reg256#10,>C4=reg256#10
# asm 2: vaddpd <2a0a4=%ymm13,<C4=%ymm9,>C4=%ymm9
# bytes: 5 uops: 1
vaddpd %ymm13,%ymm9,%ymm9

# qhasm:                               4x 2a1a3 = approx A1 * 2A3
# asm 1: vmulpd <A1=reg256#12,<2A3=reg256#9,>2a1a3=reg256#14
# asm 2: vmulpd <A1=%ymm11,<2A3=%ymm8,>2a1a3=%ymm13
# bytes: 5 uops: 1
vmulpd %ymm11,%ymm8,%ymm13

# qhasm:                               4x C4 approx+= 2a1a3
# asm 1: vaddpd <2a1a3=reg256#14,<C4=reg256#10,>C4=reg256#10
# asm 2: vaddpd <2a1a3=%ymm13,<C4=%ymm9,>C4=%ymm9
# bytes: 5 uops: 1
vaddpd %ymm13,%ymm9,%ymm9
# block pos: 2688 2720 uops: 6

# qhasm:                               4x a2a2 = approx A2 * A2
# asm 1: vmulpd <A2=reg256#1,<A2=reg256#1,>a2a2=reg256#14
# asm 2: vmulpd <A2=%ymm0,<A2=%ymm0,>a2a2=%ymm13
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm0,%ymm0,%ymm13

# qhasm:                               4x C4 approx+= a2a2
# asm 1: vaddpd <a2a2=reg256#14,<C4=reg256#10,>C4=reg256#10
# asm 2: vaddpd <a2a2=%ymm13,<C4=%ymm9,>C4=%ymm9
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm13,%ymm9,%ymm9

# qhasm:                             4x 2A2 = approx A2 + A2
# asm 1: vaddpd <A2=reg256#1,<A2=reg256#1,>2A2=reg256#1
# asm 2: vaddpd <A2=%ymm0,<A2=%ymm0,>2A2=%ymm0
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm0,%ymm0,%ymm0

# qhasm:                               4x C3 = approx 2A4 * 127a5
# asm 1: vmulpd <2A4=reg256#8,<127a5=reg256#13,>C3=reg256#8
# asm 2: vmulpd <2A4=%ymm7,<127a5=%ymm12,>C3=%ymm7
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm7,%ymm12,%ymm7

# qhasm:                               4x 2a0a3 = approx A0 * 2A3
# asm 1: vmulpd <A0=reg256#2,<2A3=reg256#9,>2a0a3=reg256#14
# asm 2: vmulpd <A0=%ymm1,<2A3=%ymm8,>2a0a3=%ymm13
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm1,%ymm8,%ymm13

# qhasm:                               4x C3 approx+= 2a0a3
# asm 1: vaddpd <2a0a3=reg256#14,<C3=reg256#8,>C3=reg256#8
# asm 2: vaddpd <2a0a3=%ymm13,<C3=%ymm7,>C3=%ymm7
# bytes: 5 uops: 1
vaddpd %ymm13,%ymm7,%ymm7
# block pos: 2720 2752 uops: 6

# qhasm:                               4x 2a1a2 = approx A1 * 2A2
# asm 1: vmulpd <A1=reg256#12,<2A2=reg256#1,>2a1a2=reg256#14
# asm 2: vmulpd <A1=%ymm11,<2A2=%ymm0,>2a1a2=%ymm13
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm11,%ymm0,%ymm13

# qhasm:                               4x C3 approx+= 2a1a2
# asm 1: vaddpd <2a1a2=reg256#14,<C3=reg256#8,>C3=reg256#8
# asm 2: vaddpd <2a1a2=%ymm13,<C3=%ymm7,>C3=%ymm7
# bytes: 5 uops: 1
vaddpd %ymm13,%ymm7,%ymm7

# qhasm:                             4x 127a4 = approx A4 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#8),<A4=reg256#4,>127a4=reg256#14
# asm 2: vmulpd -128(<const1=%r10),<A4=%ymm3,>127a4=%ymm13
# bytes: 6 uops: 1
vmulpd -128(%r10),%ymm3,%ymm13

# qhasm:                               4x C2 = approx A4 * 127a4
# asm 1: vmulpd <A4=reg256#4,<127a4=reg256#14,>C2=reg256#4
# asm 2: vmulpd <A4=%ymm3,<127a4=%ymm13,>C2=%ymm3
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm3,%ymm13,%ymm3

# qhasm:                               4x 2a3a5 = approx 2A3 * 127a5
# asm 1: vmulpd <2A3=reg256#9,<127a5=reg256#13,>2a3a5=reg256#15
# asm 2: vmulpd <2A3=%ymm8,<127a5=%ymm12,>2a3a5=%ymm14
# bytes: 5 uops: 1
vmulpd %ymm8,%ymm12,%ymm14

# qhasm:                               4x C2 approx+= 2a3a5
# asm 1: vaddpd <2a3a5=reg256#15,<C2=reg256#4,>C2=reg256#4
# asm 2: vaddpd <2a3a5=%ymm14,<C2=%ymm3,>C2=%ymm3
# bytes: 5 uops: 1
vaddpd %ymm14,%ymm3,%ymm3
# block pos: 2752 2784 uops: 6

# qhasm:                               4x 2a0a2 = approx A0 * 2A2
# asm 1: vmulpd <A0=reg256#2,<2A2=reg256#1,>2a0a2=reg256#15
# asm 2: vmulpd <A0=%ymm1,<2A2=%ymm0,>2a0a2=%ymm14
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm1,%ymm0,%ymm14

# qhasm:                               4x C2 approx+= 2a0a2
# asm 1: vaddpd <2a0a2=reg256#15,<C2=reg256#4,>C2=reg256#4
# asm 2: vaddpd <2a0a2=%ymm14,<C2=%ymm3,>C2=%ymm3
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm14,%ymm3,%ymm3

# qhasm:                               4x a1a1 = approx A1 * A1
# asm 1: vmulpd <A1=reg256#12,<A1=reg256#12,>a1a1=reg256#15
# asm 2: vmulpd <A1=%ymm11,<A1=%ymm11,>a1a1=%ymm14
# bytes: 5 uops: 1
vmulpd %ymm11,%ymm11,%ymm14

# qhasm:                               4x C2 approx+= a1a1
# asm 1: vaddpd <a1a1=reg256#15,<C2=reg256#4,>C2=reg256#4
# asm 2: vaddpd <a1a1=%ymm14,<C2=%ymm3,>C2=%ymm3
# bytes: 5 uops: 1
vaddpd %ymm14,%ymm3,%ymm3

# qhasm:                             4x 2A1 = approx A1 + A1
# asm 1: vaddpd <A1=reg256#12,<A1=reg256#12,>2A1=reg256#12
# asm 2: vaddpd <A1=%ymm11,<A1=%ymm11,>2A1=%ymm11
# bytes: 5 uops: 1
vaddpd %ymm11,%ymm11,%ymm11

# qhasm:                               4x C1 = approx 2A3 * 127a4
# asm 1: vmulpd <2A3=reg256#9,<127a4=reg256#14,>C1=reg256#9
# asm 2: vmulpd <2A3=%ymm8,<127a4=%ymm13,>C1=%ymm8
# bytes: 5 uops: 1
vmulpd %ymm8,%ymm13,%ymm8
# block pos: 2784 2816 uops: 6

# qhasm:                               4x 2a2a5 = approx 2A2 * 127a5
# asm 1: vmulpd <2A2=reg256#1,<127a5=reg256#13,>2a2a5=reg256#15
# asm 2: vmulpd <2A2=%ymm0,<127a5=%ymm12,>2a2a5=%ymm14
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm0,%ymm12,%ymm14

# qhasm:                               4x C1 approx+= 2a2a5
# asm 1: vaddpd <2a2a5=reg256#15,<C1=reg256#9,>C1=reg256#9
# asm 2: vaddpd <2a2a5=%ymm14,<C1=%ymm8,>C1=%ymm8
# bytes: 5 uops: 1
vaddpd %ymm14,%ymm8,%ymm8

# qhasm:                               4x 2a0a1 = approx A0 * 2A1
# asm 1: vmulpd <A0=reg256#2,<2A1=reg256#12,>2a0a1=reg256#15
# asm 2: vmulpd <A0=%ymm1,<2A1=%ymm11,>2a0a1=%ymm14
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm1,%ymm11,%ymm14

# qhasm:                               4x C1 approx+= 2a0a1
# asm 1: vaddpd <2a0a1=reg256#15,<C1=reg256#9,>C1=reg256#9
# asm 2: vaddpd <2a0a1=%ymm14,<C1=%ymm8,>C1=%ymm8
# bytes: 5 uops: 1
vaddpd %ymm14,%ymm8,%ymm8

# qhasm:                             4x 127a3 = approx A3 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#8),<A3=reg256#11,>127a3=reg256#15
# asm 2: vmulpd -128(<const1=%r10),<A3=%ymm10,>127a3=%ymm14
# bytes: 6 uops: 1
vmulpd -128(%r10),%ymm10,%ymm14

# qhasm:                               4x C0 = approx A3 * 127a3
# asm 1: vmulpd <A3=reg256#11,<127a3=reg256#15,>C0=reg256#11
# asm 2: vmulpd <A3=%ymm10,<127a3=%ymm14,>C0=%ymm10
# bytes: 5 uops: 1
vmulpd %ymm10,%ymm14,%ymm10
# block pos: 2816 2848 uops: 6

# qhasm:                               4x 2a2a4 = approx 2A2 * 127a4
# asm 1: vmulpd <2A2=reg256#1,<127a4=reg256#14,>2a2a4=reg256#1
# asm 2: vmulpd <2A2=%ymm0,<127a4=%ymm13,>2a2a4=%ymm0
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm0,%ymm13,%ymm0

# qhasm:                               4x C0 approx+= 2a2a4
# asm 1: vaddpd <2a2a4=reg256#1,<C0=reg256#11,>C0=reg256#1
# asm 2: vaddpd <2a2a4=%ymm0,<C0=%ymm10,>C0=%ymm0
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddpd %ymm0,%ymm10,%ymm0

# qhasm:                               4x 2a1a5 = approx 2A1 * 127a5
# asm 1: vmulpd <2A1=reg256#12,<127a5=reg256#13,>2a1a5=reg256#11
# asm 2: vmulpd <2A1=%ymm11,<127a5=%ymm12,>2a1a5=%ymm10
# bytes: 5 uops: 1
vmulpd %ymm11,%ymm12,%ymm10

# qhasm:                               4x C0 approx+= 2a1a5
# asm 1: vaddpd <2a1a5=reg256#11,<C0=reg256#1,>C0=reg256#1
# asm 2: vaddpd <2a1a5=%ymm10,<C0=%ymm0,>C0=%ymm0
# bytes: 5 uops: 1
vaddpd %ymm10,%ymm0,%ymm0

# qhasm:                               4x a0a0 = approx A0 * A0
# asm 1: vmulpd <A0=reg256#2,<A0=reg256#2,>a0a0=reg256#2
# asm 2: vmulpd <A0=%ymm1,<A0=%ymm1,>a0a0=%ymm1
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm1,%ymm1,%ymm1

# qhasm:                               4x C0 approx+= a0a0
# asm 1: vaddpd <a0a0=reg256#2,<C0=reg256#1,>C0=reg256#1
# asm 2: vaddpd <a0a0=%ymm1,<C0=%ymm0,>C0=%ymm0
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm1,%ymm0,%ymm0
# block pos: 2848 2881 uops: 6

# qhasm:                           4x c5 = approx C5 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#8),<C5=reg256#7,>c5=reg256#2
# asm 2: vmulpd -128(<const1=%r10),<C5=%ymm6,>c5=%ymm1
# bytes: 6 uops: 1
vmulpd -128(%r10),%ymm6,%ymm1

# qhasm:                           4x c5 = round(c5)
# asm 1: vroundpd $8,<c5=reg256#2,>c5=reg256#2
# asm 2: vroundpd $8,<c5=%ymm1,>c5=%ymm1
# bytes: 6 uops: 1
vroundpd $8,%ymm1,%ymm1

# qhasm:                           4x c4 = approx C4 * mem256[const1 - 32]
# asm 1: vmulpd -32(<const1=int64#8),<C4=reg256#10,>c4=reg256#11
# asm 2: vmulpd -32(<const1=%r10),<C4=%ymm9,>c4=%ymm10
# bytes: 6 uops: 1
vmulpd -32(%r10),%ymm9,%ymm10

# qhasm:                           4x c4 = round(c4)
# asm 1: vroundpd $8,<c4=reg256#11,>c4=reg256#11
# asm 2: vroundpd $8,<c4=%ymm10,>c4=%ymm10
# bytes: 6 uops: 1
vroundpd $8,%ymm10,%ymm10

# qhasm:                           4x c4 approx*= mem256[const0 + 0]
# asm 1: vmulpd 0(<const0=int64#7),<c4=reg256#11,>c4=reg256#11
# asm 2: vmulpd 0(<const0=%rax),<c4=%ymm10,>c4=%ymm10
# bytes: 4 uops: 1
vmulpd 0(%rax),%ymm10,%ymm10

# qhasm:                           4x C4 approx-= c4
# asm 1: vsubpd <c4=reg256#11,<C4=reg256#10,>C4=reg256#10
# asm 2: vsubpd <c4=%ymm10,<C4=%ymm9,>C4=%ymm9
# bytes: 5 uops: 1
vsubpd %ymm10,%ymm9,%ymm9
# block pos: 2881 2912 uops: 6

# qhasm:                           4x C5 approx+= c4
# asm 1: vaddpd <c4=reg256#11,<C5=reg256#7,>C5=reg256#7
# asm 2: vaddpd <c4=%ymm10,<C5=%ymm6,>C5=%ymm6
# bytes: 5 uops: 1
vaddpd %ymm10,%ymm6,%ymm6

# qhasm:    a106 aligned= mem256[const2 + 0]
# asm 1: vmovapd   0(<const2=int64#9),>a106=reg256#11
# asm 2: vmovapd   0(<const2=%r11),>a106=%ymm10
# bytes: 5 uops: 1
vmovapd   0(%r11),%ymm10

# qhasm:    4x B5 = approx B4 + a106
# asm 1: vaddpd <B4=reg256#6,<a106=reg256#11,>B5=reg256#12
# asm 2: vaddpd <B4=%ymm5,<a106=%ymm10,>B5=%ymm11
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm5,%ymm10,%ymm11

# qhasm:    4x B5 approx-= a106
# asm 1: vsubpd <a106=reg256#11,<B5=reg256#12,>B5=reg256#11
# asm 2: vsubpd <a106=%ymm10,<B5=%ymm11,>B5=%ymm10
# bytes: 5 uops: 1
vsubpd %ymm10,%ymm11,%ymm10

# qhasm:    4x B4 approx-= B5
# asm 1: vsubpd <B5=reg256#11,<B4=reg256#6,>B4=reg256#6
# asm 2: vsubpd <B5=%ymm10,<B4=%ymm5,>B4=%ymm5
# bytes: 5 uops: 1
vsubpd %ymm10,%ymm5,%ymm5

# qhasm:    4x B3 = approx B2 * mem256[const1 - 96]
# asm 1: vmulpd -96(<const1=int64#8),<B2=reg256#3,>B3=reg256#12
# asm 2: vmulpd -96(<const1=%r10),<B2=%ymm2,>B3=%ymm11
# bytes: 6 uops: 1
vmulpd -96(%r10),%ymm2,%ymm11
# block pos: 2912 2945 uops: 6

# qhasm:    4x B3 = round(B3)
# asm 1: vroundpd $8,<B3=reg256#12,>B3=reg256#12
# asm 2: vroundpd $8,<B3=%ymm11,>B3=%ymm11
# bytes: 6 uops: 1
vroundpd $8,%ymm11,%ymm11

# qhasm:    4x B3 approx*= mem256[const0 - 64]
# asm 1: vmulpd -64(<const0=int64#7),<B3=reg256#12,>B3=reg256#12
# asm 2: vmulpd -64(<const0=%rax),<B3=%ymm11,>B3=%ymm11
# bytes: 5 uops: 1
vmulpd -64(%rax),%ymm11,%ymm11

# qhasm:    4x B2 approx-= B3
# asm 1: vsubpd <B3=reg256#12,<B2=reg256#3,>B2=reg256#3
# asm 2: vsubpd <B3=%ymm11,<B2=%ymm2,>B2=%ymm2
# bytes: 5 uops: 1
vsubpd %ymm11,%ymm2,%ymm2

# qhasm:                           4x c3 = approx C3 * mem256[const1 - 64]
# asm 1: vmulpd -64(<const1=int64#8),<C3=reg256#8,>c3=reg256#13
# asm 2: vmulpd -64(<const1=%r10),<C3=%ymm7,>c3=%ymm12
# bytes: 6 uops: 1
vmulpd -64(%r10),%ymm7,%ymm12

# qhasm:                           4x c3 = round(c3)
# asm 1: vroundpd $8,<c3=reg256#13,>c3=reg256#13
# asm 2: vroundpd $8,<c3=%ymm12,>c3=%ymm12
# bytes: 6 uops: 1
vroundpd $8,%ymm12,%ymm12

# qhasm:                           4x c3 approx*= mem256[const0 - 32]
# asm 1: vmulpd -32(<const0=int64#7),<c3=reg256#13,>c3=reg256#13
# asm 2: vmulpd -32(<const0=%rax),<c3=%ymm12,>c3=%ymm12
# bytes: 5 uops: 1
vmulpd -32(%rax),%ymm12,%ymm12
# block pos: 2945 2976 uops: 6

# qhasm:                           4x C4 approx+= c3
# asm 1: vaddpd <c3=reg256#13,<C4=reg256#10,>C4=reg256#10
# asm 2: vaddpd <c3=%ymm12,<C4=%ymm9,>C4=%ymm9
# bytes: 5 uops: 1
vaddpd %ymm12,%ymm9,%ymm9

# qhasm:                           4x C3 approx-= c3
# asm 1: vsubpd <c3=reg256#13,<C3=reg256#8,>C3=reg256#8
# asm 2: vsubpd <c3=%ymm12,<C3=%ymm7,>C3=%ymm7
# bytes: 5 uops: 1
vsubpd %ymm12,%ymm7,%ymm7

# qhasm:    a22 aligned= mem256[const2 - 128]
# asm 1: vmovapd   -128(<const2=int64#9),>a22=reg256#13
# asm 2: vmovapd   -128(<const2=%r11),>a22=%ymm12
# bytes: 6 uops: 1
vmovapd   -128(%r11),%ymm12

# qhasm:    4x B1 = approx B0 + a22
# asm 1: vaddpd <B0=reg256#5,<a22=reg256#13,>B1=reg256#14
# asm 2: vaddpd <B0=%ymm4,<a22=%ymm12,>B1=%ymm13
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm4,%ymm12,%ymm13

# qhasm:    4x B1 approx-= a22
# asm 1: vsubpd <a22=reg256#13,<B1=reg256#14,>B1=reg256#13
# asm 2: vsubpd <a22=%ymm12,<B1=%ymm13,>B1=%ymm12
# bytes: 5 uops: 1
vsubpd %ymm12,%ymm13,%ymm12

# qhasm:    4x B0 approx-= B1
# asm 1: vsubpd <B1=reg256#13,<B0=reg256#5,>B0=reg256#5
# asm 2: vsubpd <B1=%ymm12,<B0=%ymm4,>B0=%ymm4
# bytes: 5 uops: 1
vsubpd %ymm12,%ymm4,%ymm4
# block pos: 2976 3008 uops: 6

# qhasm:                           mem256[work2 +   0] aligned= C4
# asm 1: vmovapd   <C4=reg256#10,0(<work2=int64#6)
# asm 2: vmovapd   <C4=%ymm9,0(<work2=%r9)
# bytes: 5 uops: 1
vmovapd   %ymm9,0(%r9)

# qhasm:                           4x c2 = approx C2 * mem256[const1 - 96]
# asm 1: vmulpd -96(<const1=int64#8),<C2=reg256#4,>c2=reg256#10
# asm 2: vmulpd -96(<const1=%r10),<C2=%ymm3,>c2=%ymm9
# bytes: 6 uops: 1
vmulpd -96(%r10),%ymm3,%ymm9

# qhasm:                           4x c2 = round(c2)
# asm 1: vroundpd $8,<c2=reg256#10,>c2=reg256#10
# asm 2: vroundpd $8,<c2=%ymm9,>c2=%ymm9
# bytes: 6 uops: 1
vroundpd $8,%ymm9,%ymm9

# qhasm:                           4x c2 approx*= mem256[const0 - 64]
# asm 1: vmulpd -64(<const0=int64#7),<c2=reg256#10,>c2=reg256#10
# asm 2: vmulpd -64(<const0=%rax),<c2=%ymm9,>c2=%ymm9
# bytes: 5 uops: 1
vmulpd -64(%rax),%ymm9,%ymm9

# qhasm:                           4x C3 approx+= c2
# asm 1: vaddpd <c2=reg256#10,<C3=reg256#8,>C3=reg256#8
# asm 2: vaddpd <c2=%ymm9,<C3=%ymm7,>C3=%ymm7
# bytes: 5 uops: 1
vaddpd %ymm9,%ymm7,%ymm7

# qhasm:                           4x C2 approx-= c2
# asm 1: vsubpd <c2=reg256#10,<C2=reg256#4,>C2=reg256#4
# asm 2: vsubpd <c2=%ymm9,<C2=%ymm3,>C2=%ymm3
# bytes: 5 uops: 1
vsubpd %ymm9,%ymm3,%ymm3
# block pos: 3008 3040 uops: 6

# qhasm:                           4x c1 = approx C1 * mem256[const0 + 96]
# asm 1: vmulpd 96(<const0=int64#7),<C1=reg256#9,>c1=reg256#10
# asm 2: vmulpd 96(<const0=%rax),<C1=%ymm8,>c1=%ymm9
# bytes: 5 uops: 1
vmulpd 96(%rax),%ymm8,%ymm9

# qhasm:                           4x c1 = round(c1)
# asm 1: vroundpd $8,<c1=reg256#10,>c1=reg256#10
# asm 2: vroundpd $8,<c1=%ymm9,>c1=%ymm9
# bytes: 6 uops: 1
vroundpd $8,%ymm9,%ymm9

# qhasm:                           4x c1 approx*= mem256[const0 - 96]
# asm 1: vmulpd -96(<const0=int64#7),<c1=reg256#10,>c1=reg256#10
# asm 2: vmulpd -96(<const0=%rax),<c1=%ymm9,>c1=%ymm9
# bytes: 5 uops: 1
vmulpd -96(%rax),%ymm9,%ymm9

# qhasm:                           4x C2 approx+= c1
# asm 1: vaddpd <c1=reg256#10,<C2=reg256#4,>C2=reg256#4
# asm 2: vaddpd <c1=%ymm9,<C2=%ymm3,>C2=%ymm3
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm9,%ymm3,%ymm3

# qhasm:                           4x C1 approx-= c1
# asm 1: vsubpd <c1=reg256#10,<C1=reg256#9,>C1=reg256#9
# asm 2: vsubpd <c1=%ymm9,<C1=%ymm8,>C1=%ymm8
# bytes: 5 uops: 1
vsubpd %ymm9,%ymm8,%ymm8

# qhasm:                           4x c0 = approx C0 * mem256[const0 + 64]
# asm 1: vmulpd 64(<const0=int64#7),<C0=reg256#1,>c0=reg256#10
# asm 2: vmulpd 64(<const0=%rax),<C0=%ymm0,>c0=%ymm9
# bytes: 5 uops: 1
vmulpd 64(%rax),%ymm0,%ymm9
# block pos: 3040 3072 uops: 6

# qhasm:                           4x C0 approx+= c5
# asm 1: vaddpd <c5=reg256#2,<C0=reg256#1,>C0=reg256#1
# asm 2: vaddpd <c5=%ymm1,<C0=%ymm0,>C0=%ymm0
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddpd %ymm1,%ymm0,%ymm0

# qhasm:                           4x c5 approx*= mem256[const0 + 32]
# asm 1: vmulpd 32(<const0=int64#7),<c5=reg256#2,>c5=reg256#2
# asm 2: vmulpd 32(<const0=%rax),<c5=%ymm1,>c5=%ymm1
# bytes: 5 uops: 1
vmulpd 32(%rax),%ymm1,%ymm1

# qhasm:                           4x C5 approx-= c5
# asm 1: vsubpd <c5=reg256#2,<C5=reg256#7,>C5=reg256#2
# asm 2: vsubpd <c5=%ymm1,<C5=%ymm6,>C5=%ymm1
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm1,%ymm6,%ymm1

# qhasm:                           4x c0 = round(c0)
# asm 1: vroundpd $8,<c0=reg256#10,>c0=reg256#7
# asm 2: vroundpd $8,<c0=%ymm9,>c0=%ymm6
# bytes: 6 uops: 1
vroundpd $8,%ymm9,%ymm6

# qhasm:                           4x c0 approx*= mem256[const0 - 128]
# asm 1: vmulpd -128(<const0=int64#7),<c0=reg256#7,>c0=reg256#7
# asm 2: vmulpd -128(<const0=%rax),<c0=%ymm6,>c0=%ymm6
# bytes: 5 uops: 1
vmulpd -128(%rax),%ymm6,%ymm6

# qhasm:                           4x C1 approx+= c0
# asm 1: vaddpd <c0=reg256#7,<C1=reg256#9,>C1=reg256#9
# asm 2: vaddpd <c0=%ymm6,<C1=%ymm8,>C1=%ymm8
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm6,%ymm8,%ymm8
# block pos: 3072 3104 uops: 6

# qhasm:                           4x C0 approx-= c0
# asm 1: vsubpd <c0=reg256#7,<C0=reg256#1,>C0=reg256#1
# asm 2: vsubpd <c0=%ymm6,<C0=%ymm0,>C0=%ymm0
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vsubpd %ymm6,%ymm0,%ymm0

# qhasm:                           mem256[work2 +  32] aligned= C5
# asm 1: vmovapd   <C5=reg256#2,32(<work2=int64#6)
# asm 2: vmovapd   <C5=%ymm1,32(<work2=%r9)
# bytes: 6 uops: 1
vmovapd   %ymm1,32(%r9)

# qhasm:     two aligned= mem256[const1 + 0]
# asm 1: vmovapd   0(<const1=int64#8),>two=reg256#2
# asm 2: vmovapd   0(<const1=%r10),>two=%ymm1
# bytes: 5 uops: 1
vmovapd   0(%r10),%ymm1

# qhasm:     4x 2B5 = approx B5 * two
# asm 1: vmulpd <B5=reg256#11,<two=reg256#2,>2B5=reg256#7
# asm 2: vmulpd <B5=%ymm10,<two=%ymm1,>2B5=%ymm6
# bytes: 5 uops: 1
vmulpd %ymm10,%ymm1,%ymm6

# qhasm:     4x 2B4 = approx B4 + B4
# asm 1: vaddpd <B4=reg256#6,<B4=reg256#6,>2B4=reg256#10
# asm 2: vaddpd <B4=%ymm5,<B4=%ymm5,>2B4=%ymm9
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm5,%ymm5,%ymm9

# qhasm:     4x 2B3 = approx B3 * two
# asm 1: vmulpd <B3=reg256#12,<two=reg256#2,>2B3=reg256#2
# asm 2: vmulpd <B3=%ymm11,<two=%ymm1,>2B3=%ymm1
# bytes: 5 uops: 1
vmulpd %ymm11,%ymm1,%ymm1
# block pos: 3104 3136 uops: 6

# qhasm:       4x D5 = approx B0 * 2B5
# asm 1: vmulpd <B0=reg256#5,<2B5=reg256#7,>D5=reg256#7
# asm 2: vmulpd <B0=%ymm4,<2B5=%ymm6,>D5=%ymm6
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm4,%ymm6,%ymm6

# qhasm:       4x 2B1B4 = approx B1 * 2B4
# asm 1: vmulpd <B1=reg256#13,<2B4=reg256#10,>2B1B4=reg256#14
# asm 2: vmulpd <B1=%ymm12,<2B4=%ymm9,>2B1B4=%ymm13
# bytes: 5 uops: 1
vmulpd %ymm12,%ymm9,%ymm13

# qhasm:       4x D5 approx+= 2B1B4
# asm 1: vaddpd <2B1B4=reg256#14,<D5=reg256#7,>D5=reg256#7
# asm 2: vaddpd <2B1B4=%ymm13,<D5=%ymm6,>D5=%ymm6
# bytes: 5 uops: 1
vaddpd %ymm13,%ymm6,%ymm6

# qhasm:       4x 2B2B3 = approx B2 * 2B3
# asm 1: vmulpd <B2=reg256#3,<2B3=reg256#2,>2B2B3=reg256#14
# asm 2: vmulpd <B2=%ymm2,<2B3=%ymm1,>2B2B3=%ymm13
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm2,%ymm1,%ymm13

# qhasm:       4x D5 approx+= 2B2B3
# asm 1: vaddpd <2B2B3=reg256#14,<D5=reg256#7,>D5=reg256#7
# asm 2: vaddpd <2B2B3=%ymm13,<D5=%ymm6,>D5=%ymm6
# bytes: 5 uops: 1
vaddpd %ymm13,%ymm6,%ymm6

# qhasm:     4x 127B5 = approx B5 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#8),<B5=reg256#11,>127B5=reg256#14
# asm 2: vmulpd -128(<const1=%r10),<B5=%ymm10,>127B5=%ymm13
# bytes: 6 uops: 1
vmulpd -128(%r10),%ymm10,%ymm13
# block pos: 3136 3168 uops: 6

# qhasm:       4x D4 = approx B5 * 127B5
# asm 1: vmulpd <B5=reg256#11,<127B5=reg256#14,>D4=reg256#11
# asm 2: vmulpd <B5=%ymm10,<127B5=%ymm13,>D4=%ymm10
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm10,%ymm13,%ymm10

# qhasm:       4x 2B0B4 = approx B0 * 2B4
# asm 1: vmulpd <B0=reg256#5,<2B4=reg256#10,>2B0B4=reg256#15
# asm 2: vmulpd <B0=%ymm4,<2B4=%ymm9,>2B0B4=%ymm14
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm4,%ymm9,%ymm14

# qhasm:       4x D4 approx+= 2B0B4
# asm 1: vaddpd <2B0B4=reg256#15,<D4=reg256#11,>D4=reg256#11
# asm 2: vaddpd <2B0B4=%ymm14,<D4=%ymm10,>D4=%ymm10
# bytes: 5 uops: 1
vaddpd %ymm14,%ymm10,%ymm10

# qhasm:       4x 2B1B3 = approx B1 * 2B3
# asm 1: vmulpd <B1=reg256#13,<2B3=reg256#2,>2B1B3=reg256#15
# asm 2: vmulpd <B1=%ymm12,<2B3=%ymm1,>2B1B3=%ymm14
# bytes: 5 uops: 1
vmulpd %ymm12,%ymm1,%ymm14

# qhasm:       4x D4 approx+= 2B1B3
# asm 1: vaddpd <2B1B3=reg256#15,<D4=reg256#11,>D4=reg256#11
# asm 2: vaddpd <2B1B3=%ymm14,<D4=%ymm10,>D4=%ymm10
# bytes: 5 uops: 1
vaddpd %ymm14,%ymm10,%ymm10

# qhasm:       4x B2B2 = approx B2 * B2
# asm 1: vmulpd <B2=reg256#3,<B2=reg256#3,>B2B2=reg256#15
# asm 2: vmulpd <B2=%ymm2,<B2=%ymm2,>B2B2=%ymm14
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm2,%ymm2,%ymm14
# block pos: 3168 3200 uops: 6

# qhasm:       4x D4 approx+= B2B2
# asm 1: vaddpd <B2B2=reg256#15,<D4=reg256#11,>D4=reg256#11
# asm 2: vaddpd <B2B2=%ymm14,<D4=%ymm10,>D4=%ymm10
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm14,%ymm10,%ymm10

# qhasm:     4x 2B2 = approx B2 + B2
# asm 1: vaddpd <B2=reg256#3,<B2=reg256#3,>2B2=reg256#3
# asm 2: vaddpd <B2=%ymm2,<B2=%ymm2,>2B2=%ymm2
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddpd %ymm2,%ymm2,%ymm2

# qhasm:       4x D3 = approx 2B4 * 127B5
# asm 1: vmulpd <2B4=reg256#10,<127B5=reg256#14,>D3=reg256#10
# asm 2: vmulpd <2B4=%ymm9,<127B5=%ymm13,>D3=%ymm9
# bytes: 5 uops: 1
vmulpd %ymm9,%ymm13,%ymm9

# qhasm:       4x 2B0B3 = approx B0 * 2B3
# asm 1: vmulpd <B0=reg256#5,<2B3=reg256#2,>2B0B3=reg256#15
# asm 2: vmulpd <B0=%ymm4,<2B3=%ymm1,>2B0B3=%ymm14
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm4,%ymm1,%ymm14

# qhasm:       4x D3 approx+= 2B0B3
# asm 1: vaddpd <2B0B3=reg256#15,<D3=reg256#10,>D3=reg256#10
# asm 2: vaddpd <2B0B3=%ymm14,<D3=%ymm9,>D3=%ymm9
# bytes: 5 uops: 1
vaddpd %ymm14,%ymm9,%ymm9

# qhasm:       4x 2B1B2 = approx B1 * 2B2
# asm 1: vmulpd <B1=reg256#13,<2B2=reg256#3,>2B1B2=reg256#15
# asm 2: vmulpd <B1=%ymm12,<2B2=%ymm2,>2B1B2=%ymm14
# bytes: 5 uops: 1
vmulpd %ymm12,%ymm2,%ymm14
# block pos: 3200 3232 uops: 6

# qhasm:       4x D3 approx+= 2B1B2
# asm 1: vaddpd <2B1B2=reg256#15,<D3=reg256#10,>D3=reg256#10
# asm 2: vaddpd <2B1B2=%ymm14,<D3=%ymm9,>D3=%ymm9
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm14,%ymm9,%ymm9

# qhasm:     4x 127B4 = approx B4 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#8),<B4=reg256#6,>127B4=reg256#15
# asm 2: vmulpd -128(<const1=%r10),<B4=%ymm5,>127B4=%ymm14
# bytes: 6 uops: 1
vmulpd -128(%r10),%ymm5,%ymm14

# qhasm:       4x D2 = approx B4 * 127B4
# asm 1: vmulpd <B4=reg256#6,<127B4=reg256#15,>D2=reg256#6
# asm 2: vmulpd <B4=%ymm5,<127B4=%ymm14,>D2=%ymm5
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm5,%ymm14,%ymm5

# qhasm:       4x 2B3B5 = approx 2B3 * 127B5
# asm 1: vmulpd <2B3=reg256#2,<127B5=reg256#14,>2B3B5=reg256#16
# asm 2: vmulpd <2B3=%ymm1,<127B5=%ymm13,>2B3B5=%ymm15
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm1,%ymm13,%ymm15

# qhasm:       4x D2 approx+= 2B3B5
# asm 1: vaddpd <2B3B5=reg256#16,<D2=reg256#6,>D2=reg256#6
# asm 2: vaddpd <2B3B5=%ymm15,<D2=%ymm5,>D2=%ymm5
# bytes: 5 uops: 1
vaddpd %ymm15,%ymm5,%ymm5

# qhasm:       4x 2B0B2 = approx B0 * 2B2
# asm 1: vmulpd <B0=reg256#5,<2B2=reg256#3,>2B0B2=reg256#16
# asm 2: vmulpd <B0=%ymm4,<2B2=%ymm2,>2B0B2=%ymm15
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm4,%ymm2,%ymm15
# block pos: 3232 3264 uops: 6

# qhasm:       4x D2 approx+= 2B0B2
# asm 1: vaddpd <2B0B2=reg256#16,<D2=reg256#6,>D2=reg256#6
# asm 2: vaddpd <2B0B2=%ymm15,<D2=%ymm5,>D2=%ymm5
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm15,%ymm5,%ymm5

# qhasm:       4x B1B1 = approx B1 * B1
# asm 1: vmulpd <B1=reg256#13,<B1=reg256#13,>B1B1=reg256#16
# asm 2: vmulpd <B1=%ymm12,<B1=%ymm12,>B1B1=%ymm15
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm12,%ymm12,%ymm15

# qhasm:       4x D2 approx+= B1B1
# asm 1: vaddpd <B1B1=reg256#16,<D2=reg256#6,>D2=reg256#6
# asm 2: vaddpd <B1B1=%ymm15,<D2=%ymm5,>D2=%ymm5
# bytes: 5 uops: 1
vaddpd %ymm15,%ymm5,%ymm5

# qhasm:     4x 2B1 = approx B1 + B1
# asm 1: vaddpd <B1=reg256#13,<B1=reg256#13,>2B1=reg256#13
# asm 2: vaddpd <B1=%ymm12,<B1=%ymm12,>2B1=%ymm12
# bytes: 5 uops: 1
vaddpd %ymm12,%ymm12,%ymm12

# qhasm:       4x D1 = approx 2B3 * 127B4
# asm 1: vmulpd <2B3=reg256#2,<127B4=reg256#15,>D1=reg256#2
# asm 2: vmulpd <2B3=%ymm1,<127B4=%ymm14,>D1=%ymm1
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm1,%ymm14,%ymm1

# qhasm:       4x 2B2B5 = approx 2B2 * 127B5
# asm 1: vmulpd <2B2=reg256#3,<127B5=reg256#14,>2B2B5=reg256#16
# asm 2: vmulpd <2B2=%ymm2,<127B5=%ymm13,>2B2B5=%ymm15
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm2,%ymm13,%ymm15
# block pos: 3264 3296 uops: 6

# qhasm:       4x D1 approx+= 2B2B5
# asm 1: vaddpd <2B2B5=reg256#16,<D1=reg256#2,>D1=reg256#2
# asm 2: vaddpd <2B2B5=%ymm15,<D1=%ymm1,>D1=%ymm1
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm15,%ymm1,%ymm1

# qhasm:       4x 2B0B1 = approx B0 * 2B1
# asm 1: vmulpd <B0=reg256#5,<2B1=reg256#13,>2B0B1=reg256#16
# asm 2: vmulpd <B0=%ymm4,<2B1=%ymm12,>2B0B1=%ymm15
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm4,%ymm12,%ymm15

# qhasm:       4x D1 approx+= 2B0B1
# asm 1: vaddpd <2B0B1=reg256#16,<D1=reg256#2,>D1=reg256#2
# asm 2: vaddpd <2B0B1=%ymm15,<D1=%ymm1,>D1=%ymm1
# bytes: 5 uops: 1
vaddpd %ymm15,%ymm1,%ymm1

# qhasm:     4x 127B3 = approx B3 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#8),<B3=reg256#12,>127B3=reg256#16
# asm 2: vmulpd -128(<const1=%r10),<B3=%ymm11,>127B3=%ymm15
# bytes: 6 uops: 1
vmulpd -128(%r10),%ymm11,%ymm15

# qhasm:       4x D0 = approx B3 * 127B3
# asm 1: vmulpd <B3=reg256#12,<127B3=reg256#16,>D0=reg256#12
# asm 2: vmulpd <B3=%ymm11,<127B3=%ymm15,>D0=%ymm11
# bytes: 5 uops: 1
vmulpd %ymm11,%ymm15,%ymm11

# qhasm:       4x 2B2B4 = approx 2B2 * 127B4
# asm 1: vmulpd <2B2=reg256#3,<127B4=reg256#15,>2B2B4=reg256#3
# asm 2: vmulpd <2B2=%ymm2,<127B4=%ymm14,>2B2B4=%ymm2
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm2,%ymm14,%ymm2
# block pos: 3296 3328 uops: 6

# qhasm:       4x D0 approx+= 2B2B4
# asm 1: vaddpd <2B2B4=reg256#3,<D0=reg256#12,>D0=reg256#3
# asm 2: vaddpd <2B2B4=%ymm2,<D0=%ymm11,>D0=%ymm2
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddpd %ymm2,%ymm11,%ymm2

# qhasm:       4x 2B1B5 = approx 2B1 * 127B5
# asm 1: vmulpd <2B1=reg256#13,<127B5=reg256#14,>2B1B5=reg256#12
# asm 2: vmulpd <2B1=%ymm12,<127B5=%ymm13,>2B1B5=%ymm11
# bytes: 5 uops: 1
vmulpd %ymm12,%ymm13,%ymm11

# qhasm:       4x D0 approx+= 2B1B5
# asm 1: vaddpd <2B1B5=reg256#12,<D0=reg256#3,>D0=reg256#3
# asm 2: vaddpd <2B1B5=%ymm11,<D0=%ymm2,>D0=%ymm2
# bytes: 5 uops: 1
vaddpd %ymm11,%ymm2,%ymm2

# qhasm:       4x B0B0 = approx B0 * B0
# asm 1: vmulpd <B0=reg256#5,<B0=reg256#5,>B0B0=reg256#5
# asm 2: vmulpd <B0=%ymm4,<B0=%ymm4,>B0B0=%ymm4
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm4,%ymm4,%ymm4

# qhasm:       4x D0 approx+= B0B0
# asm 1: vaddpd <B0B0=reg256#5,<D0=reg256#3,>D0=reg256#3
# asm 2: vaddpd <B0B0=%ymm4,<D0=%ymm2,>D0=%ymm2
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm4,%ymm2,%ymm2

# qhasm:   4x c5 = approx D5 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#8),<D5=reg256#7,>c5=reg256#5
# asm 2: vmulpd -128(<const1=%r10),<D5=%ymm6,>c5=%ymm4
# bytes: 6 uops: 1
vmulpd -128(%r10),%ymm6,%ymm4
# block pos: 3328 3362 uops: 6

# qhasm:   4x c4 = approx D4 * mem256[const1 - 32]
# asm 1: vmulpd -32(<const1=int64#8),<D4=reg256#11,>c4=reg256#12
# asm 2: vmulpd -32(<const1=%r10),<D4=%ymm10,>c4=%ymm11
# bytes: 6 uops: 1
vmulpd -32(%r10),%ymm10,%ymm11

# qhasm:   4x c3 = approx D3 * mem256[const1 - 64]
# asm 1: vmulpd -64(<const1=int64#8),<D3=reg256#10,>c3=reg256#13
# asm 2: vmulpd -64(<const1=%r10),<D3=%ymm9,>c3=%ymm12
# bytes: 6 uops: 1
vmulpd -64(%r10),%ymm9,%ymm12

# qhasm:   4x c2 = approx D2 * mem256[const1 - 96]
# asm 1: vmulpd -96(<const1=int64#8),<D2=reg256#6,>c2=reg256#14
# asm 2: vmulpd -96(<const1=%r10),<D2=%ymm5,>c2=%ymm13
# bytes: 6 uops: 1
vmulpd -96(%r10),%ymm5,%ymm13

# qhasm:   4x c1 = approx D1 * mem256[const0 + 96]
# asm 1: vmulpd 96(<const0=int64#7),<D1=reg256#2,>c1=reg256#15
# asm 2: vmulpd 96(<const0=%rax),<D1=%ymm1,>c1=%ymm14
# bytes: 5 uops: 1
vmulpd 96(%rax),%ymm1,%ymm14

# qhasm:   4x c0 = approx D0 * mem256[const0 + 64]
# asm 1: vmulpd 64(<const0=int64#7),<D0=reg256#3,>c0=reg256#16
# asm 2: vmulpd 64(<const0=%rax),<D0=%ymm2,>c0=%ymm15
# bytes: 5 uops: 1
vmulpd 64(%rax),%ymm2,%ymm15

# qhasm:   4x c5 = round(c5)
# asm 1: vroundpd $8,<c5=reg256#5,>c5=reg256#5
# asm 2: vroundpd $8,<c5=%ymm4,>c5=%ymm4
# bytes: 6 uops: 1
vroundpd $8,%ymm4,%ymm4
# block pos: 3362 3392 uops: 5

# qhasm:   4x c4 = round(c4)
# asm 1: vroundpd $8,<c4=reg256#12,>c4=reg256#12
# asm 2: vroundpd $8,<c4=%ymm11,>c4=%ymm11
# bytes: 6 uops: 1
vroundpd $8,%ymm11,%ymm11

# qhasm:   4x c3 = round(c3)
# asm 1: vroundpd $8,<c3=reg256#13,>c3=reg256#13
# asm 2: vroundpd $8,<c3=%ymm12,>c3=%ymm12
# bytes: 6 uops: 1
vroundpd $8,%ymm12,%ymm12

# qhasm:   4x c2 = round(c2)
# asm 1: vroundpd $8,<c2=reg256#14,>c2=reg256#14
# asm 2: vroundpd $8,<c2=%ymm13,>c2=%ymm13
# bytes: 6 uops: 1
vroundpd $8,%ymm13,%ymm13

# qhasm:   4x c1 = round(c1)
# asm 1: vroundpd $8,<c1=reg256#15,>c1=reg256#15
# asm 2: vroundpd $8,<c1=%ymm14,>c1=%ymm14
# bytes: 6 uops: 1
vroundpd $8,%ymm14,%ymm14

# qhasm:   4x c0 = round(c0)
# asm 1: vroundpd $8,<c0=reg256#16,>c0=reg256#16
# asm 2: vroundpd $8,<c0=%ymm15,>c0=%ymm15
# bytes: 6 uops: 1
vroundpd $8,%ymm15,%ymm15
# block pos: 3392 3424 uops: 6

# qhasm:   4x D0 approx+= c5
# asm 1: vaddpd <c5=reg256#5,<D0=reg256#3,>D0=reg256#3
# asm 2: vaddpd <c5=%ymm4,<D0=%ymm2,>D0=%ymm2
# bytes: 8 uops: 1
.byte 0x3e
.byte 0x3e
.byte 0x3e
.byte 0x3e
vaddpd %ymm4,%ymm2,%ymm2

# qhasm:   4x c4 approx*= mem256[const0 + 0]
# asm 1: vmulpd 0(<const0=int64#7),<c4=reg256#12,>c4=reg256#12
# asm 2: vmulpd 0(<const0=%rax),<c4=%ymm11,>c4=%ymm11
# bytes: 4 uops: 1
vmulpd 0(%rax),%ymm11,%ymm11

# qhasm:   4x c3 approx*= mem256[const0 - 32]
# asm 1: vmulpd -32(<const0=int64#7),<c3=reg256#13,>c3=reg256#13
# asm 2: vmulpd -32(<const0=%rax),<c3=%ymm12,>c3=%ymm12
# bytes: 5 uops: 1
vmulpd -32(%rax),%ymm12,%ymm12

# qhasm:   4x c2 approx*= mem256[const0 - 64]
# asm 1: vmulpd -64(<const0=int64#7),<c2=reg256#14,>c2=reg256#14
# asm 2: vmulpd -64(<const0=%rax),<c2=%ymm13,>c2=%ymm13
# bytes: 5 uops: 1
vmulpd -64(%rax),%ymm13,%ymm13

# qhasm:   4x c1 approx*= mem256[const0 - 96]
# asm 1: vmulpd -96(<const0=int64#7),<c1=reg256#15,>c1=reg256#15
# asm 2: vmulpd -96(<const0=%rax),<c1=%ymm14,>c1=%ymm14
# bytes: 5 uops: 1
vmulpd -96(%rax),%ymm14,%ymm14

# qhasm:   4x c0 approx*= mem256[const0 - 128]
# asm 1: vmulpd -128(<const0=int64#7),<c0=reg256#16,>c0=reg256#16
# asm 2: vmulpd -128(<const0=%rax),<c0=%ymm15,>c0=%ymm15
# bytes: 5 uops: 1
vmulpd -128(%rax),%ymm15,%ymm15
# block pos: 3424 3456 uops: 6

# qhasm:   4x c5 approx*= mem256[const0 + 32]
# asm 1: vmulpd 32(<const0=int64#7),<c5=reg256#5,>c5=reg256#5
# asm 2: vmulpd 32(<const0=%rax),<c5=%ymm4,>c5=%ymm4
# bytes: 5 uops: 1
vmulpd 32(%rax),%ymm4,%ymm4

# qhasm:   4x D5 approx+= c4
# asm 1: vaddpd <c4=reg256#12,<D5=reg256#7,>D5=reg256#7
# asm 2: vaddpd <c4=%ymm11,<D5=%ymm6,>D5=%ymm6
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm11,%ymm6,%ymm6

# qhasm:   4x D4 approx+= c3
# asm 1: vaddpd <c3=reg256#13,<D4=reg256#11,>D4=reg256#11
# asm 2: vaddpd <c3=%ymm12,<D4=%ymm10,>D4=%ymm10
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm12,%ymm10,%ymm10

# qhasm:   4x D3 approx+= c2
# asm 1: vaddpd <c2=reg256#14,<D3=reg256#10,>D3=reg256#10
# asm 2: vaddpd <c2=%ymm13,<D3=%ymm9,>D3=%ymm9
# bytes: 5 uops: 1
vaddpd %ymm13,%ymm9,%ymm9

# qhasm:   4x D2 approx+= c1
# asm 1: vaddpd <c1=reg256#15,<D2=reg256#6,>D2=reg256#6
# asm 2: vaddpd <c1=%ymm14,<D2=%ymm5,>D2=%ymm5
# bytes: 5 uops: 1
vaddpd %ymm14,%ymm5,%ymm5

# qhasm:   4x D1 approx+= c0
# asm 1: vaddpd <c0=reg256#16,<D1=reg256#2,>D1=reg256#2
# asm 2: vaddpd <c0=%ymm15,<D1=%ymm1,>D1=%ymm1
# bytes: 5 uops: 1
vaddpd %ymm15,%ymm1,%ymm1
# block pos: 3456 3488 uops: 6

# qhasm:   4x D5 approx-= c5
# asm 1: vsubpd <c5=reg256#5,<D5=reg256#7,>D5=reg256#5
# asm 2: vsubpd <c5=%ymm4,<D5=%ymm6,>D5=%ymm4
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm4,%ymm6,%ymm4

# qhasm:   4x D4 approx-= c4
# asm 1: vsubpd <c4=reg256#12,<D4=reg256#11,>D4=reg256#7
# asm 2: vsubpd <c4=%ymm11,<D4=%ymm10,>D4=%ymm6
# bytes: 5 uops: 1
vsubpd %ymm11,%ymm10,%ymm6

# qhasm:   4x D3 approx-= c3
# asm 1: vsubpd <c3=reg256#13,<D3=reg256#10,>D3=reg256#10
# asm 2: vsubpd <c3=%ymm12,<D3=%ymm9,>D3=%ymm9
# bytes: 5 uops: 1
vsubpd %ymm12,%ymm9,%ymm9

# qhasm:     mem256[work1 - 32] aligned= D3
# asm 1: vmovapd   <D3=reg256#10,-32(<work1=int64#5)
# asm 2: vmovapd   <D3=%ymm9,-32(<work1=%r8)
# bytes: 6 uops: 1
vmovapd   %ymm9,-32(%r8)

# qhasm:   4x D2 approx-= c2
# asm 1: vsubpd <c2=reg256#14,<D2=reg256#6,>D2=reg256#6
# asm 2: vsubpd <c2=%ymm13,<D2=%ymm5,>D2=%ymm5
# bytes: 5 uops: 1
vsubpd %ymm13,%ymm5,%ymm5

# qhasm:     mem256[work1 - 64] aligned= D2
# asm 1: vmovapd   <D2=reg256#6,-64(<work1=int64#5)
# asm 2: vmovapd   <D2=%ymm5,-64(<work1=%r8)
# bytes: 6 uops: 1
vmovapd   %ymm5,-64(%r8)
# block pos: 3488 3521 uops: 6

# qhasm:   4x D1 approx-= c1
# asm 1: vsubpd <c1=reg256#15,<D1=reg256#2,>D1=reg256#2
# asm 2: vsubpd <c1=%ymm14,<D1=%ymm1,>D1=%ymm1
# bytes: 5 uops: 1
vsubpd %ymm14,%ymm1,%ymm1

# qhasm:     mem256[work1 - 96] aligned= D1
# asm 1: vmovapd   <D1=reg256#2,-96(<work1=int64#5)
# asm 2: vmovapd   <D1=%ymm1,-96(<work1=%r8)
# bytes: 6 uops: 1
vmovapd   %ymm1,-96(%r8)

# qhasm:   4x D0 approx-= c0
# asm 1: vsubpd <c0=reg256#16,<D0=reg256#3,>D0=reg256#2
# asm 2: vsubpd <c0=%ymm15,<D0=%ymm2,>D0=%ymm1
# bytes: 5 uops: 1
vsubpd %ymm15,%ymm2,%ymm1

# qhasm:     mem256[work1 - 128] aligned= D0
# asm 1: vmovapd   <D0=reg256#2,-128(<work1=int64#5)
# asm 2: vmovapd   <D0=%ymm1,-128(<work1=%r8)
# bytes: 6 uops: 1
vmovapd   %ymm1,-128(%r8)

# qhasm:                           a0 aligned= mem256[work0 - 128]
# asm 1: vmovapd   -128(<work0=int64#3),>a0=reg256#2
# asm 2: vmovapd   -128(<work0=%rdx),>a0=%ymm1
# bytes: 5 uops: 1
vmovapd   -128(%rdx),%ymm1

# qhasm:                           C5 aligned= mem256[work2 +  32]
# asm 1: vmovapd   32(<work2=int64#6),>C5=reg256#3
# asm 2: vmovapd   32(<work2=%r9),>C5=%ymm2
# bytes: 6 uops: 1
vmovapd   32(%r9),%ymm2
# block pos: 3521 3552 uops: 6

# qhasm:                           C4 aligned= mem256[work2 +   0]
# asm 1: vmovapd   0(<work2=int64#6),>C4=reg256#6
# asm 2: vmovapd   0(<work2=%r9),>C4=%ymm5
# bytes: 5 uops: 1
vmovapd   0(%r9),%ymm5

# qhasm:                           4x E5 = approx a0 * C5
# asm 1: vmulpd <a0=reg256#2,<C5=reg256#3,>E5=reg256#10
# asm 2: vmulpd <a0=%ymm1,<C5=%ymm2,>E5=%ymm9
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm1,%ymm2,%ymm9

# qhasm:                             4x E4 = approx a0 * C4
# asm 1: vmulpd <a0=reg256#2,<C4=reg256#6,>E4=reg256#11
# asm 2: vmulpd <a0=%ymm1,<C4=%ymm5,>E4=%ymm10
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm1,%ymm5,%ymm10

# qhasm:                               4x E3 = approx a0 * C3
# asm 1: vmulpd <a0=reg256#2,<C3=reg256#8,>E3=reg256#12
# asm 2: vmulpd <a0=%ymm1,<C3=%ymm7,>E3=%ymm11
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm1,%ymm7,%ymm11

# qhasm:                           a1 aligned= mem256[work0 - 96]
# asm 1: vmovapd   -96(<work0=int64#3),>a1=reg256#13
# asm 2: vmovapd   -96(<work0=%rdx),>a1=%ymm12
# bytes: 5 uops: 1
vmovapd   -96(%rdx),%ymm12

# qhasm:                           4x a1b4 = approx a1 * C4
# asm 1: vmulpd <a1=reg256#13,<C4=reg256#6,>a1b4=reg256#14
# asm 2: vmulpd <a1=%ymm12,<C4=%ymm5,>a1b4=%ymm13
# bytes: 5 uops: 1
vmulpd %ymm12,%ymm5,%ymm13
# block pos: 3552 3584 uops: 6

# qhasm:                           4x E5 approx+= a1b4
# asm 1: vaddpd <a1b4=reg256#14,<E5=reg256#10,>E5=reg256#10
# asm 2: vaddpd <a1b4=%ymm13,<E5=%ymm9,>E5=%ymm9
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm13,%ymm9,%ymm9

# qhasm:                             4x a1b3 = approx a1 * C3
# asm 1: vmulpd <a1=reg256#13,<C3=reg256#8,>a1b3=reg256#14
# asm 2: vmulpd <a1=%ymm12,<C3=%ymm7,>a1b3=%ymm13
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm12,%ymm7,%ymm13

# qhasm:                             4x E4 approx+= a1b3
# asm 1: vaddpd <a1b3=reg256#14,<E4=reg256#11,>E4=reg256#11
# asm 2: vaddpd <a1b3=%ymm13,<E4=%ymm10,>E4=%ymm10
# bytes: 5 uops: 1
vaddpd %ymm13,%ymm10,%ymm10

# qhasm:                               4x a1b2 = approx a1 * C2
# asm 1: vmulpd <a1=reg256#13,<C2=reg256#4,>a1b2=reg256#14
# asm 2: vmulpd <a1=%ymm12,<C2=%ymm3,>a1b2=%ymm13
# bytes: 5 uops: 1
vmulpd %ymm12,%ymm3,%ymm13

# qhasm:                               4x E3 approx+= a1b2
# asm 1: vaddpd <a1b2=reg256#14,<E3=reg256#12,>E3=reg256#12
# asm 2: vaddpd <a1b2=%ymm13,<E3=%ymm11,>E3=%ymm11
# bytes: 5 uops: 1
vaddpd %ymm13,%ymm11,%ymm11

# qhasm:                                 4x E2 = approx a0 * C2
# asm 1: vmulpd <a0=reg256#2,<C2=reg256#4,>E2=reg256#14
# asm 2: vmulpd <a0=%ymm1,<C2=%ymm3,>E2=%ymm13
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm1,%ymm3,%ymm13
# block pos: 3584 3616 uops: 6

# qhasm:                                   4x E1 = approx a0 * C1
# asm 1: vmulpd <a0=reg256#2,<C1=reg256#9,>E1=reg256#15
# asm 2: vmulpd <a0=%ymm1,<C1=%ymm8,>E1=%ymm14
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm1,%ymm8,%ymm14

# qhasm:                                     4x E0 = approx a0 * C0
# asm 1: vmulpd <a0=reg256#2,<C0=reg256#1,>E0=reg256#2
# asm 2: vmulpd <a0=%ymm1,<C0=%ymm0,>E0=%ymm1
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vmulpd %ymm1,%ymm0,%ymm1

# qhasm:                                 4x a1b1 = approx a1 * C1
# asm 1: vmulpd <a1=reg256#13,<C1=reg256#9,>a1b1=reg256#16
# asm 2: vmulpd <a1=%ymm12,<C1=%ymm8,>a1b1=%ymm15
# bytes: 5 uops: 1
vmulpd %ymm12,%ymm8,%ymm15

# qhasm:                                 4x E2 approx+= a1b1
# asm 1: vaddpd <a1b1=reg256#16,<E2=reg256#14,>E2=reg256#14
# asm 2: vaddpd <a1b1=%ymm15,<E2=%ymm13,>E2=%ymm13
# bytes: 5 uops: 1
vaddpd %ymm15,%ymm13,%ymm13

# qhasm:                                   4x a1b0 = approx a1 * C0
# asm 1: vmulpd <a1=reg256#13,<C0=reg256#1,>a1b0=reg256#13
# asm 2: vmulpd <a1=%ymm12,<C0=%ymm0,>a1b0=%ymm12
# bytes: 5 uops: 1
vmulpd %ymm12,%ymm0,%ymm12

# qhasm: 			          4x E1 approx+= a1b0
# asm 1: vaddpd <a1b0=reg256#13,<E1=reg256#15,>E1=reg256#13
# asm 2: vaddpd <a1b0=%ymm12,<E1=%ymm14,>E1=%ymm12
# bytes: 5 uops: 1
vaddpd %ymm12,%ymm14,%ymm12
# block pos: 3616 3648 uops: 6

# qhasm:                                     127a1 aligned= mem256[work3 + 0]
# asm 1: vmovapd   0(<work3=int64#1),>127a1=reg256#15
# asm 2: vmovapd   0(<work3=%rdi),>127a1=%ymm14
# bytes: 4 uops: 1
vmovapd   0(%rdi),%ymm14

# qhasm:                                     4x a1b5 = approx 127a1 * C5
# asm 1: vmulpd <127a1=reg256#15,<C5=reg256#3,>a1b5=reg256#15
# asm 2: vmulpd <127a1=%ymm14,<C5=%ymm2,>a1b5=%ymm14
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm14,%ymm2,%ymm14

# qhasm:                                     4x E0 approx+= a1b5
# asm 1: vaddpd <a1b5=reg256#15,<E0=reg256#2,>E0=reg256#2
# asm 2: vaddpd <a1b5=%ymm14,<E0=%ymm1,>E0=%ymm1
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm14,%ymm1,%ymm1

# qhasm:                           a2 aligned= mem256[work0 - 64]
# asm 1: vmovapd   -64(<work0=int64#3),>a2=reg256#15
# asm 2: vmovapd   -64(<work0=%rdx),>a2=%ymm14
# bytes: 5 uops: 1
vmovapd   -64(%rdx),%ymm14

# qhasm:                           4x a2b3 = approx a2 * C3
# asm 1: vmulpd <a2=reg256#15,<C3=reg256#8,>a2b3=reg256#16
# asm 2: vmulpd <a2=%ymm14,<C3=%ymm7,>a2b3=%ymm15
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm14,%ymm7,%ymm15

# qhasm:                           4x E5 approx+= a2b3
# asm 1: vaddpd <a2b3=reg256#16,<E5=reg256#10,>E5=reg256#10
# asm 2: vaddpd <a2b3=%ymm15,<E5=%ymm9,>E5=%ymm9
# bytes: 5 uops: 1
vaddpd %ymm15,%ymm9,%ymm9
# block pos: 3648 3680 uops: 6

# qhasm:                             4x a2b2 = approx a2 * C2
# asm 1: vmulpd <a2=reg256#15,<C2=reg256#4,>a2b2=reg256#16
# asm 2: vmulpd <a2=%ymm14,<C2=%ymm3,>a2b2=%ymm15
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm14,%ymm3,%ymm15

# qhasm:                             4x E4 approx+= a2b2
# asm 1: vaddpd <a2b2=reg256#16,<E4=reg256#11,>E4=reg256#11
# asm 2: vaddpd <a2b2=%ymm15,<E4=%ymm10,>E4=%ymm10
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm15,%ymm10,%ymm10

# qhasm:                               4x a2b1 = approx a2 * C1
# asm 1: vmulpd <a2=reg256#15,<C1=reg256#9,>a2b1=reg256#16
# asm 2: vmulpd <a2=%ymm14,<C1=%ymm8,>a2b1=%ymm15
# bytes: 5 uops: 1
vmulpd %ymm14,%ymm8,%ymm15

# qhasm:                               4x E3 approx+= a2b1
# asm 1: vaddpd <a2b1=reg256#16,<E3=reg256#12,>E3=reg256#12
# asm 2: vaddpd <a2b1=%ymm15,<E3=%ymm11,>E3=%ymm11
# bytes: 5 uops: 1
vaddpd %ymm15,%ymm11,%ymm11

# qhasm:                                 4x a2b0 = approx a2 * C0
# asm 1: vmulpd <a2=reg256#15,<C0=reg256#1,>a2b0=reg256#15
# asm 2: vmulpd <a2=%ymm14,<C0=%ymm0,>a2b0=%ymm14
# bytes: 5 uops: 1
vmulpd %ymm14,%ymm0,%ymm14

# qhasm: 			        4x E2 approx+= a2b0
# asm 1: vaddpd <a2b0=reg256#15,<E2=reg256#14,>E2=reg256#14
# asm 2: vaddpd <a2b0=%ymm14,<E2=%ymm13,>E2=%ymm13
# bytes: 5 uops: 1
vaddpd %ymm14,%ymm13,%ymm13
# block pos: 3680 3712 uops: 6

# qhasm:                           a3 aligned= mem256[work0 - 32]
# asm 1: vmovapd   -32(<work0=int64#3),>a3=reg256#15
# asm 2: vmovapd   -32(<work0=%rdx),>a3=%ymm14
# bytes: 5 uops: 1
vmovapd   -32(%rdx),%ymm14

# qhasm:                           4x a3b2 = approx a3 * C2
# asm 1: vmulpd <a3=reg256#15,<C2=reg256#4,>a3b2=reg256#16
# asm 2: vmulpd <a3=%ymm14,<C2=%ymm3,>a3b2=%ymm15
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm14,%ymm3,%ymm15

# qhasm:                           4x E5 approx+= a3b2
# asm 1: vaddpd <a3b2=reg256#16,<E5=reg256#10,>E5=reg256#10
# asm 2: vaddpd <a3b2=%ymm15,<E5=%ymm9,>E5=%ymm9
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm15,%ymm9,%ymm9

# qhasm:                             4x a3b1 = approx a3 * C1
# asm 1: vmulpd <a3=reg256#15,<C1=reg256#9,>a3b1=reg256#16
# asm 2: vmulpd <a3=%ymm14,<C1=%ymm8,>a3b1=%ymm15
# bytes: 5 uops: 1
vmulpd %ymm14,%ymm8,%ymm15

# qhasm:                             4x E4 approx+= a3b1
# asm 1: vaddpd <a3b1=reg256#16,<E4=reg256#11,>E4=reg256#11
# asm 2: vaddpd <a3b1=%ymm15,<E4=%ymm10,>E4=%ymm10
# bytes: 5 uops: 1
vaddpd %ymm15,%ymm10,%ymm10

# qhasm:                               4x a3b0 = approx a3 * C0
# asm 1: vmulpd <a3=reg256#15,<C0=reg256#1,>a3b0=reg256#15
# asm 2: vmulpd <a3=%ymm14,<C0=%ymm0,>a3b0=%ymm14
# bytes: 5 uops: 1
vmulpd %ymm14,%ymm0,%ymm14
# block pos: 3712 3744 uops: 6

# qhasm: 			      4x E3 approx+= a3b0
# asm 1: vaddpd <a3b0=reg256#15,<E3=reg256#12,>E3=reg256#12
# asm 2: vaddpd <a3b0=%ymm14,<E3=%ymm11,>E3=%ymm11
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm14,%ymm11,%ymm11

# qhasm:                                   127a2 aligned= mem256[work3 - 32]
# asm 1: vmovapd   -32(<work3=int64#1),>127a2=reg256#15
# asm 2: vmovapd   -32(<work3=%rdi),>127a2=%ymm14
# bytes: 5 uops: 1
vmovapd   -32(%rdi),%ymm14

# qhasm:                                   4x a2b5 = approx 127a2 * C5
# asm 1: vmulpd <127a2=reg256#15,<C5=reg256#3,>a2b5=reg256#16
# asm 2: vmulpd <127a2=%ymm14,<C5=%ymm2,>a2b5=%ymm15
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm14,%ymm2,%ymm15

# qhasm:                                   4x E1 approx+= a2b5
# asm 1: vaddpd <a2b5=reg256#16,<E1=reg256#13,>E1=reg256#13
# asm 2: vaddpd <a2b5=%ymm15,<E1=%ymm12,>E1=%ymm12
# bytes: 5 uops: 1
vaddpd %ymm15,%ymm12,%ymm12

# qhasm:                                     4x a2b4 = approx 127a2 * C4
# asm 1: vmulpd <127a2=reg256#15,<C4=reg256#6,>a2b4=reg256#15
# asm 2: vmulpd <127a2=%ymm14,<C4=%ymm5,>a2b4=%ymm14
# bytes: 5 uops: 1
vmulpd %ymm14,%ymm5,%ymm14

# qhasm:                                     4x E0 approx+= a2b4
# asm 1: vaddpd <a2b4=reg256#15,<E0=reg256#2,>E0=reg256#2
# asm 2: vaddpd <a2b4=%ymm14,<E0=%ymm1,>E0=%ymm1
# bytes: 5 uops: 1
vaddpd %ymm14,%ymm1,%ymm1
# block pos: 3744 3776 uops: 6

# qhasm:                                 127a3 aligned= mem256[work3 - 64]
# asm 1: vmovapd   -64(<work3=int64#1),>127a3=reg256#15
# asm 2: vmovapd   -64(<work3=%rdi),>127a3=%ymm14
# bytes: 5 uops: 1
vmovapd   -64(%rdi),%ymm14

# qhasm:                                 4x a3b5 = approx 127a3 * C5
# asm 1: vmulpd <127a3=reg256#15,<C5=reg256#3,>a3b5=reg256#16
# asm 2: vmulpd <127a3=%ymm14,<C5=%ymm2,>a3b5=%ymm15
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm14,%ymm2,%ymm15

# qhasm:                                 4x E2 approx+= a3b5
# asm 1: vaddpd <a3b5=reg256#16,<E2=reg256#14,>E2=reg256#14
# asm 2: vaddpd <a3b5=%ymm15,<E2=%ymm13,>E2=%ymm13
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm15,%ymm13,%ymm13

# qhasm:                                   4x a3b4 = approx 127a3 * C4
# asm 1: vmulpd <127a3=reg256#15,<C4=reg256#6,>a3b4=reg256#16
# asm 2: vmulpd <127a3=%ymm14,<C4=%ymm5,>a3b4=%ymm15
# bytes: 5 uops: 1
vmulpd %ymm14,%ymm5,%ymm15

# qhasm:                                   4x E1 approx+= a3b4
# asm 1: vaddpd <a3b4=reg256#16,<E1=reg256#13,>E1=reg256#13
# asm 2: vaddpd <a3b4=%ymm15,<E1=%ymm12,>E1=%ymm12
# bytes: 5 uops: 1
vaddpd %ymm15,%ymm12,%ymm12

# qhasm:                                     4x a3b3 = approx 127a3 * C3
# asm 1: vmulpd <127a3=reg256#15,<C3=reg256#8,>a3b3=reg256#15
# asm 2: vmulpd <127a3=%ymm14,<C3=%ymm7,>a3b3=%ymm14
# bytes: 5 uops: 1
vmulpd %ymm14,%ymm7,%ymm14
# block pos: 3776 3808 uops: 6

# qhasm:                                     4x E0 approx+= a3b3
# asm 1: vaddpd <a3b3=reg256#15,<E0=reg256#2,>E0=reg256#2
# asm 2: vaddpd <a3b3=%ymm14,<E0=%ymm1,>E0=%ymm1
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm14,%ymm1,%ymm1

# qhasm:                           a4 aligned= mem256[work0 + 0]
# asm 1: vmovapd   0(<work0=int64#3),>a4=reg256#15
# asm 2: vmovapd   0(<work0=%rdx),>a4=%ymm14
# bytes: 4 uops: 1
vmovapd   0(%rdx),%ymm14

# qhasm:                           4x a4b1 = approx a4 * C1
# asm 1: vmulpd <a4=reg256#15,<C1=reg256#9,>a4b1=reg256#16
# asm 2: vmulpd <a4=%ymm14,<C1=%ymm8,>a4b1=%ymm15
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm14,%ymm8,%ymm15

# qhasm:                           4x E5 approx+= a4b1
# asm 1: vaddpd <a4b1=reg256#16,<E5=reg256#10,>E5=reg256#10
# asm 2: vaddpd <a4b1=%ymm15,<E5=%ymm9,>E5=%ymm9
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm15,%ymm9,%ymm9

# qhasm:                             4x a4b0 = approx a4 * C0
# asm 1: vmulpd <a4=reg256#15,<C0=reg256#1,>a4b0=reg256#15
# asm 2: vmulpd <a4=%ymm14,<C0=%ymm0,>a4b0=%ymm14
# bytes: 5 uops: 1
vmulpd %ymm14,%ymm0,%ymm14

# qhasm: 			    4x E4 approx+= a4b0
# asm 1: vaddpd <a4b0=reg256#15,<E4=reg256#11,>E4=reg256#11
# asm 2: vaddpd <a4b0=%ymm14,<E4=%ymm10,>E4=%ymm10
# bytes: 5 uops: 1
vaddpd %ymm14,%ymm10,%ymm10
# block pos: 3808 3840 uops: 6

# qhasm:                               127a4 aligned= mem256[work3 - 96]
# asm 1: vmovapd   -96(<work3=int64#1),>127a4=reg256#15
# asm 2: vmovapd   -96(<work3=%rdi),>127a4=%ymm14
# bytes: 5 uops: 1
vmovapd   -96(%rdi),%ymm14

# qhasm:                               4x a4b5 = approx 127a4 * C5
# asm 1: vmulpd <127a4=reg256#15,<C5=reg256#3,>a4b5=reg256#16
# asm 2: vmulpd <127a4=%ymm14,<C5=%ymm2,>a4b5=%ymm15
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm14,%ymm2,%ymm15

# qhasm:                               4x E3 approx+= a4b5
# asm 1: vaddpd <a4b5=reg256#16,<E3=reg256#12,>E3=reg256#12
# asm 2: vaddpd <a4b5=%ymm15,<E3=%ymm11,>E3=%ymm11
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm15,%ymm11,%ymm11

# qhasm:                                 4x a4b4 = approx 127a4 * C4
# asm 1: vmulpd <127a4=reg256#15,<C4=reg256#6,>a4b4=reg256#16
# asm 2: vmulpd <127a4=%ymm14,<C4=%ymm5,>a4b4=%ymm15
# bytes: 5 uops: 1
vmulpd %ymm14,%ymm5,%ymm15

# qhasm:                                 4x E2 approx+= a4b4
# asm 1: vaddpd <a4b4=reg256#16,<E2=reg256#14,>E2=reg256#14
# asm 2: vaddpd <a4b4=%ymm15,<E2=%ymm13,>E2=%ymm13
# bytes: 5 uops: 1
vaddpd %ymm15,%ymm13,%ymm13

# qhasm:                                   4x a4b3 = approx 127a4 * C3
# asm 1: vmulpd <127a4=reg256#15,<C3=reg256#8,>a4b3=reg256#16
# asm 2: vmulpd <127a4=%ymm14,<C3=%ymm7,>a4b3=%ymm15
# bytes: 5 uops: 1
vmulpd %ymm14,%ymm7,%ymm15
# block pos: 3840 3872 uops: 6

# qhasm:                                   4x E1 approx+= a4b3
# asm 1: vaddpd <a4b3=reg256#16,<E1=reg256#13,>E1=reg256#13
# asm 2: vaddpd <a4b3=%ymm15,<E1=%ymm12,>E1=%ymm12
# bytes: 6 uops: 1
.byte 0x3e
vaddpd %ymm15,%ymm12,%ymm12

# qhasm:                                     4x a4b2 = approx 127a4 * C2
# asm 1: vmulpd <127a4=reg256#15,<C2=reg256#4,>a4b2=reg256#15
# asm 2: vmulpd <127a4=%ymm14,<C2=%ymm3,>a4b2=%ymm14
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm14,%ymm3,%ymm14

# qhasm:                                     4x E0 approx+= a4b2
# asm 1: vaddpd <a4b2=reg256#15,<E0=reg256#2,>E0=reg256#2
# asm 2: vaddpd <a4b2=%ymm14,<E0=%ymm1,>E0=%ymm1
# bytes: 5 uops: 1
vaddpd %ymm14,%ymm1,%ymm1

# qhasm:                           a5 aligned= mem256[work0 + 32]
# asm 1: vmovapd   32(<work0=int64#3),>a5=reg256#15
# asm 2: vmovapd   32(<work0=%rdx),>a5=%ymm14
# bytes: 5 uops: 1
vmovapd   32(%rdx),%ymm14

# qhasm:                           4x a5b0 = approx a5 * C0
# asm 1: vmulpd <a5=reg256#15,<C0=reg256#1,>a5b0=reg256#1
# asm 2: vmulpd <a5=%ymm14,<C0=%ymm0,>a5b0=%ymm0
# bytes: 5 uops: 1
vmulpd %ymm14,%ymm0,%ymm0

# qhasm: 			  4x E5 approx+= a5b0
# asm 1: vaddpd <a5b0=reg256#1,<E5=reg256#10,>E5=reg256#1
# asm 2: vaddpd <a5b0=%ymm0,<E5=%ymm9,>E5=%ymm0
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm0,%ymm9,%ymm0
# block pos: 3872 3904 uops: 6

# qhasm:                             127a5 aligned= mem256[work3 - 128]
# asm 1: vmovapd   -128(<work3=int64#1),>127a5=reg256#10
# asm 2: vmovapd   -128(<work3=%rdi),>127a5=%ymm9
# bytes: 5 uops: 1
vmovapd   -128(%rdi),%ymm9

# qhasm:                             4x a5b5 = approx 127a5 * C5
# asm 1: vmulpd <127a5=reg256#10,<C5=reg256#3,>a5b5=reg256#3
# asm 2: vmulpd <127a5=%ymm9,<C5=%ymm2,>a5b5=%ymm2
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm9,%ymm2,%ymm2

# qhasm:                             4x E4 approx+= a5b5
# asm 1: vaddpd <a5b5=reg256#3,<E4=reg256#11,>E4=reg256#3
# asm 2: vaddpd <a5b5=%ymm2,<E4=%ymm10,>E4=%ymm2
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddpd %ymm2,%ymm10,%ymm2

# qhasm:                               4x a5b4 = approx 127a5 * C4
# asm 1: vmulpd <127a5=reg256#10,<C4=reg256#6,>a5b4=reg256#6
# asm 2: vmulpd <127a5=%ymm9,<C4=%ymm5,>a5b4=%ymm5
# bytes: 5 uops: 1
vmulpd %ymm9,%ymm5,%ymm5

# qhasm:                               4x E3 approx+= a5b4
# asm 1: vaddpd <a5b4=reg256#6,<E3=reg256#12,>E3=reg256#6
# asm 2: vaddpd <a5b4=%ymm5,<E3=%ymm11,>E3=%ymm5
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm5,%ymm11,%ymm5

# qhasm:                                 4x a5b3 = approx 127a5 * C3
# asm 1: vmulpd <127a5=reg256#10,<C3=reg256#8,>a5b3=reg256#8
# asm 2: vmulpd <127a5=%ymm9,<C3=%ymm7,>a5b3=%ymm7
# bytes: 5 uops: 1
vmulpd %ymm9,%ymm7,%ymm7
# block pos: 3904 3936 uops: 6

# qhasm:                                 4x E2 approx+= a5b3
# asm 1: vaddpd <a5b3=reg256#8,<E2=reg256#14,>E2=reg256#8
# asm 2: vaddpd <a5b3=%ymm7,<E2=%ymm13,>E2=%ymm7
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddpd %ymm7,%ymm13,%ymm7

# qhasm:                                   4x a5b2 = approx 127a5 * C2
# asm 1: vmulpd <127a5=reg256#10,<C2=reg256#4,>a5b2=reg256#4
# asm 2: vmulpd <127a5=%ymm9,<C2=%ymm3,>a5b2=%ymm3
# bytes: 6 uops: 1
.byte 0x3e
vmulpd %ymm9,%ymm3,%ymm3

# qhasm:                                   4x E1 approx+= a5b2
# asm 1: vaddpd <a5b2=reg256#4,<E1=reg256#13,>E1=reg256#4
# asm 2: vaddpd <a5b2=%ymm3,<E1=%ymm12,>E1=%ymm3
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm3,%ymm12,%ymm3

# qhasm:                                     4x a5b1 = approx 127a5 * C1
# asm 1: vmulpd <127a5=reg256#10,<C1=reg256#9,>a5b1=reg256#9
# asm 2: vmulpd <127a5=%ymm9,<C1=%ymm8,>a5b1=%ymm8
# bytes: 5 uops: 1
vmulpd %ymm9,%ymm8,%ymm8

# qhasm:                                     4x E0 approx+= a5b1
# asm 1: vaddpd <a5b1=reg256#9,<E0=reg256#2,>E0=reg256#2
# asm 2: vaddpd <a5b1=%ymm8,<E0=%ymm1,>E0=%ymm1
# bytes: 5 uops: 1
vaddpd %ymm8,%ymm1,%ymm1

# qhasm:                                             a106 aligned= mem256[const2 + 0]
# asm 1: vmovapd   0(<const2=int64#9),>a106=reg256#9
# asm 2: vmovapd   0(<const2=%r11),>a106=%ymm8
# bytes: 5 uops: 1
vmovapd   0(%r11),%ymm8
# block pos: 3936 3968 uops: 6

# qhasm:                                             4x c4 = approx E4 + a106
# asm 1: vaddpd <E4=reg256#3,<a106=reg256#9,>c4=reg256#10
# asm 2: vaddpd <E4=%ymm2,<a106=%ymm8,>c4=%ymm9
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddpd %ymm2,%ymm8,%ymm9

# qhasm:                                             4x c4 approx-= a106
# asm 1: vsubpd <a106=reg256#9,<c4=reg256#10,>c4=reg256#9
# asm 2: vsubpd <a106=%ymm8,<c4=%ymm9,>c4=%ymm8
# bytes: 5 uops: 1
vsubpd %ymm8,%ymm9,%ymm8

# qhasm:                                             4x E5 approx+= c4
# asm 1: vaddpd <c4=reg256#9,<E5=reg256#1,>E5=reg256#1
# asm 2: vaddpd <c4=%ymm8,<E5=%ymm0,>E5=%ymm0
# bytes: 5 uops: 1
vaddpd %ymm8,%ymm0,%ymm0

# qhasm:                                             4x E4 approx-= c4
# asm 1: vsubpd <c4=reg256#9,<E4=reg256#3,>E4=reg256#3
# asm 2: vsubpd <c4=%ymm8,<E4=%ymm2,>E4=%ymm2
# bytes: 5 uops: 1
vsubpd %ymm8,%ymm2,%ymm2

# qhasm:                                             a64 aligned= mem256[const2 - 64]
# asm 1: vmovapd   -64(<const2=int64#9),>a64=reg256#9
# asm 2: vmovapd   -64(<const2=%r11),>a64=%ymm8
# bytes: 6 uops: 1
vmovapd   -64(%r11),%ymm8

# qhasm:                                             4x c2 = approx E2 + a64
# asm 1: vaddpd <E2=reg256#8,<a64=reg256#9,>c2=reg256#10
# asm 2: vaddpd <E2=%ymm7,<a64=%ymm8,>c2=%ymm9
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm7,%ymm8,%ymm9
# block pos: 3968 4000 uops: 6

# qhasm:                                             4x c2 approx-= a64
# asm 1: vsubpd <a64=reg256#9,<c2=reg256#10,>c2=reg256#9
# asm 2: vsubpd <a64=%ymm8,<c2=%ymm9,>c2=%ymm8
# bytes: 6 uops: 1
.byte 0x3e
vsubpd %ymm8,%ymm9,%ymm8

# qhasm:                                             4x E3 approx+= c2
# asm 1: vaddpd <c2=reg256#9,<E3=reg256#6,>E3=reg256#6
# asm 2: vaddpd <c2=%ymm8,<E3=%ymm5,>E3=%ymm5
# bytes: 5 uops: 1
vaddpd %ymm8,%ymm5,%ymm5

# qhasm: 					    a22 aligned= mem256[const2 - 128]
# asm 1: vmovapd   -128(<const2=int64#9),>a22=reg256#10
# asm 2: vmovapd   -128(<const2=%r11),>a22=%ymm9
# bytes: 6 uops: 1
vmovapd   -128(%r11),%ymm9

# qhasm:                                             4x c0 = approx E0 + a22
# asm 1: vaddpd <E0=reg256#2,<a22=reg256#10,>c0=reg256#11
# asm 2: vaddpd <E0=%ymm1,<a22=%ymm9,>c0=%ymm10
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm1,%ymm9,%ymm10

# qhasm:                                             4x c0 approx-= a22
# asm 1: vsubpd <a22=reg256#10,<c0=reg256#11,>c0=reg256#10
# asm 2: vsubpd <a22=%ymm9,<c0=%ymm10,>c0=%ymm9
# bytes: 5 uops: 1
vsubpd %ymm9,%ymm10,%ymm9

# qhasm:                                             4x E1 approx+= c0
# asm 1: vaddpd <c0=reg256#10,<E1=reg256#4,>E1=reg256#4
# asm 2: vaddpd <c0=%ymm9,<E1=%ymm3,>E1=%ymm3
# bytes: 5 uops: 1
vaddpd %ymm9,%ymm3,%ymm3
# block pos: 4000 4032 uops: 6

# qhasm:                                             4x E2 approx-= c2
# asm 1: vsubpd <c2=reg256#9,<E2=reg256#8,>E2=reg256#8
# asm 2: vsubpd <c2=%ymm8,<E2=%ymm7,>E2=%ymm7
# bytes: 5 uops: 1
vsubpd %ymm8,%ymm7,%ymm7

# qhasm:                                             4x E0 approx-= c0
# asm 1: vsubpd <c0=reg256#10,<E0=reg256#2,>E0=reg256#2
# asm 2: vsubpd <c0=%ymm9,<E0=%ymm1,>E0=%ymm1
# bytes: 5 uops: 1
vsubpd %ymm9,%ymm1,%ymm1

# qhasm:   ABCD aligned= mem256[const2 + 64]
# asm 1: vmovapd   64(<const2=int64#9),>ABCD=reg256#9
# asm 2: vmovapd   64(<const2=%r11),>ABCD=%ymm8
# bytes: 6 uops: 1
vmovapd   64(%r11),%ymm8

# qhasm:   4x F5 = approx D5 * ABCD
# asm 1: vmulpd <D5=reg256#5,<ABCD=reg256#9,>F5=reg256#5
# asm 2: vmulpd <D5=%ymm4,<ABCD=%ymm8,>F5=%ymm4
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm4,%ymm8,%ymm4

# qhasm:   4x F4 = approx D4 * ABCD
# asm 1: vmulpd <D4=reg256#7,<ABCD=reg256#9,>F4=reg256#7
# asm 2: vmulpd <D4=%ymm6,<ABCD=%ymm8,>F4=%ymm6
# bytes: 5 uops: 1
.byte 0x3e
vmulpd %ymm6,%ymm8,%ymm6

# qhasm:   4x F3 = approx ABCD * mem256[work1 - 32]
# asm 1: vmulpd -32(<work1=int64#5),<ABCD=reg256#9,>F3=reg256#10
# asm 2: vmulpd -32(<work1=%r8),<ABCD=%ymm8,>F3=%ymm9
# bytes: 6 uops: 1
vmulpd -32(%r8),%ymm8,%ymm9
# block pos: 4032 4065 uops: 6

# qhasm:   4x F2 = approx ABCD * mem256[work1 - 64]
# asm 1: vmulpd -64(<work1=int64#5),<ABCD=reg256#9,>F2=reg256#11
# asm 2: vmulpd -64(<work1=%r8),<ABCD=%ymm8,>F2=%ymm10
# bytes: 6 uops: 1
vmulpd -64(%r8),%ymm8,%ymm10

# qhasm:   4x F1 = approx ABCD * mem256[work1 - 96]
# asm 1: vmulpd -96(<work1=int64#5),<ABCD=reg256#9,>F1=reg256#12
# asm 2: vmulpd -96(<work1=%r8),<ABCD=%ymm8,>F1=%ymm11
# bytes: 6 uops: 1
vmulpd -96(%r8),%ymm8,%ymm11

# qhasm:   4x F0 = approx ABCD * mem256[work1 - 128]
# asm 1: vmulpd -128(<work1=int64#5),<ABCD=reg256#9,>F0=reg256#9
# asm 2: vmulpd -128(<work1=%r8),<ABCD=%ymm8,>F0=%ymm8
# bytes: 6 uops: 1
vmulpd -128(%r8),%ymm8,%ymm8

# qhasm:                                           a85 aligned= mem256[const2 - 32]
# asm 1: vmovapd   -32(<const2=int64#9),>a85=reg256#13
# asm 2: vmovapd   -32(<const2=%r11),>a85=%ymm12
# bytes: 6 uops: 1
vmovapd   -32(%r11),%ymm12

# qhasm:                                           4x c3 = approx E3 + a85
# asm 1: vaddpd <E3=reg256#6,<a85=reg256#13,>c3=reg256#14
# asm 2: vaddpd <E3=%ymm5,<a85=%ymm12,>c3=%ymm13
# bytes: 4 uops: 1
vaddpd %ymm5,%ymm12,%ymm13

# qhasm:                                           4x c3 approx-= a85
# asm 1: vsubpd <a85=reg256#13,<c3=reg256#14,>c3=reg256#13
# asm 2: vsubpd <a85=%ymm12,<c3=%ymm13,>c3=%ymm12
# bytes: 5 uops: 1
vsubpd %ymm12,%ymm13,%ymm12
# block pos: 4065 4097 uops: 6

# qhasm:                                           4x E4 approx+= c3
# asm 1: vaddpd <c3=reg256#13,<E4=reg256#3,>E4=reg256#3
# asm 2: vaddpd <c3=%ymm12,<E4=%ymm2,>E4=%ymm2
# bytes: 5 uops: 1
vaddpd %ymm12,%ymm2,%ymm2

# qhasm: 					  4x E3 approx-= c3
# asm 1: vsubpd <c3=reg256#13,<E3=reg256#6,>E3=reg256#6
# asm 2: vsubpd <c3=%ymm12,<E3=%ymm5,>E3=%ymm5
# bytes: 5 uops: 1
vsubpd %ymm12,%ymm5,%ymm5

# qhasm:                                           4x c5 = approx E5 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#8),<E5=reg256#1,>c5=reg256#13
# asm 2: vmulpd -128(<const1=%r10),<E5=%ymm0,>c5=%ymm12
# bytes: 6 uops: 1
vmulpd -128(%r10),%ymm0,%ymm12

# qhasm:                                           4x c5 = round(c5)
# asm 1: vroundpd $8,<c5=reg256#13,>c5=reg256#13
# asm 2: vroundpd $8,<c5=%ymm12,>c5=%ymm12
# bytes: 6 uops: 1
vroundpd $8,%ymm12,%ymm12

# qhasm:                                           4x E0 approx+= c5
# asm 1: vaddpd <c5=reg256#13,<E0=reg256#2,>E0=reg256#14
# asm 2: vaddpd <c5=%ymm12,<E0=%ymm1,>E0=%ymm13
# bytes: 5 uops: 1
vaddpd %ymm12,%ymm1,%ymm13

# qhasm:                                           4x c5 approx*= mem256[const0 + 32]
# asm 1: vmulpd 32(<const0=int64#7),<c5=reg256#13,>c5=reg256#2
# asm 2: vmulpd 32(<const0=%rax),<c5=%ymm12,>c5=%ymm1
# bytes: 5 uops: 1
vmulpd 32(%rax),%ymm12,%ymm1
# block pos: 4097 4128 uops: 6

# qhasm:                                           4x E5 approx-= c5
# asm 1: vsubpd <c5=reg256#2,<E5=reg256#1,>E5=reg256#1
# asm 2: vsubpd <c5=%ymm1,<E5=%ymm0,>E5=%ymm0
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm1,%ymm0,%ymm0

# qhasm:                                           4x c1 = approx E1 * mem256[const0 + 96]
# asm 1: vmulpd 96(<const0=int64#7),<E1=reg256#4,>c1=reg256#2
# asm 2: vmulpd 96(<const0=%rax),<E1=%ymm3,>c1=%ymm1
# bytes: 5 uops: 1
vmulpd 96(%rax),%ymm3,%ymm1

# qhasm:                                           4x c1 = round(c1)
# asm 1: vroundpd $8,<c1=reg256#2,>c1=reg256#2
# asm 2: vroundpd $8,<c1=%ymm1,>c1=%ymm1
# bytes: 6 uops: 1
vroundpd $8,%ymm1,%ymm1

# qhasm:                                           4x c1 approx*= mem256[const0 - 96]
# asm 1: vmulpd -96(<const0=int64#7),<c1=reg256#2,>c1=reg256#2
# asm 2: vmulpd -96(<const0=%rax),<c1=%ymm1,>c1=%ymm1
# bytes: 5 uops: 1
vmulpd -96(%rax),%ymm1,%ymm1

# qhasm:                                           4x E2 approx+= c1
# asm 1: vaddpd <c1=reg256#2,<E2=reg256#8,>E2=reg256#8
# asm 2: vaddpd <c1=%ymm1,<E2=%ymm7,>E2=%ymm7
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm1,%ymm7,%ymm7

# qhasm:                                           4x E1 approx-= c1
# asm 1: vsubpd <c1=reg256#2,<E1=reg256#4,>E1=reg256#4
# asm 2: vsubpd <c1=%ymm1,<E1=%ymm3,>E1=%ymm3
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm1,%ymm3,%ymm3
# block pos: 4128 4160 uops: 6

# qhasm:                                           4x E4 approx+= E5
# asm 1: vaddpd <E5=reg256#1,<E4=reg256#3,>E4=reg256#1
# asm 2: vaddpd <E5=%ymm0,<E4=%ymm2,>E4=%ymm0
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm0,%ymm2,%ymm0

# qhasm:                                           4x E2 approx+= E3
# asm 1: vaddpd <E3=reg256#6,<E2=reg256#8,>E2=reg256#2
# asm 2: vaddpd <E3=%ymm5,<E2=%ymm7,>E2=%ymm1
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm5,%ymm7,%ymm1

# qhasm:                                           4x E0 approx+= E1
# asm 1: vaddpd <E1=reg256#4,<E0=reg256#14,>E0=reg256#3
# asm 2: vaddpd <E1=%ymm3,<E0=%ymm13,>E0=%ymm2
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm3,%ymm13,%ymm2

# qhasm:   4x c5 = approx F5 * mem256[const1 - 128]
# asm 1: vmulpd -128(<const1=int64#8),<F5=reg256#5,>c5=reg256#4
# asm 2: vmulpd -128(<const1=%r10),<F5=%ymm4,>c5=%ymm3
# bytes: 6 uops: 1
vmulpd -128(%r10),%ymm4,%ymm3

# qhasm:   4x c5 = round(c5)
# asm 1: vroundpd $8,<c5=reg256#4,>c5=reg256#4
# asm 2: vroundpd $8,<c5=%ymm3,>c5=%ymm3
# bytes: 6 uops: 1
vroundpd $8,%ymm3,%ymm3

# qhasm:   4x F0 approx+= c5
# asm 1: vaddpd <c5=reg256#4,<F0=reg256#9,>F0=reg256#6
# asm 2: vaddpd <c5=%ymm3,<F0=%ymm8,>F0=%ymm5
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm3,%ymm8,%ymm5
# block pos: 4160 4192 uops: 6

# qhasm:   4x c5 approx*= mem256[const0 + 32]
# asm 1: vmulpd 32(<const0=int64#7),<c5=reg256#4,>c5=reg256#4
# asm 2: vmulpd 32(<const0=%rax),<c5=%ymm3,>c5=%ymm3
# bytes: 5 uops: 1
vmulpd 32(%rax),%ymm3,%ymm3

# qhasm:   4x F5 approx-= c5
# asm 1: vsubpd <c5=reg256#4,<F5=reg256#5,>F5=reg256#4
# asm 2: vsubpd <c5=%ymm3,<F5=%ymm4,>F5=%ymm3
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm3,%ymm4,%ymm3

# qhasm:   4x F4 approx+= F5
# asm 1: vaddpd <F5=reg256#4,<F4=reg256#7,>F4=reg256#4
# asm 2: vaddpd <F5=%ymm3,<F4=%ymm6,>F4=%ymm3
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm3,%ymm6,%ymm3

# qhasm:   4x c3 = approx F3 * mem256[const1 - 64]
# asm 1: vmulpd -64(<const1=int64#8),<F3=reg256#10,>c3=reg256#5
# asm 2: vmulpd -64(<const1=%r10),<F3=%ymm9,>c3=%ymm4
# bytes: 6 uops: 1
vmulpd -64(%r10),%ymm9,%ymm4

# qhasm:   4x c3 = round(c3)
# asm 1: vroundpd $8,<c3=reg256#5,>c3=reg256#5
# asm 2: vroundpd $8,<c3=%ymm4,>c3=%ymm4
# bytes: 6 uops: 1
vroundpd $8,%ymm4,%ymm4

# qhasm:   4x c3 approx*= mem256[const0 - 32]
# asm 1: vmulpd -32(<const0=int64#7),<c3=reg256#5,>c3=reg256#5
# asm 2: vmulpd -32(<const0=%rax),<c3=%ymm4,>c3=%ymm4
# bytes: 5 uops: 1
vmulpd -32(%rax),%ymm4,%ymm4
# block pos: 4192 4224 uops: 6

# qhasm:   4x F4 approx+= c3
# asm 1: vaddpd <c3=reg256#5,<F4=reg256#4,>F4=reg256#4
# asm 2: vaddpd <c3=%ymm4,<F4=%ymm3,>F4=%ymm3
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddpd %ymm4,%ymm3,%ymm3

# qhasm:   4x F3 approx-= c3
# asm 1: vsubpd <c3=reg256#5,<F3=reg256#10,>F3=reg256#5
# asm 2: vsubpd <c3=%ymm4,<F3=%ymm9,>F3=%ymm4
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm4,%ymm9,%ymm4

# qhasm:   4x F2 approx+= F3
# asm 1: vaddpd <F3=reg256#5,<F2=reg256#11,>F2=reg256#5
# asm 2: vaddpd <F3=%ymm4,<F2=%ymm10,>F2=%ymm4
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm4,%ymm10,%ymm4

# qhasm:   4x c1 = approx F1 * mem256[const0 + 96]
# asm 1: vmulpd 96(<const0=int64#7),<F1=reg256#12,>c1=reg256#7
# asm 2: vmulpd 96(<const0=%rax),<F1=%ymm11,>c1=%ymm6
# bytes: 5 uops: 1
vmulpd 96(%rax),%ymm11,%ymm6

# qhasm:   4x c1 = round(c1)
# asm 1: vroundpd $8,<c1=reg256#7,>c1=reg256#7
# asm 2: vroundpd $8,<c1=%ymm6,>c1=%ymm6
# bytes: 6 uops: 1
vroundpd $8,%ymm6,%ymm6

# qhasm:   4x c1 approx*= mem256[const0 - 96]
# asm 1: vmulpd -96(<const0=int64#7),<c1=reg256#7,>c1=reg256#7
# asm 2: vmulpd -96(<const0=%rax),<c1=%ymm6,>c1=%ymm6
# bytes: 5 uops: 1
vmulpd -96(%rax),%ymm6,%ymm6
# block pos: 4224 4256 uops: 6

# qhasm:   4x F2 approx+= c1
# asm 1: vaddpd <c1=reg256#7,<F2=reg256#5,>F2=reg256#5
# asm 2: vaddpd <c1=%ymm6,<F2=%ymm4,>F2=%ymm4
# bytes: 6 uops: 1
.byte 0x3e
.byte 0x3e
vaddpd %ymm6,%ymm4,%ymm4

# qhasm:   4x F1 approx-= c1
# asm 1: vsubpd <c1=reg256#7,<F1=reg256#12,>F1=reg256#7
# asm 2: vsubpd <c1=%ymm6,<F1=%ymm11,>F1=%ymm6
# bytes: 5 uops: 1
.byte 0x3e
vsubpd %ymm6,%ymm11,%ymm6

# qhasm:   4x F0 approx+= F1
# asm 1: vaddpd <F1=reg256#7,<F0=reg256#6,>F0=reg256#6
# asm 2: vaddpd <F1=%ymm6,<F0=%ymm5,>F0=%ymm5
# bytes: 5 uops: 1
.byte 0x3e
vaddpd %ymm6,%ymm5,%ymm5

# qhasm:                   signed<? pos - 0
# asm 1: cmp  $0,<pos=int64#10
# asm 2: cmp  $0,<pos=%r12
# bytes: 5 uops: 1
.byte 0x3e
cmp  $0,%r12
# comment:fp stack unchanged by jump

# qhasm: goto mainloop if !signed<
# bytes: 6 uops: 1
jge ._mainloop

# qhasm:   prevbit -= 1
# asm 1: sub  $1,<prevbit=int64#11
# asm 2: sub  $1,<prevbit=%r13
# bytes: 5 uops: 1
.byte 0x3e
sub  $1,%r13
# block pos: 4256 4288 uops: 6

# qhasm:   mem64[work3 + 32] = prevbit
# asm 1: movq   <prevbit=int64#11,32(<work3=int64#1)
# asm 2: movq   <prevbit=%r13,32(<work3=%rdi)
# bytes: 4 uops: 1
movq   %r13,32(%rdi)

# qhasm:   b = mem64[work3 + 32],mem64[work3 + 32],mem64[work3 + 32],mem64[work3 + 32]
# asm 1: vbroadcastsd 32(<work3=int64#1),>b=reg256#7
# asm 2: vbroadcastsd 32(<work3=%rdi),>b=%ymm6
# bytes: 6 uops: 1
vbroadcastsd 32(%rdi),%ymm6

# qhasm:   4x E4 = F4 if b<0 else E4
# asm 1: vblendvpd <b=reg256#7,<F4=reg256#4,<E4=reg256#1,>E4=reg256#1
# asm 2: vblendvpd <b=%ymm6,<F4=%ymm3,<E4=%ymm0,>E4=%ymm0
# bytes: 11 uops: 2
.byte 0x3e
.byte 0x3e
.byte 0x3e
.byte 0x3e
.byte 0x3e
vblendvpd %ymm6,%ymm3,%ymm0,%ymm0

# qhasm:   4x E2 = F2 if b<0 else E2
# asm 1: vblendvpd <b=reg256#7,<F2=reg256#5,<E2=reg256#2,>E2=reg256#2
# asm 2: vblendvpd <b=%ymm6,<F2=%ymm4,<E2=%ymm1,>E2=%ymm1
# bytes: 11 uops: 2
.byte 0x3e
.byte 0x3e
.byte 0x3e
.byte 0x3e
.byte 0x3e
vblendvpd %ymm6,%ymm4,%ymm1,%ymm1
# block pos: 4288 4320 uops: 6

# qhasm:   4x E0 = F0 if b<0 else E0
# asm 1: vblendvpd <b=reg256#7,<F0=reg256#6,<E0=reg256#3,>E0=reg256#3
# asm 2: vblendvpd <b=%ymm6,<F0=%ymm5,<E0=%ymm2,>E0=%ymm2
# bytes: 7 uops: 2
.byte 0x3e
vblendvpd %ymm6,%ymm5,%ymm2,%ymm2

# qhasm:   mem256[work1 + 0] aligned= E4
# asm 1: vmovapd   <E4=reg256#1,0(<work1=int64#5)
# asm 2: vmovapd   <E4=%ymm0,0(<work1=%r8)
# bytes: 5 uops: 1
vmovapd   %ymm0,0(%r8)

# qhasm:   mem256[work1 - 64] aligned= E2
# asm 1: vmovapd   <E2=reg256#2,-64(<work1=int64#5)
# asm 2: vmovapd   <E2=%ymm1,-64(<work1=%r8)
# bytes: 6 uops: 1
vmovapd   %ymm1,-64(%r8)

# qhasm:   mem256[work1 - 128] aligned= E0
# asm 1: vmovapd   <E0=reg256#3,-128(<work1=int64#5)
# asm 2: vmovapd   <E0=%ymm2,-128(<work1=%r8)
# bytes: 6 uops: 1
vmovapd   %ymm2,-128(%r8)

# qhasm:   caller_r11 = stack_r11
# asm 1: movq <stack_r11=stack64#1,>caller_r11=int64#9
# asm 2: movq <stack_r11=896(%rsp),>caller_r11=%r11
# bytes: 8 uops: 1
movq 896(%rsp),%r11
# block pos: 4320 4352 uops: 4

# qhasm:   caller_r12 = stack_r12
# asm 1: movq <stack_r12=stack64#2,>caller_r12=int64#10
# asm 2: movq <stack_r12=904(%rsp),>caller_r12=%r12
# bytes: 8 uops: 1
movq 904(%rsp),%r12

# qhasm:   caller_r13 = stack_r13
# asm 1: movq <stack_r13=stack64#3,>caller_r13=int64#11
# asm 2: movq <stack_r13=912(%rsp),>caller_r13=%r13
# bytes: 8 uops: 1
movq 912(%rsp),%r13

# qhasm:   caller_r14 = stack_r14
# asm 1: movq <stack_r14=stack64#4,>caller_r14=int64#12
# asm 2: movq <stack_r14=920(%rsp),>caller_r14=%r14
# bytes: 8 uops: 1
movq 920(%rsp),%r14

# qhasm:   caller_r15 = stack_r15
# asm 1: movq <stack_r15=stack64#5,>caller_r15=int64#13
# asm 2: movq <stack_r15=928(%rsp),>caller_r15=%r15
# bytes: 8 uops: 1
movq 928(%rsp),%r15
# block pos: 4352 4372 uops: 4

# qhasm:   caller_rbx = stack_rbx
# asm 1: movq <stack_rbx=stack64#6,>caller_rbx=int64#14
# asm 2: movq <stack_rbx=936(%rsp),>caller_rbx=%rbx
# bytes: 8 uops: 1
movq 936(%rsp),%rbx

# qhasm:   caller_rbp = stack_rbp
# asm 1: movq <stack_rbp=stack64#7,>caller_rbp=int64#15
# asm 2: movq <stack_rbp=944(%rsp),>caller_rbp=%rbp
# bytes: 8 uops: 1
movq 944(%rsp),%rbp

# qhasm: return
# bytes: 3 uops: 1
add %r11,%rsp
# bytes: 1 uops: 1
ret
